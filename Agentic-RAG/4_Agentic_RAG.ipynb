{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783a234e",
   "metadata": {},
   "source": [
    "### In this section, I will build an Agentic RAG\n",
    "\n",
    "Now I have a Rerank RAG which can retrieve relevant medicine documents based on the query.\n",
    "\n",
    "But why I need an **Agentic RAG**?\n",
    "\n",
    "Becuase Rerank RAG can only similarity search documents by query. If the query contains no relevant information linked to the documents in vector database, it is not able to retrieve relevant docs.\n",
    "\n",
    "I describe some real-life scenarios we can have below:\n",
    "\n",
    "### Problem description:\n",
    "\n",
    "In real conversation, users can ask anything we can not predict ahead. \n",
    "\n",
    "For example:\n",
    "In the third turn the user really want to ask 'How do I take Phenylephrine?'\n",
    "\n",
    "But he types 'How do I take it?'. From the context, 'it' means 'Phenylephrine'.\n",
    "\n",
    "If we retrieve documents by query 'How do I take it?', we can get unrelevant document.  'How do I take Phenylephrine?' makes more sense.\n",
    "\n",
    "Other scenarios:\n",
    "\n",
    "1. In first turn, a user just greet without any question.\n",
    "2. User ask a random question in the middle of conversation.\n",
    "3. .........\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "The root problem is how to determine whether a query is a clinial/medical query and whether a query is related previous conversation.\n",
    "\n",
    "### Solution:\n",
    "\n",
    "#### To handle all those, I will put a local LLM as a master agent to determine what to do next based on different situation.\n",
    "#### So I will involve Basic RAG, langgraph, memory, local LLM, wiki search tool... working together to make the RAG can retrieve real relevant documents by itself.\n",
    "\n",
    "### Implementation:\n",
    "\n",
    "* I will involve an agent to decide what to do next based on the query and history conversation. \n",
    "* Then, the agent will execute the task and observe the result to decide again..... until get a proper result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac03e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own libraries\n",
    "from mytools import best_dtype, best_device, login_huggingface\n",
    "from rerank_rag import Rerank_RAG\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import uuid\n",
    "import random\n",
    "import settings\n",
    "\n",
    "from typing import TypedDict, List, Literal, Any, Dict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory # Short-term Memory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain_community.tools import WikipediaQueryRun, BraveSearch\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9626d",
   "metadata": {},
   "source": [
    "#### As I mentioned previously:\n",
    "\n",
    "Bio-Medical-Llama-3-8B model is a specialized large language model designed for biomedical applications. It is finetuned from the meta-llama/Meta-Llama-3-8B-Instruct model using a custom dataset containing over 500,000 diverse entries. These entries include a mix of synthetic and manually curated data, ensuring high quality and broad coverage of biomedical topics.\n",
    "\n",
    "The model is trained to understand and generate text related to various biomedical fields, making it a valuable tool for researchers, clinicians, and other professionals in the biomedical domain.\n",
    "\n",
    "@misc{ContactDoctor_Bio-Medical-Llama-3-8B, author = ContactDoctor, title = {ContactDoctor-Bio-Medical: A High-Performance Biomedical Language Model}, year = {2024}, howpublished = {https://huggingface.co/ContactDoctor/Bio-Medical-Llama-3-8B}, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8cdc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
    "\n",
    "#model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "195419ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login HuggingFace!\n"
     ]
    }
   ],
   "source": [
    "login_huggingface() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78220075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b137ba11024ed88c3058bdfc601ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenizer and base model done!\n"
     ]
    }
   ],
   "source": [
    "# Load a HuggingFace model. Inference it from local GPU.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    dtype = best_dtype(),\n",
    "    device_map={\"\":best_device()},     \n",
    "    low_cpu_mem_usage=True     \n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Load tokenizer and base model done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3ff620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n",
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)                    # full architecture tree (long but useful)\n",
    "print(model.config)             # core hyperparameters (dims, layers, heads…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0da7c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "original_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,  \n",
    "    temperature=0.1,  \n",
    "    return_full_text=False,   \n",
    ")\n",
    "\n",
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipeline = HuggingFacePipeline(pipeline=original_pipeline)\n",
    "\n",
    "master_llm = ChatHuggingFace(llm=hug_pipeline) # It is the brain of the whole system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c8317",
   "metadata": {},
   "source": [
    "### Master LLM is ready. Next RAG...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3662b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_retriever starts runing!\n",
      "Login HuggingFace!\n",
      "load_embedding_model starts runing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 5.2.0.dev0, but you're currently using version 5.1.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_embedding_model took 4.0355s\n",
      "load_crossencoder starts runing!\n",
      "load_crossencoder took 1.1209s\n",
      "setup_retriever took 6.9355s\n"
     ]
    }
   ],
   "source": [
    "rag = Rerank_RAG()\n",
    "rag.setup_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cd4628ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b417c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "brave_api_key = os.getenv(\"BRAVE_SEARCH_KEY\")\n",
    "brave = BraveSearch.from_api_key(api_key=brave_api_key, search_kwargs={\"count\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e85d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a short-term memory\n",
    "\n",
    "class Short_Term_Memory():\n",
    "    def __init__(self) -> None: \n",
    "        \"\"\"Initialize the message container and current session id \"\"\"       \n",
    "        self.session_store: dict[int,BaseChatMessageHistory] = {}\n",
    "        self.current_session_id: int = 0\n",
    "\n",
    "    def get_history(self, session_id: int) -> BaseChatMessageHistory:    \n",
    "        \"\"\"return history messages by sessionId\"\"\"    \n",
    "        self.current_session_id = session_id\n",
    "        if session_id not in self.session_store:\n",
    "            self.session_store[session_id] = ChatMessageHistory()\n",
    "        return self.session_store[session_id]\n",
    "    \n",
    "    def get_current_history(self) -> BaseChatMessageHistory:\n",
    "        \"\"\"return history messages for current session\"\"\"\n",
    "        return self.get_history(self.current_session_id)\n",
    "    \n",
    "    def add_message(self, session_id: int, message: str, msg_type: str) -> None:\n",
    "        history_messages = self.get_history(session_id)\n",
    "        if len(history_messages.messages) >= 5: # Only keep the recent 5 messages\n",
    "            del history_messages.messages[0] # Remove the first message\n",
    "        \n",
    "        if msg_type == \"ai\": \n",
    "            history_messages.add_ai_message(message)\n",
    "        else:\n",
    "            history_messages.add_user_message(message)        \n",
    "            \n",
    "    \n",
    "    def delete_history(self, session_id: int) -> bool:\n",
    "        \"\"\"delete history messages by sessionId\"\"\"\n",
    "        if session_id in self.session_store:\n",
    "            deleted = self.session_store.pop(session_id)\n",
    "            if deleted:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def delete_current_history(self) -> bool:\n",
    "        \"\"\"delete history messages for current session\"\"\"\n",
    "        return self.delete_history(self.current_session_id)\n",
    "    \n",
    "# Convert a history chat message to a string\n",
    "def history_as_text(history: BaseChatMessageHistory) -> str:\n",
    "    \"\"\"convert history messsages into a string\"\"\"\n",
    "    return \"\\n\".join([\n",
    "        f\"{m.type.upper()}: {m.content[:150]}\"   # e.g. \"HUMAN: …\" or \"Master_Agent: …\"\n",
    "        for m in history.messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8205392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the graph.\n",
    "\n",
    "    Attributes:\n",
    "        session_id: current session id\n",
    "        query: user's query or augmented query\n",
    "        retrieved_doc: retrieval docment    \n",
    "        grade: keep the binary score for every router node to make decision   \n",
    "        wiki_used: Flag whether it already used Wiki search\n",
    "        brave_used: Flag whether it already used brave search\n",
    "        rewrite_counter: count rewrite action, maximum 3 times.\n",
    "    \"\"\"\n",
    "    session_id: int\n",
    "    query: str\n",
    "    retrieved_doc: str\n",
    "    grade: dict\n",
    "    wiki_used: bool      # Avoid infinity loop in graph\n",
    "    brave_used: bool     # Avoid infinity loop in graph\n",
    "    rewrite_counter: int # Avoid infinity loop in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50cf13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a global short-term memory for all users\n",
    "settings.SHORT_TERM_MEMORY = Short_Term_Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "daa7445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test function\n",
    "\n",
    "def unit_test(action_func, decide_function):\n",
    "    questions = [\n",
    "        \"Why doesn't my friend play tennis with me?\",\n",
    "        \"What is the tallest mountain in South America?\",        \n",
    "        \"Can you explain how blockchain technology works?\",\n",
    "        \"It is not a good idea.\"      \n",
    "        \"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\",        \n",
    "        \"How can I take it?\",\n",
    "        \"Which symptoms usually appear first in a case of seasonal influenza?\",        \n",
    "        \"what do you recommend?\",\n",
    "        \"What are the warning signs of a severe allergic reaction?\",\n",
    "        \"The project is reaching the deadline.\"       \n",
    "    ]\n",
    "\n",
    "    session_id = 1\n",
    "    settings.STEP = 1\n",
    "\n",
    "    for query in questions:\n",
    "        state = AgentState(session_id=session_id,query=query,wiki_used=False,brave_used=False,rewrite_counter=0)\n",
    "        state = action_func(state)\n",
    "        result = decide_function(state)\n",
    "        print(f\"Decision: {result} \\n\")\n",
    "        print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5ac26",
   "metadata": {},
   "source": [
    "#### Local and small LLMs usually has no robust structured output. So I have to prepare for all possible results it might output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b1fceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_score(text: str) -> str:\n",
    "    \"\"\"Force 'yes'/'no' from messy text.\"\"\"\n",
    "    t = text.strip().lower()\n",
    "    if t in {\"yes\", \"y\", \"true\",\"ok\", \"1\"}:\n",
    "        return \"yes\"\n",
    "    if t in {\"no\", \"n\", \"false\", \"0\"}:\n",
    "        return \"no\"\n",
    "    # heuristics: ambiguous/under-specified → \"no\"\n",
    "    return \"no\"\n",
    "\n",
    "\n",
    "def _extract_json_like(s: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Try hard to find {\"score\": \"...\"} inside messy output.\n",
    "    \"\"\"\n",
    "    # 1) quick regex for a minimal JSON object with score\n",
    "    m = re.search(r'\\{[^{}]*\"score\"\\s*:\\s*\"(?P<score>yes|no|true|false)\"[^{}]*\\}', s, flags=re.I)\n",
    "    if m:\n",
    "        return {\"score\": _normalize_score(m.group(\"score\"))}\n",
    "\n",
    "    # 2) fall back: if the model just said \"yes\"/\"no\" without JSON\n",
    "    yn = re.search(r'\\b(yes|no|true|false)\\b', s, flags=re.I)\n",
    "    if yn:\n",
    "        return {\"score\": _normalize_score(yn.group(1))}\n",
    "\n",
    "    # 3) last resort default\n",
    "    return {\"score\": \"no\"}\n",
    "\n",
    "def robust_binary_grader(prompt: PromptTemplate, query: str, document: str = \"\") ->dict:\n",
    "    \"\"\" \n",
    "    Make sure robustly parse the grade result of Local LLM \n",
    "    \"\"\"\n",
    "    # Base parser (strict JSON with a single key)\n",
    "    base_parser = JsonOutputParser(pydantic_object=None, json_kwargs={\"strict\": False})\n",
    "    # Auto-fixing parser: if model outputs invalid JSON, it asks the LLM to repair\n",
    "    fixing_parser = OutputFixingParser.from_llm(parser=base_parser, llm=master_llm)\n",
    "       # Lower temperature for determinism\n",
    "    chain = prompt | master_llm | fixing_parser\n",
    "    result = None\n",
    "    try:\n",
    "        # First attempt: LLM → (auto-fixing) parser\n",
    "        if document == \"\":\n",
    "            result = chain.invoke({\"question\": query})  \n",
    "        else:\n",
    "            result = chain.invoke({\"question\": query, \"document\": document})\n",
    "        print(f\"Real output: {result}\\n\")        \n",
    "        # result may already be a dict (from parser), but be defensive:\n",
    "        if isinstance(result, dict) and \"score\" in result:\n",
    "            score = _normalize_score(str(result[\"score\"]))\n",
    "            return {\"score\": score}  # exact contract            \n",
    "\n",
    "        # If parser returned a string (some models), try to json-load or extract\n",
    "        if isinstance(result, str):\n",
    "            try:\n",
    "                json_obj = _extract_json_like(result)\n",
    "                score = _normalize_score(str(json_obj.get(\"score\", \"\")))\n",
    "                return {\"score\": score}                \n",
    "            except Exception:\n",
    "                pass\n",
    "        # Fall through to the worst baseline\n",
    "        if any(r in str(result).lower() for r in [\"yes\", \"true\"]):\n",
    "            return {\"score\": \"yes\"}\n",
    "        else:\n",
    "            return {\"score\": \"no\"}       \n",
    "\n",
    "    except Exception as e:\n",
    "        # Hard fallback path if LLM/parse fails entirely\n",
    "        print(f\"[grade_selfcontained_query] Warning: parse failed: {e} \\n\") \n",
    "\n",
    "        return {\"score\": \"no\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab4df7",
   "metadata": {},
   "source": [
    "#### Local LLMs usually output things without control. So I have to handle with all possible results it might output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "756510fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_one_line_question(text: str, fallback: str, max_len: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Make whatever the LLM returned into a clean single-line question.\n",
    "    - strip code fences, quotes, labels\n",
    "    - collapse whitespace\n",
    "    - take the first question-looking sentence if multiple\n",
    "    - ensure it ends with '?'\n",
    "    - length-limit (soft)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text or \"\")\n",
    "\n",
    "    t = text.strip()\n",
    "\n",
    "    # remove common code fences or labels\n",
    "    t = re.sub(r\"^`{3,}.*?\\n|\\n`{3,}$\", \"\", t, flags=re.S)        # ```...```\n",
    "    t = re.sub(r\"^(re.?written|improved|final|answer)\\s*:\\s*\", \"\", t, flags=re.I)\n",
    "    t = re.sub(r\"^\\\"|\\\"$\", \"\", t)  # trim surrounding quotes\n",
    "    t = re.sub(r\"^'+|'+$\", \"\", t)  # trim surrounding single quotes\n",
    "\n",
    "    # collapse to one line\n",
    "    t = \" \".join(t.split())\n",
    "\n",
    "    # If LLM returned multiple sentences, try to pick the first question-like sentence.\n",
    "    # Prefer the first chunk that ends with '?'\n",
    "    m = re.search(r\"([^?]{3,}\\?)\", t)\n",
    "    if m:\n",
    "        t = m.group(1).strip()\n",
    "\n",
    "    # If still no question mark, try to cut at a sentence boundary and add '?'\n",
    "    if \"?\" not in t:\n",
    "        # take up to first period/exclamation if present, else keep entire\n",
    "        m2 = re.split(r\"[.!]\", t, maxsplit=1)\n",
    "        candidate = m2[0].strip()\n",
    "        # guard against empty\n",
    "        if len(candidate) >= 3:\n",
    "            t = candidate\n",
    "        if not t.endswith(\"?\"):\n",
    "            t = t.rstrip(\"?\") + \"?\"\n",
    "\n",
    "    # truncate softly (avoid cutting mid-word)\n",
    "    if len(t) > max_len:\n",
    "        t = t[:max_len].rsplit(\" \", 1)[0].rstrip(\"?,.;:! \") + \"?\"\n",
    "\n",
    "    # last resort fallback\n",
    "    if len(t) < 3:\n",
    "        t = fallback.strip()\n",
    "        if not t.endswith(\"?\"):\n",
    "            t += \"?\"\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def robust_question_generater(prompt: PromptTemplate, query: str, document: str = \"\") -> str:\n",
    "    \"\"\" \n",
    "    Make sure robustly extract the question Local LLM generates.\n",
    "    \"\"\"\n",
    "    chain = prompt | master_llm | StrOutputParser()\n",
    "    try:\n",
    "        raw = chain.invoke({\"question\": query, \"document\": document})\n",
    "        print(f\"Real output: {raw}\\n\")\n",
    "        result = _clean_one_line_question(raw, fallback=query, max_len=200)\n",
    "        return result\n",
    "    except Exception:\n",
    "        # hard fallback: if model call fails, return original as a question\n",
    "        return query if query.endswith(\"?\") else (query + \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0200765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_to_json(s: str):\n",
    "    \"\"\" \n",
    "    convert the docs from Wikipedia into a list of json objects\n",
    "    \"\"\"\n",
    "    records = [r.strip() for r in s.strip().split(\"\\n\\n\") if r.strip()]\n",
    "\n",
    "    data = []\n",
    "    for record in records:\n",
    "        page_match = re.search(r\"Page:\\s*(.+)\", record)\n",
    "        summary_match = re.search(r\"Summary:\\s*(.+)\", record, re.DOTALL)\n",
    "        if page_match and summary_match:\n",
    "            data.append({\n",
    "                \"Page\": page_match.group(1).strip(),\n",
    "                \"Summary\": summary_match.group(1).strip()\n",
    "            })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "350b423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_selfcontained_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is meaningful, clear, and self-contained\n",
    "    without relying on prior conversation context.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"\"\"Master_Agent: Got a new query: \"{query}\"\\nI will check if the query is self-contained.\\n\"\"\")  \n",
    "    \n",
    "    # prompt = PromptTemplate(\n",
    "    #     template=\"\"\"You are a grader for a question. \\n \n",
    "    #     You need to determine if a question is meaningful, clear, self-contained without any ambiguity, if you don't know the conversation context. \\n    \n",
    "    #     Here is the user's question: {question} \\n   \n",
    "    #     Give a binary score 'yes' or 'no' score to indicate whether the question is meaningful and self-contained. \\n     \n",
    "    #     Only provide the binary score as a JSON object with a single key 'score', for example {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}. No premable or explanation.\"\"\",\n",
    "    #     input_variables=[\"question\"],\n",
    "    # )\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader for a question.\n",
    "    You must decide whether the question is self-contained—meaning that it is clear, meaningful, and understandable on its own, without any conversation history or external context.\n",
    "    Here is the user's question: {question} \\n\n",
    "    Return a binary judgment as a JSON object with a single key \"score\".\n",
    "    Respond only with {{\"score\": \"yes\"}} if the question is self-contained,\n",
    "    or {{\"score\": \"no\"}} if it is not. Do not include any explanation or extra text.\"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c3ee96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_selfcontained_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it's a self-contained query, go to grader node for clinical checking.\n",
    "    If it's not a self-contained query, go to grader node for history related checking. \n",
    "    \"\"\"\n",
    "    if state['grade'][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\\n\")\n",
    "        return \"grade_clinical\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \\n\")\n",
    "        return \"grade_related_history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0898b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"Why doesn't my friend play tennis with me?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': \"Why doesn't my friend play tennis with me?\", 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: Got a new query: \"What is the tallest mountain in South America?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What is the tallest mountain in South America?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: Got a new query: \"Can you explain how blockchain technology works?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Can you explain how blockchain technology works?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: Got a new query: \"It is not a good idea.My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "Decision: grade_related_history \n",
      "\n",
      "State: {'session_id': 1, 'query': 'It is not a good idea.My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: Got a new query: \"How can I take it?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "Decision: grade_related_history \n",
      "\n",
      "State: {'session_id': 1, 'query': 'How can I take it?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: Got a new query: \"Which symptoms usually appear first in a case of seasonal influenza?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Which symptoms usually appear first in a case of seasonal influenza?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 7===\n",
      "\n",
      "Master_Agent: Got a new query: \"what do you recommend?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "Decision: grade_related_history \n",
      "\n",
      "State: {'session_id': 1, 'query': 'what do you recommend?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 8===\n",
      "\n",
      "Master_Agent: Got a new query: \"What are the warning signs of a severe allergic reaction?\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What are the warning signs of a severe allergic reaction?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 9===\n",
      "\n",
      "Master_Agent: Got a new query: \"The project is reaching the deadline.\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'The project is reaching the deadline.', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unit_test(grade_selfcontained_query, decide_selfcontained_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66633d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_clinical_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is about medicine, clinical questions\n",
    "    without relying on prior conversation context.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"I am checking if the query is about medicine or clinical questions.\\n\")   \n",
    "    \n",
    "    # prompt = PromptTemplate(\n",
    "    #     template=\"\"\"You are a grader for a question.\n",
    "    #     You need to determine if the user's question is a clinical/medical question.\n",
    "    #     Consider clinical if it asks about diagnosis, symptoms, treatment, medications (dose, interactions, side effects), test/lab interpretation, procedures, triage (\"should I see a doctor/ER?\"), risks/prognosis, or health advice for humans or animals.\n",
    "    #     Non-clinical includes general health trivia/news, biology concepts without personal care decisions, admin/insurance/scheduling, or unrelated topics.\n",
    "    #     Here is the user's question: {question} \\n\n",
    "    #     Give a binary score 'yes' or 'no' to indicate whether it is a clinical question.\n",
    "    #     Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
    "    #     No preamble or explanation.\"\"\",\n",
    "    #     input_variables=[\"question\"],\n",
    "    # )    \n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader for a user message.\n",
    "    Decide whether the message is about a medical or health-related topic.\n",
    "\n",
    "    Consider it **medical** if it involves ANY of the following:\n",
    "    - Symptoms, illnesses, injuries, or physical/mental discomfort (e.g., “I have a headache”, “I feel anxious”)\n",
    "    - Diagnosis, treatment, medications, dosage, side effects, or drug interactions\n",
    "    - Tests, lab results, medical procedures, surgeries\n",
    "    - Preventive care, pregnancy/breastfeeding guidance, vaccination\n",
    "    - Psychological or mental-health issues, therapy, counseling\n",
    "    - Any advice, risk assessment, or triage about human or animal health\n",
    "\n",
    "    Consider it **non-medical** if it is about:\n",
    "    - Pure biology or academic science without personal health context\n",
    "    - Health-related news/trivia without asking for medical guidance\n",
    "    - Insurance, scheduling, or administrative tasks\n",
    "    - Completely unrelated topics\n",
    "\n",
    "    User message:\n",
    "    {question}\n",
    "\n",
    "    Return only a JSON object with a single key \"score\":\n",
    "    - {{\"score\": \"yes\"}} if it is medical/clinical/health-related\n",
    "    - {{\"score\": \"no\"}} if it is not\n",
    "\n",
    "    Do not add any explanation or extra text.\"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ab03ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_clinical_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it is a clinical query and self-contained, go to retrieve node directly.\n",
    "    If it is not a clinical query at all, go to return_sorry node.\n",
    "    \"\"\"\n",
    "    if state['grade'][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: The query is a clinical one. We can retrive some documents now.\\n\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not clinical query. I have nothing to do with it. \\n\")\n",
    "        return \"return_sorry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27d3e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 1===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': \"Why doesn't my friend play tennis with me?\", 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What is the tallest mountain in South America?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Can you explain how blockchain technology works?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 4===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'It is not a good idea.My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 5===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'How can I take it?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 6===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Which symptoms usually appear first in a case of seasonal influenza?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 7===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'what do you recommend?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 8===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What are the warning signs of a severe allergic reaction?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 9===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'The project is reaching the deadline.', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unit_test(grade_clinical_query, decide_clinical_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "44e45ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_history_related_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is related to history conversations.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "    history_conversation = history_as_text(history)\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"Master_Agent: I am checking if the query is related to history conversations. \\n\")   \n",
    "    print(f\"history conversations: {history_conversation} \\n\")   \n",
    "    \n",
    "    # prompt = PromptTemplate(\n",
    "    #     template=\"\"\"You are a grader assessing relevance between the user's current question and history conversation. \\n \n",
    "    #     Here is current question: {question} \\n\n",
    "    #     Here is the history conversations: \\n {document} \\n        \n",
    "    #     Give a binary score 'yes' or 'no' to indicate whether the question is related to history conversations.\n",
    "    #     Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\n",
    "    #     No premable or explanation.\"\"\",\n",
    "    #     input_variables=[\"question\", \"document\"],\n",
    "    # )\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a conversation coherence grader.\n",
    "        Your task is to decide whether the user's latest message is logically and topically connected to the previous conversation.\n",
    "\n",
    "        Conversation history:\n",
    "        {document}\n",
    "\n",
    "        User's latest message:\n",
    "        {question}\n",
    "\n",
    "        Return only a JSON object with a single key \"score\":\n",
    "        - {{\"score\": \"yes\"}} if the latest message is coherent and contextually related to the conversation history.\n",
    "        - {{\"score\": \"no\"}} if it is not related or breaks the context.\n",
    "\n",
    "        No explanation or extra text.\"\"\",\n",
    "        input_variables=[\"document\", \"question\"],\n",
    "    )    \n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query, document=history_conversation)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0e457e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_history_related_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If the query is related to the history conversation, but it is not self-contained. Go to rewrite node to augment the query.\n",
    "    If the query is not related to the history. Go to \"return_sorry\" node.\n",
    "    \"\"\"    \n",
    "    if state['grade'][\"score\"] == \"yes\" and state[\"rewrite_counter\"] < 3:\n",
    "        print(f\"Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\\n\")\n",
    "        return \"rewrite\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not related to the history. So it is a random query. \\n\")\n",
    "        return \"return_sorry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "abbb7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "#history = settings.SHORT_TERM_MEMORY.get_history(session_id = 1)\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"hi, there!\", msg_type=\"human\")\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"hi, how can I help you?\", msg_type=\"ai\")\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\", msg_type=\"human\")\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\", msg_type=\"ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f51e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 10===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. \n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "Decision: rewrite \n",
      "\n",
      "State: {'session_id': 1, 'query': 'How can I take it?', 'wiki_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 11===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. \n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "Decision: rewrite \n",
      "\n",
      "State: {'session_id': 1, 'query': 'where can I buy it?', 'wiki_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should be related to history\n",
    "state = AgentState(session_id=1, query=\"How can I take it?\",wiki_used=False,rewrite_counter=0)\n",
    "\n",
    "state = grade_history_related_query(state)\n",
    "\n",
    "result = decide_history_related_query(state)\n",
    "\n",
    "print(f\"Decision: {result} \\n\")\n",
    "print(f\"State: {state} \\n\")\n",
    "# Related case\n",
    "state = AgentState(session_id=1, query=\"where can I buy it?\",wiki_used=False,rewrite_counter=0)\n",
    "\n",
    "state = grade_history_related_query(state)\n",
    "\n",
    "result = decide_history_related_query(state)\n",
    "\n",
    "print(f\"Decision: {result} \\n\")\n",
    "print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8d685757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 12===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. \n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': \"Why doesn't my friend play tennis with me?\", 'wiki_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should be not related to history\n",
    "state = AgentState(session_id=1, query=\"Why doesn't my friend play tennis with me?\",wiki_used=False,rewrite_counter=0)\n",
    "\n",
    "state = grade_history_related_query(state)\n",
    "\n",
    "result = decide_history_related_query(state)\n",
    "\n",
    "print(f\"Decision: {result} \\n\")\n",
    "print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5f68d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def rewrite_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is related to history conversations.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "    history_conversation = history_as_text(history)\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \\n\")      \n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a question rewriter.\n",
    "    Your goal is to make the user's question fully self-contained and clear\n",
    "    by using the information provided in the reference material.\n",
    "\n",
    "    Reference material:\n",
    "    {document}\n",
    "\n",
    "    Original question:\n",
    "    {question}\n",
    "\n",
    "    Rewrite the question so that:\n",
    "    - It preserves the original intent and meaning.\n",
    "    - It includes any missing details from the reference material so the question can stand alone and be understood without reading the material.\n",
    "    - It is concise and natural.\n",
    "\n",
    "    Return only the rewritten question text with no explanation, no preamble, and no extra formatting.\"\"\",\n",
    "        input_variables=[\"question\", \"document\"],\n",
    "    )\n",
    "    # prompt = PromptTemplate(\n",
    "    #     template=\"\"\"You are question re-writer that converts an input question to a better version that is optimized \\n \n",
    "    #     for vectorstore retrieval. Use the history conversation to resolve references. Keep the contextual meaning. \\n\n",
    "    #     Here is the history conversation: \\n\\n {document} \\n\\n\n",
    "    #     Here is the initial question: \\n\\n {question}. \\n\n",
    "    #     Improved question with no preamble.\"\"\",\n",
    "    #     input_variables=[\"question\", \"document\"],\n",
    "    # )\n",
    "\n",
    "    new_query = robust_question_generater(prompt=prompt, query=query, document=history_conversation)\n",
    "    state['rewrite_counter'] += 1\n",
    "    state = AgentState(session_id=state[\"session_id\"], query=new_query, rewrite_counter=state['rewrite_counter']) # Avoid infinity loop in graph.\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "48abba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 13===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output: How do I take phenylephrine to relieve nasal discomfort caused by colds, allergies, and hay fever, and to relieve sinus congestion and pressure?\n",
      "\n",
      "State: {'session_id': 1, 'query': 'How do I take phenylephrine to relieve nasal discomfort caused by colds, allergies, and hay fever, and to relieve sinus congestion and pressure?', 'rewrite_counter': 1} \n",
      "\n",
      "===Step 14===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output: Can I buy phenylephrine, a medicine used to relieve nasal discomfort caused by colds, allergies, and hay fever, and relieve sinus congestion and pressure?\n",
      "\n",
      "State: {'session_id': 1, 'query': 'Can I buy phenylephrine, a medicine used to relieve nasal discomfort caused by colds, allergies, and hay fever, and relieve sinus congestion and pressure?', 'rewrite_counter': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should be related to history\n",
    "state = AgentState(session_id=1, query=\"How can I take it?\",rewrite_counter=0)\n",
    "\n",
    "state = rewrite_query(state)\n",
    "\n",
    "print(f\"State: {state} \\n\")\n",
    "\n",
    "state = AgentState(session_id=1, query=\"Where can I buy it?\",rewrite_counter=0)\n",
    "\n",
    "state = rewrite_query(state)\n",
    "\n",
    "print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1783ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def return_without_docs(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    When the query has nothing to do with clinical topic or retrieval documents are not relevant to the query, \n",
    "    Then return 'sorry...' \n",
    "    \"\"\"\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    apology_sentences = [    \n",
    "        \"We primarily provide medical information, but your question doesn’t appear to be related to health topics, so we can’t offer an answer.\",\n",
    "        \"Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\",\n",
    "        \"Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\",\n",
    "        \"This platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.\",\n",
    "        \"We mainly handle medical or health-related questions, and since your query isn’t in that area, we don’t have suitable content to share.\"\n",
    "    ]\n",
    "\n",
    "    state[\"retrieved_doc\"] = random.choice(apology_sentences)\n",
    "    print(f\"\"\"Master_Agent: {state[\"retrieved_doc\"]}\"\"\")\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57ae3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def return_with_docs(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    When it successfully retrieved relevant documents, \n",
    "    Then return \n",
    "    \"\"\"\n",
    "    print(f\"===Step {settings.STEP}===\\n\")        \n",
    "    print(\"Master_Agent: I am happy to get something you might need!\\n\")\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f10f3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def save_to_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Before End, save user's query and final answer to memory \n",
    "    \"\"\"   \n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"Master_Agent: I am saving the user query and RAG response to memory.\\n\")  \n",
    "    print(f\"\"\"User query: {state[\"query\"]} - RAG response: {state[\"retrieved_doc\"]}\"\"\") \n",
    "    #history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "\n",
    "    settings.SHORT_TERM_MEMORY.add_message(session_id=state[\"session_id\"], message=state[\"query\"], msg_type=\"human\")\n",
    "    settings.SHORT_TERM_MEMORY.add_message(session_id=state[\"session_id\"], message=state[\"retrieved_doc\"], msg_type=\"ai\")\n",
    "    settings.STEP = 1 # Reset the STEP \n",
    "    return state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f4c36dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Retrieve documents by query.\n",
    "    Then grade the relevance.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"Master_Agent: I am seaching documents from RAG.\\n\")  \n",
    "    documents = rag.retrieve(state[\"query\"], top_k=3)\n",
    "    final_documents = [d.page_content for d in documents if d.metadata[\"rerank_score\"] > 0.7]\n",
    "    state[\"retrieved_doc\"] = \". \".join(final_documents)\n",
    "    if len(final_documents) == 0:        \n",
    "        state[\"grade\"] = {\"score\": \"no\"}\n",
    "    else:\n",
    "        state[\"grade\"] = {\"score\": \"yes\"}\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e09fbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_relevant_docs(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it retrieved relevant documents from RAG, go to \"return_with_docs\" node\n",
    "    If it didn't find anything from RAG and Wiki tool has not been used, then go to \"wiki_search\" tool node.\n",
    "    If it didn't find anything from RAG and Wiki, the return sorry.\n",
    "    \"\"\"\n",
    "    if state[\"grade\"][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: I found some documents you may need.\\n\")\n",
    "        return \"return_with_docs\"\n",
    "    elif not state[\"wiki_used\"]:\n",
    "        print(\"Master_Agent: I am sorry I didn't get the relevant document from RAG. I am going to search on wikipedia.\\n\")          \n",
    "        return \"wiki_search\"\n",
    "    elif not state[\"brave_used\"]:\n",
    "        print(\"Master_Agent: I only have last tool to use now..\\n\")          \n",
    "        return \"brave_search\"\n",
    "    else:\n",
    "        print(\"Master_Agent: I am sorry I didn't get any thing from RAG, Brave search and wikipedia.\\n\")         \n",
    "        return \"return_sorry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b1a98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def wiki_search(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Search documents by Wikipedia seach tool.\n",
    "    Then grade the relevance.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"I am seaching documents from Wikipedia.\\n\")  \n",
    "    documents = wiki.invoke({\"query\": state[\"query\"]})\n",
    "    json_list = wiki_to_json(documents)\n",
    "    \n",
    "    # Rank the wiki docs with crossEncoder\n",
    "    pairs = [[state[\"query\"], s[\"Summary\"]] for s in json_list]\n",
    "    scores = rag.cross_encoder.predict(pairs, batch_size=32)\n",
    "    for j_l, score in zip(json_list, scores):\n",
    "        j_l[\"score\"] = float(score)\n",
    "\n",
    "    final_documents = [d[\"Summary\"] for d in json_list if d[\"score\"] > 0.5]\n",
    "    state[\"retrieved_doc\"] = \". \".join(final_documents)\n",
    "    state[\"wiki_used\"] = True # For a good query, only use wiki search once. Avoid infinity loop.\n",
    "    if len(final_documents) == 0:        \n",
    "        state[\"grade\"] = {\"score\": \"no\"}\n",
    "    else:        \n",
    "        state[\"grade\"] = {\"score\": \"yes\"}\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8785fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def brave_search(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Search documents by Brave seach tool.\n",
    "    Then grade the relevance.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"I am seaching documents from Brave search Engine.\\n\")  \n",
    "    \n",
    "    json_list = json.loads(brave.run(state[\"query\"]))\n",
    "    \n",
    "    # Rank the brave docs with crossEncoder\n",
    "    pairs = [[state[\"query\"], d[\"snippet\"]] for d in json_list]\n",
    "    scores = rag.cross_encoder.predict(pairs, batch_size=32)\n",
    "    for j_l, score in zip(json_list, scores):\n",
    "        j_l[\"score\"] = float(score)\n",
    "\n",
    "    final_documents = [d[\"snippet\"] for d in json_list if d[\"score\"] > 0.5]\n",
    "    state[\"retrieved_doc\"] = \". \".join(final_documents)\n",
    "    state[\"brave_used\"] = True # For a good query, only use brave search once. Avoid infinity loop.\n",
    "    if len(final_documents) == 0:        \n",
    "        state[\"grade\"] = {\"score\": \"no\"}\n",
    "    else:        \n",
    "        state[\"grade\"] = {\"score\": \"yes\"}\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aad8f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_entry_relevant(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    No matter what the query looks like. Just retrieve something to see if we can get relevant documents.\n",
    "    This is the most efficient way. \n",
    "    \"\"\"    \n",
    "    if state[\"grade\"][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: I found some documents you may need.\\n\")\n",
    "        return \"return_with_docs\"    \n",
    "    else:               \n",
    "        return \"grade_selfcontained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5297358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph\n",
    "agentic_rag_graph = StateGraph(AgentState)\n",
    "# Add nodes\n",
    "\n",
    "agentic_rag_graph.add_node(\"retrieve_entry_node\", retrieve)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_selfcontained_node\", grade_selfcontained_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_selfcontained_node\", decide_selfcontained_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_history_related_node\", grade_history_related_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_history_related_node\", decide_history_related_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"rewrite_query_node\", rewrite_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_clinical_node\", grade_clinical_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_clinical_node\", decide_clinical_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"retrieve_node\", retrieve)\n",
    "\n",
    "agentic_rag_graph.add_node(\"decide_relevant_router\", lambda state:state) # Transparent\n",
    "\n",
    "agentic_rag_graph.add_node(\"return_sorry_node\", return_without_docs)\n",
    "\n",
    "agentic_rag_graph.add_node(\"return_docs_node\", return_with_docs)\n",
    "\n",
    "agentic_rag_graph.add_node(\"save_node\", save_to_memory)\n",
    "\n",
    "agentic_rag_graph.add_node(\"wiki_search_node\", wiki_search)\n",
    "\n",
    "agentic_rag_graph.add_node(\"brave_search_node\", brave_search)\n",
    "\n",
    "# Add Edges\n",
    "\n",
    "agentic_rag_graph.add_edge(START, \"retrieve_entry_node\")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"retrieve_entry_node\",\n",
    "    path=decide_entry_relevant,\n",
    "    path_map={\n",
    "        \"return_with_docs\": \"return_docs_node\",\n",
    "        \"grade_selfcontained\": \"grade_selfcontained_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_selfcontained_node\",\n",
    "    path=decide_selfcontained_query,\n",
    "    path_map={\n",
    "        \"grade_clinical\": \"grade_clinical_node\",\n",
    "        \"grade_related_history\": \"grade_history_related_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_history_related_node\",\n",
    "    path=decide_history_related_query,\n",
    "    path_map={\n",
    "        \"rewrite\": \"rewrite_query_node\",\n",
    "        \"return_sorry\": \"return_sorry_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_clinical_node\",\n",
    "    path=decide_clinical_query,\n",
    "    path_map={\n",
    "        \"retrieve\": \"retrieve_node\",\n",
    "        \"return_sorry\": \"return_sorry_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"rewrite_query_node\", \"grade_selfcontained_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"retrieve_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"decide_relevant_router\",\n",
    "    path=decide_relevant_docs,\n",
    "    path_map={\n",
    "        \"return_sorry\": \"return_sorry_node\",\n",
    "        \"return_with_docs\": \"return_docs_node\",\n",
    "        \"wiki_search\": \"wiki_search_node\",\n",
    "        \"brave_search\": \"brave_search_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"wiki_search_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"brave_search_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"return_sorry_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"return_docs_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"save_node\", END)\n",
    "\n",
    "app = agentic_rag_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f4925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph\n",
    "agentic_rag_graph = StateGraph(AgentState)\n",
    "# Add nodes\n",
    "\n",
    "agentic_rag_graph.add_node(\"retrieve_entry_node\", retrieve)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_selfcontained_node\", grade_selfcontained_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_selfcontained_node\", decide_selfcontained_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_history_related_node\", grade_history_related_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_history_related_node\", decide_history_related_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"rewrite_query_node\", rewrite_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_clinical_node\", grade_clinical_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_clinical_node\", decide_clinical_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"retrieve_node\", retrieve)\n",
    "\n",
    "agentic_rag_graph.add_node(\"decide_relevant_router\", lambda state:state) # Transparent\n",
    "\n",
    "agentic_rag_graph.add_node(\"return_sorry_node\", return_without_docs)\n",
    "\n",
    "agentic_rag_graph.add_node(\"return_docs_node\", return_with_docs)\n",
    "\n",
    "agentic_rag_graph.add_node(\"save_node\", save_to_memory)\n",
    "\n",
    "agentic_rag_graph.add_node(\"wiki_search_node\", wiki_search)\n",
    "\n",
    "agentic_rag_graph.add_node(\"brave_search_node\", brave_search)\n",
    "\n",
    "# Add Edges\n",
    "\n",
    "agentic_rag_graph.add_edge(START, \"grade_selfcontained_node\")\n",
    "\n",
    "# agentic_rag_graph.add_conditional_edges(\n",
    "#     source=\"retrieve_entry_node\",\n",
    "#     path=decide_entry_relevant,\n",
    "#     path_map={\n",
    "#         \"return_with_docs\": \"return_docs_node\",\n",
    "#         \"grade_selfcontained\": \"grade_selfcontained_node\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_selfcontained_node\",\n",
    "    path=decide_selfcontained_query,\n",
    "    path_map={\n",
    "        \"grade_clinical\": \"grade_clinical_node\",\n",
    "        \"grade_related_history\": \"grade_history_related_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_history_related_node\",\n",
    "    path=decide_history_related_query,\n",
    "    path_map={\n",
    "        \"rewrite\": \"rewrite_query_node\",\n",
    "        \"return_sorry\": \"return_sorry_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_clinical_node\",\n",
    "    path=decide_clinical_query,\n",
    "    path_map={\n",
    "        \"retrieve\": \"retrieve_node\",\n",
    "        \"return_sorry\": \"return_sorry_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"rewrite_query_node\", \"grade_selfcontained_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"retrieve_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"decide_relevant_router\",\n",
    "    path=decide_relevant_docs,\n",
    "    path_map={\n",
    "        \"return_sorry\": \"return_sorry_node\",\n",
    "        \"return_with_docs\": \"return_docs_node\",\n",
    "        \"wiki_search\": \"wiki_search_node\",\n",
    "        \"brave_search\": \"brave_search_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"wiki_search_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"brave_search_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"return_sorry_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"return_docs_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"save_node\", END)\n",
    "\n",
    "app = agentic_rag_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6e93b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 15===\n",
      "\n",
      "Master_Agent: Got a new query: \"hi there\"\n",
      "I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 16===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. \n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "===Step 17===\n",
      "\n",
      "Master_Agent: Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\n",
      "===Step 18===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: hi there - RAG response: Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\n",
      "result:{'session_id': 1, 'query': 'hi there', 'retrieved_doc': 'Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n"
     ]
    }
   ],
   "source": [
    "questions = [    \n",
    "    \"Is there anything I can assist you with?\",    \n",
    "    \"Can I help you in any way, next?\",\n",
    "    \"Do you have any questions about this?\",  \n",
    "    \"Are you looking for any particular information?\",\n",
    "    \"Do you want me to go over anything again?\",\n",
    "    \"What more information do you want?\"    \n",
    "]\n",
    "\n",
    "user_input = input(\"I am a Medicine Agentic RAG. I can help you get medical and clinical documents. Just tell me what you need?\")\n",
    "\n",
    "while user_input.strip().lower() not in [\"end\", \"exit\"]:\n",
    "    query = AgentState(query=user_input, session_id=1,wiki_used=False,brave_used=False,rewrite_counter=0)\n",
    "    result = app.invoke(query)\n",
    "    print(f\"result:{result}\")\n",
    "    user_input = input(random.choice(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94cd98d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve starts runing!\n",
      "retrieve took 0.6238s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '5bd24645-22f3-4cf1-9259-20e0e36463b6', 'rerank_score': 0.9990140199661255}, page_content='zafirlukast may cause side effects. tell your doctor if this symptom is severe or does not go away.headachesome side effects can be serious. if you experience any of the following symptoms or those listed in the special precautions section, call your doctor immediately.nausealoss of appetitepain in the right upper part of your stomachexcessive tirednesslack of energyitchingyellowing of the skin or eyesflu-like symptomsrashswelling of the eyes, face, lips, tongue, or throatdifficulty breathing or swallowinghoarsenesspain, burning, numbness, or tingling in the hands or feetzafirlukast may cause other side effects. call your doctor if you have any unusual problems while you are taking Zafirlukast.'),\n",
       " Document(metadata={'doc_id': '41bc9ae2-840e-43b4-9653-b7b188b1c1e9', 'rerank_score': 0.9987200498580933}, page_content='drinking or eating foods high in caffeine, like coffee, tea, cocoa, and chocolate, may increase the side effects caused by theophylline. avoid large amounts of these substances while you are taking theophylline.about Theophylline'),\n",
       " Document(metadata={'doc_id': '12fbe386-cf77-427c-8eaa-8f04f0b65720', 'rerank_score': 0.9210190176963806}, page_content=\"before taking theophylline,tell your doctor and pharmacist if you are allergic to theophylline, any other medications, or any of the ingredients in theophylline preparations. ask your pharmacist for a list of the ingredients.tell your doctor and pharmacist what prescription medications you are taking, especially allopurinol (zyloprim), azithromycin (zithromax), carbamazepine (tegretol), cimetidine (tagamet), ciprofloxacin (cipro), clarithromycin (biaxin), diuretics ('water pills'), erythromycin, lithium (eskalith, lithobid), oral contraceptives, phenytoin (dilantin), prednisone (deltasone), propranolol (inderal), rifampin (rifadin), tetracycline (sumycin), and other medications for infections or heart disease.tell your doctor and pharmacist what prescription, nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take while taking theophylline.  your doctor may need to change the doses of your medications or monitor you carefully for side effects.the following nonprescription or herbal products may interact with theophylline: cimetidine (tagamet); ephedrine; pseudoephedrine; st. john's wort. be sure to let your doctor and pharmacist know that you are taking these medications before you start taking theophylline. do not start any of these medications while taking theophylline without discussing with your healthcare provider.tell your doctor if you have or have ever had seizures, ulcers, heart disease, an overactive or underactive thyroid gland, high blood pressure, or liver disease or if you have a history of alcohol abuse.tell your doctor if you are pregnant, plan to become pregnant, or are breast-feeding. if you become pregnant while taking theophylline, call your doctor.tell your doctor if you use tobacco products. cigarette smoking may decrease the effectiveness of theophylline.about Theophylline\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.retrieve(\"any side effect?\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
