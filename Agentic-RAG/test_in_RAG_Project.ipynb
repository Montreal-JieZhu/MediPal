{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5fc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7432723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4f2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['name', 'user_input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='You are a helpful AI bot. Your name is {name}.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, how are you doing?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"I'm doing well, thanks!\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], input_types={}, partial_variables={}, template='{user_input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f2d335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6fef7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful AI bot. Your name is \u001b[33;1m\u001b[1;3m{name}\u001b[0m.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, how are you doing?\n",
      "\n",
      "==================================\u001b[1m AI Message \u001b[0m==================================\n",
      "\n",
      "I'm doing well, thanks!\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{user_input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "template2.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328591f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = template.invoke(\n",
    "    {\"name\": \"Bob\", \"user_input\": \"What is your name?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d40e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cdefb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot.\"),\n",
    "        # Means the template will receive an optional list of messages under\n",
    "        # the \"conversation\" key\n",
    "        (\"placeholder\", \"{conversation}\"),\n",
    "        # Equivalently:\n",
    "        # MessagesPlaceholder(variable_name=\"conversation\", optional=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"conversation\": [\n",
    "            (\"human\", \"Hi!\"),\n",
    "            (\"ai\", \"How can I assist you today?\"),\n",
    "            (\"human\", \"Can you make me an ice cream sundae?\"),\n",
    "            (\"ai\", \"No.\"),\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07986812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful AI bot.\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{conversation}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "template.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785aae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b7a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = template.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c49ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "async def reverse(s: str) -> str:\n",
    "    return s[::-1]\n",
    "\n",
    "\n",
    "chain = RunnableLambda(func=reverse)\n",
    "\n",
    "events = [\n",
    "    event async for event in chain.astream_events(\"hello\", version=\"v2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "502a4427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'run_id': '8af127dd-9475-4019-aeb6-a18ea9a5a671',\n",
       "  'metadata': {},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chain_stream',\n",
       "  'run_id': '8af127dd-9475-4019-aeb6-a18ea9a5a671',\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'data': {'chunk': 'olleh'},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chain_end',\n",
       "  'data': {'output': 'olleh'},\n",
       "  'run_id': '8af127dd-9475-4019-aeb6-a18ea9a5a671',\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71023e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': 'some_input1'}, 'name': 'slow_thing', 'tags': [], 'run_id': '650bde20-d344-43ea-b673-d63471c07b6b', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_custom_event', 'run_id': '650bde20-d344-43ea-b673-d63471c07b6b', 'name': 'progress_event', 'tags': [], 'metadata': {}, 'data': {'message': 'Finished step 1 of 3'}, 'parent_ids': []}\n",
      "{'event': 'on_custom_event', 'run_id': '650bde20-d344-43ea-b673-d63471c07b6b', 'name': 'progress_event', 'tags': [], 'metadata': {}, 'data': {'message': 'Finished step 2 of 3'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_stream', 'run_id': '650bde20-d344-43ea-b673-d63471c07b6b', 'name': 'slow_thing', 'tags': [], 'metadata': {}, 'data': {'chunk': 'Done'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'Done'}, 'run_id': '650bde20-d344-43ea-b673-d63471c07b6b', 'name': 'slow_thing', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.callbacks.manager import (\n",
    "    adispatch_custom_event,\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def slow_thing(some_input: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Do something that takes a long time.\"\"\"\n",
    "    await asyncio.sleep(1) # Placeholder for some slow operation\n",
    "    await adispatch_custom_event(\n",
    "        \"progress_event\",\n",
    "        {\"message\": \"Finished step 1 of 3\"},\n",
    "        config=config # Must be included for python < 3.10\n",
    "    )\n",
    "    await asyncio.sleep(1) # Placeholder for some slow operation\n",
    "    await adispatch_custom_event(\n",
    "        \"progress_event\",\n",
    "        {\"message\": \"Finished step 2 of 3\"},\n",
    "        config=config # Must be included for python < 3.10\n",
    "    )\n",
    "    await asyncio.sleep(1) # Placeholder for some slow operation\n",
    "    return \"Done\"\n",
    "\n",
    "slow_thing1 = RunnableLambda(slow_thing)\n",
    "\n",
    "async for event in slow_thing1.astream_events(\"some_input1\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e3ae64c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_ollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[32m      4\u001b[39m llm = ChatOllama(model=\u001b[33m\"\u001b[39m\u001b[33mllama2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_ollama'"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(model=\"llama2\")\n",
    "\n",
    "# Without bind.\n",
    "chain = llm | StrOutputParser()\n",
    "\n",
    "chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
    "# Output is 'One two three four five.'\n",
    "\n",
    "# With bind.\n",
    "chain = llm.bind(stop=[\"three\"]) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db4d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
