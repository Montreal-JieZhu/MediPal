{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783a234e",
   "metadata": {},
   "source": [
    "### In this section, I will build an Agentic RAG\n",
    "\n",
    "Now I have a Rerank RAG which can retrieve relevant medicine documents based on the query.\n",
    "\n",
    "But why I need an **Agentic RAG**?\n",
    "\n",
    "Becuase Rerank RAG can only similarity search documents by query. If the query contains no relevant information linked to the documents in vector database, it is not able to retrieve relevant docs.\n",
    "\n",
    "I describe some real-life scenarios we can have below:\n",
    "\n",
    "### Problem description:\n",
    "\n",
    "In real conversation, users can ask anything we can not predict ahead. \n",
    "\n",
    "For example:\n",
    "In the third turn the user really want to ask 'How do I take Phenylephrine?'\n",
    "\n",
    "But he types 'How do I take it?'. From the context, 'it' means 'Phenylephrine'.\n",
    "\n",
    "If we retrieve documents by query 'How do I take it?', we can get unrelevant document.  'How do I take Phenylephrine?' makes more sense.\n",
    "\n",
    "Other scenarios:\n",
    "\n",
    "1. In first turn, a user just greet without any question.\n",
    "2. User ask a random question in the middle of conversation.\n",
    "3. .........\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "The root problem is how to determine whether a query is a clinial/medical query and whether a query is related previous conversation.\n",
    "\n",
    "### Solution:\n",
    "\n",
    "#### To handle all those, I will put a local LLM as a master agent to determine what to do next based on different situation.\n",
    "#### So I will involve Basic RAG, langgraph, memory, local LLM, wiki search tool... working together to make the RAG can retrieve real relevant documents by itself.\n",
    "\n",
    "### Implementation:\n",
    "\n",
    "* I will involve an agent to decide what to do next based on the query and history conversation. \n",
    "* Then, the agent will execute the task and observe the result to decide again..... until get a proper result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac03e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own libraries\n",
    "from mytools import best_dtype, best_device, login_huggingface\n",
    "from rerank_rag import Rerank_RAG\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import settings\n",
    "\n",
    "from typing import TypedDict, Any, Dict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory # Short-term Memory\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain_community.tools import WikipediaQueryRun, BraveSearch\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9626d",
   "metadata": {},
   "source": [
    "#### As I mentioned previously:\n",
    "\n",
    "Bio-Medical-Llama-3-8B model is a specialized large language model designed for biomedical applications. It is finetuned from the meta-llama/Meta-Llama-3-8B-Instruct model using a custom dataset containing over 500,000 diverse entries. These entries include a mix of synthetic and manually curated data, ensuring high quality and broad coverage of biomedical topics.\n",
    "\n",
    "The model is trained to understand and generate text related to various biomedical fields, making it a valuable tool for researchers, clinicians, and other professionals in the biomedical domain.\n",
    "\n",
    "@misc{ContactDoctor_Bio-Medical-Llama-3-8B, author = ContactDoctor, title = {ContactDoctor-Bio-Medical: A High-Performance Biomedical Language Model}, year = {2024}, howpublished = {https://huggingface.co/ContactDoctor/Bio-Medical-Llama-3-8B}, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8cdc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
    "\n",
    "#model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195419ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login HuggingFace!\n"
     ]
    }
   ],
   "source": [
    "login_huggingface() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78220075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fcfcfe146143b6913fe79eb4701854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenizer and base model done!\n"
     ]
    }
   ],
   "source": [
    "# Load a HuggingFace model. Inference it from local GPU.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    dtype = best_dtype(),\n",
    "    device_map={\"\":best_device()},     \n",
    "    low_cpu_mem_usage=True     \n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Load tokenizer and base model done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3ff620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n",
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)                    # full architecture tree (long but useful)\n",
    "print(model.config)             # core hyperparameters (dims, layers, heads…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da7c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "original_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,  \n",
    "    temperature=0.1,  \n",
    "    return_full_text=False,   \n",
    ")\n",
    "\n",
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipeline = HuggingFacePipeline(pipeline=original_pipeline)\n",
    "\n",
    "master_llm = ChatHuggingFace(llm=hug_pipeline) # It is the brain of the whole system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c8317",
   "metadata": {},
   "source": [
    "### Master LLM is ready. Next RAG...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3662b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_retriever starts runing!\n",
      "Login HuggingFace!\n",
      "load_embedding_model starts runing!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d0b4aeccfc49dfb5479f7c803a4da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/604 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fdc3115487461085a4c0ec6740abb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/976 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 5.2.0.dev0, but you're currently using version 5.1.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4532ce2251394540b9b8f58c02cd781d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6685a82ed27e45939a85e2cd20b93917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1814044e4dc044f0992fe2cff1dd6dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157882273a6a4c2ba81efc124347d7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c143c6b19b374069a621622bed267ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc0e4bb5903472996d9a2babc6b6a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c0b3206fde44ceb9d2f5f425b89cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb0fadb219e40e286f6304be5e627e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/38.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0040af7e8b49d9b65c0fccaa2073a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba7e1d9a3944eb8b7ee8e69621e8ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0fd882530a44f4a84a7f9987fe150a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/139 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c551b815204c3ebcb8ef3f70858b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9214a973e176483eb5ba2fb51e956396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/139 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af181239536546c49247c1bec443de9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_embedding_model took 11.3097s\n",
      "load_crossencoder starts runing!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4053cbfec0d74ff4a2af06a5f8581f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6433ef88ed3b43f4b767ada3367e83c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba83cbe05e4246418f91912ac62066aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03902d34c93246338ad028506b3915eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1dfb9e66454e18ac3e2808c464b097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993e32c21aee464884b66d56cfeea82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b14b852bc0e40a4ad3846875fa6a3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e65e75eeca49dcab941bf87f979dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb2f456827e4743a9c8e730d65ea232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_crossencoder took 6.3115s\n",
      "setup_retriever took 27.2687s\n"
     ]
    }
   ],
   "source": [
    "rag = Rerank_RAG()\n",
    "rag.setup_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4628ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b417c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "brave_api_key = os.getenv(\"BRAVE_SEARCH_KEY\")\n",
    "brave = BraveSearch.from_api_key(api_key=brave_api_key, search_kwargs={\"count\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e85d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a short-term memory\n",
    "\n",
    "class Short_Term_Memory():\n",
    "    def __init__(self) -> None: \n",
    "        \"\"\"Initialize the message container and current session id \"\"\"       \n",
    "        self.session_store: dict[int,BaseChatMessageHistory] = {}\n",
    "        self.current_session_id: int = 0\n",
    "\n",
    "    def get_history(self, session_id: int) -> BaseChatMessageHistory:    \n",
    "        \"\"\"return history messages by sessionId\"\"\"    \n",
    "        self.current_session_id = session_id\n",
    "        if session_id not in self.session_store:\n",
    "            self.session_store[session_id] = ChatMessageHistory()\n",
    "        return self.session_store[session_id]\n",
    "    \n",
    "    def get_current_history(self) -> BaseChatMessageHistory:\n",
    "        \"\"\"return history messages for current session\"\"\"\n",
    "        return self.get_history(self.current_session_id)\n",
    "    \n",
    "    def add_message(self, session_id: int, message: str, msg_type: str) -> None:\n",
    "        history_messages = self.get_history(session_id)     \n",
    "        if msg_type == \"ai\": \n",
    "            history_messages.add_ai_message(message)\n",
    "        else:\n",
    "            history_messages.add_user_message(message)   \n",
    "\n",
    "        if len(history_messages.messages) > 2: # Only keep the recent 2 messages\n",
    "            del history_messages.messages[0] # Remove the first message     \n",
    "            \n",
    "    \n",
    "    def delete_history(self, session_id: int) -> bool:\n",
    "        \"\"\"delete history messages by sessionId\"\"\"\n",
    "        if session_id in self.session_store:\n",
    "            deleted = self.session_store.pop(session_id)\n",
    "            if deleted:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def delete_current_history(self) -> bool:\n",
    "        \"\"\"delete history messages for current session\"\"\"\n",
    "        return self.delete_history(self.current_session_id)\n",
    "    \n",
    "# Convert a history chat message to a string\n",
    "def history_as_text(history: BaseChatMessageHistory) -> str:\n",
    "    \"\"\"convert history messsages into a string\"\"\"\n",
    "    return \"\\n\".join([\n",
    "        f\"{m.type.upper()}: {m.content[:200]}\"   # e.g. \"HUMAN: …\" or \"Master_Agent: …\"\n",
    "        for m in history.messages[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8205392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the graph.\n",
    "\n",
    "    Attributes:\n",
    "        session_id: current session id\n",
    "        query: user's query or augmented query\n",
    "        retrieved_doc: retrieval docment\n",
    "        generation: the answer the llm generate    \n",
    "        grade: keep the binary score for every router node to make decision   \n",
    "        wiki_used: Flag whether it already used Wiki search\n",
    "        brave_used: Flag whether it already used brave search\n",
    "        rewrite_counter: count rewrite action, maximum 3 times.\n",
    "    \"\"\"\n",
    "    session_id: int\n",
    "    query: str\n",
    "    retrieved_doc: str\n",
    "    generation: str\n",
    "    grade: dict\n",
    "    wiki_used: bool      # Avoid infinity loop in graph\n",
    "    brave_used: bool     # Avoid infinity loop in graph\n",
    "    rewrite_counter: int # Avoid infinity loop in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "50cf13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a global short-term memory for all users\n",
    "settings.SHORT_TERM_MEMORY = Short_Term_Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daa7445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test function\n",
    "\n",
    "def unit_test(action_func, decide_function):\n",
    "    questions = [\n",
    "        \"Why doesn't my friend play tennis with me?\",\n",
    "        \"What is the tallest mountain in South America?\",        \n",
    "        \"Can you explain how blockchain technology works?\",\n",
    "        \"It is not a good idea.\"      \n",
    "        \"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\",        \n",
    "        \"How can I take it?\",\n",
    "        \"Which symptoms usually appear first in a case of seasonal influenza?\",        \n",
    "        \"what do you recommend?\",\n",
    "        \"What are the warning signs of a severe allergic reaction?\",\n",
    "        \"The project is reaching the deadline.\"       \n",
    "    ]\n",
    "\n",
    "    session_id = 1\n",
    "    settings.STEP = 1\n",
    "\n",
    "    for query in questions:\n",
    "        state = AgentState(session_id=session_id,query=query,wiki_used=False,brave_used=False,rewrite_counter=0)\n",
    "        state = action_func(state)\n",
    "        result = decide_function(state)\n",
    "        print(f\"Decision: {result} \\n\")\n",
    "        print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5ac26",
   "metadata": {},
   "source": [
    "#### Local and small LLMs usually has no robust structured output. So I have to prepare for all possible results it might output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b1fceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_score(text: str) -> str:\n",
    "    \"\"\"Force 'yes'/'no' from messy text.\"\"\"\n",
    "    t = text.strip().lower()\n",
    "    if t in {\"yes\", \"y\", \"true\",\"ok\", \"1\"}:\n",
    "        return \"yes\"\n",
    "    if t in {\"no\", \"n\", \"false\", \"0\"}:\n",
    "        return \"no\"\n",
    "    # heuristics: ambiguous/under-specified → \"no\"\n",
    "    return \"no\"\n",
    "\n",
    "\n",
    "def _extract_json_like(s: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Try hard to find {\"score\": \"...\"} inside messy output.\n",
    "    \"\"\"\n",
    "    # 1) quick regex for a minimal JSON object with score\n",
    "    m = re.search(r'\\{[^{}]*\"score\"\\s*:\\s*\"(?P<score>yes|no|true|false)\"[^{}]*\\}', s, flags=re.I)\n",
    "    if m:\n",
    "        return {\"score\": _normalize_score(m.group(\"score\"))}\n",
    "\n",
    "    # 2) fall back: if the model just said \"yes\"/\"no\" without JSON\n",
    "    yn = re.search(r'\\b(yes|no|true|false)\\b', s, flags=re.I)\n",
    "    if yn:\n",
    "        return {\"score\": _normalize_score(yn.group(1))}\n",
    "\n",
    "    # 3) last resort default\n",
    "    return {\"score\": \"no\"}\n",
    "\n",
    "def robust_binary_grader(prompt: PromptTemplate, query: str, document: str = \"\") ->dict:\n",
    "    \"\"\" \n",
    "    Make sure robustly parse the grade result of Local LLM \n",
    "    \"\"\"\n",
    "    # Base parser (strict JSON with a single key)\n",
    "    base_parser = JsonOutputParser(pydantic_object=None, json_kwargs={\"strict\": False})\n",
    "    # Auto-fixing parser: if model outputs invalid JSON, it asks the LLM to repair\n",
    "    fixing_parser = OutputFixingParser.from_llm(parser=base_parser, llm=master_llm)\n",
    "       # Lower temperature for determinism\n",
    "    chain = prompt | master_llm | fixing_parser\n",
    "    result = None\n",
    "    try:\n",
    "        # First attempt: LLM → (auto-fixing) parser\n",
    "        if document == \"\":\n",
    "            result = chain.invoke({\"question\": query})  \n",
    "        else:\n",
    "            result = chain.invoke({\"question\": query, \"document\": document})\n",
    "        print(f\"Real output: {result}\\n\")        \n",
    "        # result may already be a dict (from parser), but be defensive:\n",
    "        if isinstance(result, dict) and \"score\" in result:\n",
    "            score = _normalize_score(str(result[\"score\"]))\n",
    "            return {\"score\": score}  # exact contract            \n",
    "\n",
    "        # If parser returned a string (some models), try to json-load or extract\n",
    "        if isinstance(result, str):\n",
    "            try:\n",
    "                json_obj = _extract_json_like(result)\n",
    "                score = _normalize_score(str(json_obj.get(\"score\", \"\")))\n",
    "                return {\"score\": score}                \n",
    "            except Exception:\n",
    "                pass\n",
    "        # Fall through to the worst baseline\n",
    "        if any(r in str(result).lower() for r in [\"yes\", \"true\"]):\n",
    "            return {\"score\": \"yes\"}\n",
    "        else:\n",
    "            return {\"score\": \"no\"}       \n",
    "\n",
    "    except Exception as e:\n",
    "        # Hard fallback path if LLM/parse fails entirely\n",
    "        print(f\"[grade_selfcontained_query] Warning: parse failed: {e} \\n\") \n",
    "\n",
    "        return {\"score\": \"no\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab4df7",
   "metadata": {},
   "source": [
    "#### Local LLMs usually output things without control. So I have to handle with all possible results it might output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "756510fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_one_line_question(text: str, fallback: str, max_len: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Make whatever the LLM returned into a clean single-line question.\n",
    "    - strip code fences, quotes, labels\n",
    "    - collapse whitespace\n",
    "    - take the first question-looking sentence if multiple\n",
    "    - ensure it ends with '?'\n",
    "    - length-limit (soft)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text or \"\")\n",
    "\n",
    "    t = text.strip()\n",
    "\n",
    "    # remove common code fences or labels\n",
    "    t = re.sub(r\"^`{3,}.*?\\n|\\n`{3,}$\", \"\", t, flags=re.S)        # ```...```\n",
    "    t = re.sub(r\"^(re.?written|improved|final|answer)\\s*:\\s*\", \"\", t, flags=re.I)\n",
    "    t = re.sub(r\"^\\\"|\\\"$\", \"\", t)  # trim surrounding quotes\n",
    "    t = re.sub(r\"^'+|'+$\", \"\", t)  # trim surrounding single quotes\n",
    "\n",
    "    # collapse to one line\n",
    "    t = \" \".join(t.split())\n",
    "\n",
    "    # If LLM returned multiple sentences, try to pick the first question-like sentence.\n",
    "    # Prefer the first chunk that ends with '?'\n",
    "    m = re.search(r\"([^?]{3,}\\?)\", t)\n",
    "    if m:\n",
    "        t = m.group(1).strip()\n",
    "\n",
    "    # If still no question mark, try to cut at a sentence boundary and add '?'\n",
    "    if \"?\" not in t:\n",
    "        # take up to first period/exclamation if present, else keep entire\n",
    "        m2 = re.split(r\"[.!]\", t, maxsplit=1)\n",
    "        candidate = m2[0].strip()\n",
    "        # guard against empty\n",
    "        if len(candidate) >= 3:\n",
    "            t = candidate\n",
    "        if not t.endswith(\"?\"):\n",
    "            t = t.rstrip(\"?\") + \"?\"\n",
    "\n",
    "    # truncate softly (avoid cutting mid-word)\n",
    "    if len(t) > max_len:\n",
    "        t = t[:max_len].rsplit(\" \", 1)[0].rstrip(\"?,.;:! \") + \"?\"\n",
    "\n",
    "    # last resort fallback\n",
    "    if len(t) < 3:\n",
    "        t = fallback.strip()\n",
    "        if not t.endswith(\"?\"):\n",
    "            t += \"?\"\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def robust_question_generater(prompt: PromptTemplate, query: str, document: str = \"\") -> str:\n",
    "    \"\"\" \n",
    "    Make sure robustly extract the question Local LLM generates.\n",
    "    \"\"\"\n",
    "    chain = prompt | master_llm | StrOutputParser()\n",
    "    try:\n",
    "        raw = chain.invoke({\"question\": query, \"document\": document})\n",
    "        print(f\"Real output: {raw}\\n\")\n",
    "        result = _clean_one_line_question(raw, fallback=query, max_len=200)\n",
    "        return result\n",
    "    except Exception:\n",
    "        # hard fallback: if model call fails, return original as a question\n",
    "        return query if query.endswith(\"?\") else (query + \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00c5566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action node\n",
    "def answer_generater(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Generate answer based on the retrieval documents.\n",
    "    \"\"\"\n",
    "\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    document = state[\"retrieved_doc\"]\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an assistant that answers questions **only** using the retrieved documents.\n",
    "\n",
    "        ## Instructions\n",
    "        - Read the provided documents carefully.\n",
    "        - Answer the user query **strictly grounded in the documents**.  \n",
    "        - If the documents do not contain enough information, reply with:\n",
    "        \"I'm sorry, the provided documents do not contain enough information to answer this question.\"\n",
    "        - Do NOT add any outside knowledge or assumptions.\n",
    "\n",
    "        ## Inputs\n",
    "        Retrieved Documents:\n",
    "        {document}\n",
    "\n",
    "        User Query:\n",
    "        {question}\n",
    "\n",
    "        ## Output\n",
    "        Provide a concise, plain-English answer based solely on the retrieved documents.\n",
    "        \"\"\",\n",
    "        input_variables=[\"document\", \"question\"],\n",
    "    )\n",
    "    chain = prompt | master_llm | StrOutputParser()   \n",
    "\n",
    "    raw = chain.invoke({\"question\": query, \"document\": document})\n",
    "    print(f\"Real output: {raw}\\n\")        \n",
    "    state[\"generation\"] = str(raw)\n",
    "    return state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0200765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_to_json(s: str):\n",
    "    \"\"\" \n",
    "    convert the docs from Wikipedia into a list of json objects\n",
    "    \"\"\"\n",
    "    records = [r.strip() for r in s.strip().split(\"\\n\\n\") if r.strip()]\n",
    "\n",
    "    data = []\n",
    "    for record in records:\n",
    "        page_match = re.search(r\"Page:\\s*(.+)\", record)\n",
    "        summary_match = re.search(r\"Summary:\\s*(.+)\", record, re.DOTALL)\n",
    "        if page_match and summary_match:\n",
    "            data.append({\n",
    "                \"Page\": page_match.group(1).strip(),\n",
    "                \"Summary\": summary_match.group(1).strip()\n",
    "            })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_greeting_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is pure greeting.\n",
    "    without relying on prior conversation context.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"\"\"Master_Agent: Got a new query: \"{query}\"\\nI will check if the query is pure greeting.\\n\"\"\")     \n",
    "   \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "    You are a classifier that checks if a message is a **pure greeting**.\n",
    "\n",
    "    Definition of pure greeting:\n",
    "    - A short message whose sole purpose is to greet or say hello.\n",
    "    - It may include polite questions or phrases like “How are you?”, “What’s up?”, \n",
    "    “Good to meet you”, “Nice to see you”, “How’s it going?”, etc.\n",
    "    - It must NOT contain any request for information, task instructions, or other content.\n",
    "\n",
    "    Your task:\n",
    "    Given the user's input below, decide if it is a pure greeting.\n",
    "\n",
    "    User input: {question}\n",
    "\n",
    "    Return only a JSON object with a single key \"score\":\n",
    "    - Output {{\"score\": \"yes\"}} if it is a pure greeting (even if it looks like a casual question such as “What’s up?”).\n",
    "    - Output {{\"score\": \"no\"}} if it contains anything beyond a greeting.\n",
    "\n",
    "    Do not add explanation or extra text.\n",
    "    \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d05d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_greeting_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it's a greeting query, go to grader node for clinical checking.\n",
    "    If it's not a greeting query, go to grader node for self-contained checking. \n",
    "    \"\"\"\n",
    "    if state['grade'][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: The query is just greeting. Greeting back.\\n\")\n",
    "        return \"greeting\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not greeting. Let's check if it is self-contained one. \\n\")\n",
    "        return \"grade_selfcontained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def greeting_back(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Greeting back    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")    \n",
    "     \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a polite greeter.\n",
    "        When the user sends any message, you must ONLY greet them back in a friendly, natural way.\n",
    "        Do NOT answer questions, give information, or add any extra content.\n",
    "        Keep the reply short (one or two greeting sentences) and nothing else.\n",
    "\n",
    "        User message: {message}\n",
    "        Your entire reply must be ONLY the greeting, for example \"Hello!\" or \"Hi, good morning!\".\n",
    "        \"\"\",\n",
    "        input_variables=[\"message\"],\n",
    "    )\n",
    "    chain = prompt | master_llm | StrOutputParser()    \n",
    "    raw = chain.invoke({\"message\": query})\n",
    "    print(f\"Real output: {raw}\\n\")      \n",
    "    state[\"generation\"] = str(raw)\n",
    "    state[\"retrieved_doc\"] = \"\"\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "350b423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_selfcontained_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is meaningful, clear, and self-contained\n",
    "    without relying on prior conversation context.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"\"\"Master_Agent: I will check if the query is self-contained.\\n\"\"\")  \n",
    "     \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader for a question.\n",
    "    You must decide whether the question is self-contained—meaning that it is clear, meaningful, and understandable on its own, without any conversation history or external context.\n",
    "    Here is the user's question: {question} \\n\n",
    "    Return a binary judgment as a JSON object with a single key \"score\".\n",
    "    Respond only with {{\"score\": \"yes\"}} if the question is self-contained,\n",
    "    or {{\"score\": \"no\"}} if it is not. Do not include any explanation or extra text.\"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c3ee96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_selfcontained_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it's a self-contained query, go to grader node for clinical checking.\n",
    "    If it's not a self-contained query, go to grader node for history related checking. \n",
    "    \"\"\"\n",
    "    if state['grade'][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\\n\")\n",
    "        return \"grade_clinical\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \\n\")\n",
    "        return \"grade_related_history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0898b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 1===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': \"Why doesn't my friend play tennis with me?\", 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What is the tallest mountain in South America?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Can you explain how blockchain technology works?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'It is not a good idea.My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "Decision: grade_related_history \n",
      "\n",
      "State: {'session_id': 1, 'query': 'How can I take it?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Which symptoms usually appear first in a case of seasonal influenza?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 7===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'what do you recommend?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 8===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What are the warning signs of a severe allergic reaction?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 9===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "Decision: grade_clinical \n",
      "\n",
      "State: {'session_id': 1, 'query': 'The project is reaching the deadline.', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unit_test(grade_selfcontained_query, decide_selfcontained_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66633d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_clinical_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is about medicine, clinical questions\n",
    "    without relying on prior conversation context.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"I am checking if the query is about medicine or clinical questions.\\n\")     \n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader for a user message.\n",
    "    Decide whether the message is about a medical or health-related topic.\n",
    "\n",
    "    Consider it **medical** if it involves ANY of the following:\n",
    "    - Symptoms, illnesses, injuries, or physical/mental discomfort (e.g., “I have a headache”, “I feel anxious”)\n",
    "    - Diagnosis, treatment, medications, dosage, side effects, or drug interactions\n",
    "    - Tests, lab results, medical procedures, surgeries\n",
    "    - Preventive care, pregnancy/breastfeeding guidance, vaccination\n",
    "    - Psychological or mental-health issues, therapy, counseling\n",
    "    - Any advice, risk assessment, or triage about human or animal health\n",
    "\n",
    "    Consider it **non-medical** if it is about:\n",
    "    - Pure biology or academic science without personal health context\n",
    "    - Health-related news/trivia without asking for medical guidance\n",
    "    - Insurance, scheduling, or administrative tasks\n",
    "    - Completely unrelated topics\n",
    "\n",
    "    User message:\n",
    "    {question}\n",
    "\n",
    "    Return only a JSON object with a single key \"score\":\n",
    "    - {{\"score\": \"yes\"}} if it is medical/clinical/health-related\n",
    "    - {{\"score\": \"no\"}} if it is not\n",
    "\n",
    "    Do not add any explanation or extra text.\"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab03ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_clinical_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it is a clinical query and self-contained, go to retrieve node directly.\n",
    "    If it is not a clinical query at all, go to return_sorry node.\n",
    "    \"\"\"\n",
    "    if state['grade'][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: The query is a clinical one. We can retrive some documents now.\\n\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not clinical query. I have nothing to do with it. \\n\")\n",
    "        return \"return_sorry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27d3e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 1===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': \"Why doesn't my friend play tennis with me?\", 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What is the tallest mountain in South America?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Can you explain how blockchain technology works?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 4===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'It is not a good idea.My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 5===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'How can I take it?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 6===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'Which symptoms usually appear first in a case of seasonal influenza?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 7===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'what do you recommend?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n",
      "===Step 8===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "Decision: retrieve \n",
      "\n",
      "State: {'session_id': 1, 'query': 'What are the warning signs of a severe allergic reaction?', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 9===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': 'The project is reaching the deadline.', 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unit_test(grade_clinical_query, decide_clinical_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "44e45ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def grade_history_related_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is related to history conversations.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "    history_conversation = history_as_text(history)\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"Master_Agent: I am checking if the query is related to history conversations. \\n\")   \n",
    "    print(f\"history conversations: {history_conversation} \\n\")   \n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a conversation coherence grader.\n",
    "        Your task is to decide whether the user's latest message is logically and topically connected to the previous conversation.\n",
    "\n",
    "        Conversation history:\n",
    "        {document}\n",
    "\n",
    "        User's latest message:\n",
    "        {question}\n",
    "\n",
    "        Return only a JSON object with a single key \"score\":\n",
    "        - {{\"score\": \"yes\"}} if the latest message is coherent and contextually related to the conversation history.\n",
    "        - {{\"score\": \"no\"}} if it is not related or breaks the context.\n",
    "\n",
    "        No explanation or extra text.\"\"\",\n",
    "        input_variables=[\"document\", \"question\"],\n",
    "    )    \n",
    "\n",
    "    state[\"grade\"] = robust_binary_grader(prompt=prompt, query=query, document=history_conversation)\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e457e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_history_related_query(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If the query is related to the history conversation, but it is not self-contained. Go to rewrite node to augment the query.\n",
    "    If the query is not related to the history. Go to \"return_sorry\" node.\n",
    "    \"\"\"    \n",
    "    if state['grade'][\"score\"] == \"yes\" and state[\"rewrite_counter\"] < 3:\n",
    "        print(f\"Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\\n\")\n",
    "        return \"rewrite\"\n",
    "    else:\n",
    "        print(f\"Master_Agent: The query is not related to the history. So it is a random query. \\n\")\n",
    "        return \"return_sorry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abbb7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "#history = settings.SHORT_TERM_MEMORY.get_history(session_id = 1)\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"hi, there!\", msg_type=\"human\")\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"hi, how can I help you?\", msg_type=\"ai\")\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\", msg_type=\"human\")\n",
    "settings.SHORT_TERM_MEMORY.add_message(session_id=1,message=\"phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\", msg_type=\"ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f51e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 10===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "Decision: rewrite \n",
      "\n",
      "State: {'session_id': 1, 'query': 'How can I take it?', 'wiki_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n",
      "===Step 11===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not  \n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "Decision: rewrite \n",
      "\n",
      "State: {'session_id': 1, 'query': 'where can I buy it?', 'wiki_used': False, 'rewrite_counter': 0, 'grade': {'score': 'yes'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should be related to history\n",
    "state = AgentState(session_id=1, query=\"How can I take it?\",wiki_used=False,rewrite_counter=0)\n",
    "\n",
    "state = grade_history_related_query(state)\n",
    "\n",
    "result = decide_history_related_query(state)\n",
    "\n",
    "print(f\"Decision: {result} \\n\")\n",
    "print(f\"State: {state} \\n\")\n",
    "# Related case\n",
    "state = AgentState(session_id=1, query=\"where can I buy it?\",wiki_used=False,rewrite_counter=0)\n",
    "\n",
    "state = grade_history_related_query(state)\n",
    "\n",
    "result = decide_history_related_query(state)\n",
    "\n",
    "print(f\"Decision: {result} \\n\")\n",
    "print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d685757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 12===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: HUMAN: hi, there!\n",
      "AI: hi, how can I help you?\n",
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not  \n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "Decision: return_sorry \n",
      "\n",
      "State: {'session_id': 1, 'query': \"Why doesn't my friend play tennis with me?\", 'wiki_used': False, 'rewrite_counter': 0, 'grade': {'score': 'no'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should be not related to history\n",
    "state = AgentState(session_id=1, query=\"Why doesn't my friend play tennis with me?\",wiki_used=False,rewrite_counter=0)\n",
    "\n",
    "state = grade_history_related_query(state)\n",
    "\n",
    "result = decide_history_related_query(state)\n",
    "\n",
    "print(f\"Decision: {result} \\n\")\n",
    "print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5f68d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def rewrite_query(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Determine whether a query is related to history conversations.    \n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "    history_conversation = history_as_text(history)\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(f\"Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \\n\")      \n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a question rewriter.\n",
    "    Your goal is to make the user's question fully self-contained and clear\n",
    "    by using the information provided in the reference material.\n",
    "\n",
    "    Reference material:\n",
    "    {document}\n",
    "\n",
    "    Original question:\n",
    "    {question}\n",
    "\n",
    "    Rewrite the question so that:\n",
    "    - It preserves the original intent and meaning.\n",
    "    - It includes any missing details from the reference material so the question can stand alone and be understood without reading the material.\n",
    "    - It is concise and natural.\n",
    "\n",
    "    Return only the rewritten question text with no explanation, no preamble, and no extra formatting.\"\"\",\n",
    "        input_variables=[\"question\", \"document\"],\n",
    "    )\n",
    "\n",
    "    new_query = robust_question_generater(prompt=prompt, query=query, document=history_conversation)\n",
    "    state['rewrite_counter'] += 1\n",
    "    state = AgentState(session_id=state[\"session_id\"], query=new_query, rewrite_counter=state['rewrite_counter']) # Avoid infinity loop in graph.\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48abba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 13===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output:  How do I take phenylephrine to relieve sinus congestion and pressure?\n",
      "\n",
      "State: {'session_id': 1, 'query': 'How do I take phenylephrine to relieve sinus congestion and pressure?', 'rewrite_counter': 1} \n",
      "\n",
      "===Step 14===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output:  Where can I buy phenylephrine to relieve sinus congestion and pressure?\n",
      "\n",
      "State: {'session_id': 1, 'query': 'Where can I buy phenylephrine to relieve sinus congestion and pressure?', 'rewrite_counter': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Should be related to history\n",
    "state = AgentState(session_id=1, query=\"How can I take it?\",rewrite_counter=0)\n",
    "\n",
    "state = rewrite_query(state)\n",
    "\n",
    "print(f\"State: {state} \\n\")\n",
    "\n",
    "state = AgentState(session_id=1, query=\"Where can I buy it?\",rewrite_counter=0)\n",
    "\n",
    "state = rewrite_query(state)\n",
    "\n",
    "print(f\"State: {state} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1783ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def return_without_docs(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    When the query has nothing to do with clinical topic or retrieval documents are not relevant to the query, \n",
    "    Then return 'sorry...' \n",
    "    \"\"\"\n",
    "    # query = state[\"query\"]\n",
    "    # print(f\"===Step {settings.STEP}===\\n\")\n",
    "\n",
    "    # prompt = PromptTemplate(\n",
    "    #     template=\"\"\"\n",
    "    # You are a helpful and concise assistant.\n",
    "\n",
    "    # Task:\n",
    "    # - Read the user's question carefully.\n",
    "    # - Provide a direct, **simple and reasonable** answer in plain language.\n",
    "    # - Keep the answer short and clear. Avoid long explanations unless absolutely needed.\n",
    "    # - If the question is unclear, politely ask for clarification in a simple way.\n",
    "\n",
    "    # User question:\n",
    "    # {question}\n",
    "\n",
    "    # Your answer:\n",
    "    # \"\"\",\n",
    "    #     input_variables=[\"question\"],\n",
    "    # )\n",
    "\n",
    "    # chain = prompt | master_llm | StrOutputParser()    \n",
    "    # raw = chain.invoke({\"question\": query})\n",
    "    # print(f\"Real output: {raw}\\n\")      \n",
    "    # state[\"generation\"] = str(raw)\n",
    "    # state[\"retrieved_doc\"] = \"\"\n",
    "    apology_sentences = [    \n",
    "        \"We primarily provide medical information, but your question doesn’t appear to be related to health topics, so we can’t offer an answer.\",\n",
    "        \"Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\",\n",
    "        \"Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\",\n",
    "        \"This platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.\",\n",
    "        \"We mainly handle medical or health-related questions, and since your query isn’t in that area, we don’t have suitable content to share.\"\n",
    "    ]\n",
    "\n",
    "    state[\"generation\"] = random.choice(apology_sentences)\n",
    "    state[\"retrieved_doc\"] = \"\"\n",
    "    print(f\"\"\"Master_Agent: {state[\"generation\"]}\"\"\")\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57ae3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def return_with_docs(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    When it successfully retrieved relevant documents, \n",
    "    Then return \n",
    "    \"\"\"\n",
    "    print(f\"===Step {settings.STEP}===\\n\")        \n",
    "    print(\"Master_Agent: I am happy to get something you might need!\\n\")\n",
    "    settings.STEP += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def save_to_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Before End, save user's query and final answer to memory \n",
    "    \"\"\"   \n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"Master_Agent: I am saving the user query and RAG response to memory.\\n\")  \n",
    "    print(f\"\"\"User query: {state[\"query\"]} - RAG documents: {state[\"retrieved_doc\"]} - Agent answer: {state[\"generation\"]}\"\"\") \n",
    "    #history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "\n",
    "    settings.SHORT_TERM_MEMORY.add_message(session_id=state[\"session_id\"], message=state[\"query\"], msg_type=\"human\")\n",
    "    settings.SHORT_TERM_MEMORY.add_message(session_id=state[\"session_id\"], message=state[\"generation\"], msg_type=\"ai\")\n",
    "    settings.STEP = 1 # Reset the STEP \n",
    "    return state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4c36dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Retrieve documents by query.\n",
    "    Then grade the relevance.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"Master_Agent: I am seaching documents from RAG.\\n\")  \n",
    "    documents = rag.retrieve(state[\"query\"], top_k=3)\n",
    "    final_documents = [d.page_content for d in documents if d.metadata[\"rerank_score\"] > 0.7]\n",
    "    state[\"retrieved_doc\"] = \". \".join(final_documents)\n",
    "    if len(final_documents) == 0:        \n",
    "        state[\"grade\"] = {\"score\": \"no\"}\n",
    "    else:\n",
    "        state[\"grade\"] = {\"score\": \"yes\"}\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e09fbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_relevant_docs(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    If it retrieved relevant documents from RAG, go to \"return_with_docs\" node\n",
    "    If it didn't find anything from RAG and Wiki tool has not been used, then go to \"wiki_search\" tool node.\n",
    "    If it didn't find anything from RAG and Wiki, the return sorry.\n",
    "    \"\"\"\n",
    "    if state[\"grade\"][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: I found some documents you may need.\\n\")\n",
    "        return \"return_with_docs\"\n",
    "    elif not state[\"wiki_used\"]:\n",
    "        print(\"Master_Agent: I am sorry I didn't get the relevant document from RAG. I am going to search on wikipedia.\\n\")          \n",
    "        return \"wiki_search\"\n",
    "    elif not state[\"brave_used\"]:\n",
    "        print(\"Master_Agent: I only have last tool to use now..\\n\")          \n",
    "        return \"brave_search\"\n",
    "    else:\n",
    "        print(\"Master_Agent: I am sorry I didn't get any thing from RAG, Brave search and wikipedia.\\n\")         \n",
    "        return \"return_sorry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b1a98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def wiki_search(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Search documents by Wikipedia seach tool.\n",
    "    Then grade the relevance.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"I am seaching documents from Wikipedia.\\n\")  \n",
    "    documents = wiki.invoke({\"query\": state[\"query\"]})\n",
    "    json_list = wiki_to_json(documents)\n",
    "    \n",
    "    # Rank the wiki docs with crossEncoder\n",
    "    pairs = [[state[\"query\"], s[\"Summary\"]] for s in json_list]\n",
    "    scores = rag.cross_encoder.predict(pairs, batch_size=32)\n",
    "    for j_l, score in zip(json_list, scores):\n",
    "        j_l[\"score\"] = float(score)\n",
    "\n",
    "    final_documents = [d[\"Summary\"] for d in json_list if d[\"score\"] > 0.5]\n",
    "    state[\"retrieved_doc\"] = \". \".join(final_documents)\n",
    "    state[\"wiki_used\"] = True # For a good query, only use wiki search once. Avoid infinity loop.\n",
    "    if len(final_documents) == 0:        \n",
    "        state[\"grade\"] = {\"score\": \"no\"}\n",
    "    else:        \n",
    "        state[\"grade\"] = {\"score\": \"yes\"}\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8785fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action Node\n",
    "def brave_search(state: AgentState) -> AgentState:\n",
    "    \"\"\" \n",
    "    Search documents by Brave seach tool.\n",
    "    Then grade the relevance.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"===Step {settings.STEP}===\\n\")\n",
    "    print(\"I am seaching documents from Brave search Engine.\\n\")  \n",
    "    \n",
    "    json_list = json.loads(brave.run(state[\"query\"]))\n",
    "    \n",
    "    # Rank the brave docs with crossEncoder\n",
    "    pairs = [[state[\"query\"], d[\"snippet\"]] for d in json_list]\n",
    "    scores = rag.cross_encoder.predict(pairs, batch_size=32)\n",
    "    for j_l, score in zip(json_list, scores):\n",
    "        j_l[\"score\"] = float(score)\n",
    "\n",
    "    final_documents = [d[\"snippet\"] for d in json_list if d[\"score\"] > 0.5]\n",
    "    state[\"retrieved_doc\"] = \". \".join(final_documents)\n",
    "    state[\"brave_used\"] = True # For a good query, only use brave search once. Avoid infinity loop.\n",
    "    if len(final_documents) == 0:        \n",
    "        state[\"grade\"] = {\"score\": \"no\"}\n",
    "    else:        \n",
    "        state[\"grade\"] = {\"score\": \"yes\"}\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aad8f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Node\n",
    "def decide_entry_relevant(state: AgentState) -> str:\n",
    "    \"\"\" \n",
    "    No matter what the query looks like. Just retrieve something to see if we can get relevant documents.\n",
    "    This is the most efficient way. \n",
    "    \"\"\"    \n",
    "    if state[\"grade\"][\"score\"] == \"yes\":\n",
    "        print(f\"Master_Agent: I found some documents you may need.\\n\")\n",
    "        return \"return_with_docs\"    \n",
    "    else:               \n",
    "        return \"grade_selfcontained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f4925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph\n",
    "agentic_rag_graph = StateGraph(AgentState)\n",
    "# Add nodes\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_greeting_node\", grade_greeting_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"greeting_node\", greeting_back)\n",
    "\n",
    "agentic_rag_graph.add_node(\"retrieve_entry_node\", retrieve)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_selfcontained_node\", grade_selfcontained_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_selfcontained_node\", decide_selfcontained_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_history_related_node\", grade_history_related_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_history_related_node\", decide_history_related_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"rewrite_query_node\", rewrite_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"grade_clinical_node\", grade_clinical_query)\n",
    "\n",
    "#agentic_rag_graph.add_node(\"decide_clinical_node\", decide_clinical_query)\n",
    "\n",
    "agentic_rag_graph.add_node(\"retrieve_node\", retrieve)\n",
    "\n",
    "agentic_rag_graph.add_node(\"decide_relevant_router\", lambda state:state) # Transparent\n",
    "\n",
    "agentic_rag_graph.add_node(\"return_sorry_node\", return_without_docs)\n",
    "\n",
    "agentic_rag_graph.add_node(\"return_docs_node\", return_with_docs)\n",
    "\n",
    "agentic_rag_graph.add_node(\"answer_node\", answer_generater)\n",
    "\n",
    "agentic_rag_graph.add_node(\"save_node\", save_to_memory)\n",
    "\n",
    "agentic_rag_graph.add_node(\"wiki_search_node\", wiki_search)\n",
    "\n",
    "agentic_rag_graph.add_node(\"brave_search_node\", brave_search)\n",
    "\n",
    "# Add Edges\n",
    "\n",
    "agentic_rag_graph.add_edge(START,\"grade_greeting_node\")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_greeting_node\",\n",
    "    path=decide_greeting_query,\n",
    "    path_map={\n",
    "        \"greeting\": \"greeting_node\",\n",
    "        \"grade_selfcontained\": \"grade_selfcontained_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "#agentic_rag_graph.add_edge(START, \"grade_selfcontained_node\")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_selfcontained_node\",\n",
    "    path=decide_selfcontained_query,\n",
    "    path_map={\n",
    "        \"grade_clinical\": \"grade_clinical_node\",\n",
    "        \"grade_related_history\": \"grade_history_related_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_history_related_node\",\n",
    "    path=decide_history_related_query,\n",
    "    path_map={\n",
    "        \"rewrite\": \"rewrite_query_node\",\n",
    "        \"return_sorry\": \"return_sorry_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"grade_clinical_node\",\n",
    "    path=decide_clinical_query,\n",
    "    path_map={\n",
    "        \"retrieve\": \"retrieve_node\",\n",
    "        \"return_sorry\": \"return_sorry_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"rewrite_query_node\", \"grade_selfcontained_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"retrieve_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_conditional_edges(\n",
    "    source=\"decide_relevant_router\",\n",
    "    path=decide_relevant_docs,\n",
    "    path_map={\n",
    "        \"return_sorry\": \"return_sorry_node\",\n",
    "        \"return_with_docs\": \"return_docs_node\",\n",
    "        \"wiki_search\": \"wiki_search_node\",\n",
    "        \"brave_search\": \"brave_search_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"wiki_search_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"brave_search_node\", \"decide_relevant_router\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"return_docs_node\", \"answer_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"return_sorry_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"answer_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"greeting_node\", \"save_node\")\n",
    "\n",
    "agentic_rag_graph.add_edge(\"save_node\", END)\n",
    "\n",
    "app = agentic_rag_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1188d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(data=app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e93b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"逗我\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations:  \n",
      "\n",
      "[grade_selfcontained_query] Warning: parse failed: \"Input to PromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \" \n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "Master_Agent: Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: 逗我 - RAG response:  - Agent answerOur service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\n",
      "result:{'session_id': 1, 'query': '逗我', 'retrieved_doc': '', 'generation': 'Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"hi\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is just greeting. Greeting back.\n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Real output:  Hi!\n",
      "\n",
      "===Step 0===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: hi - RAG response:  - Agent answer Hi!\n",
      "result:{'session_id': 1, 'query': 'hi', 'retrieved_doc': '', 'generation': ' Hi!', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"dancing?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Master_Agent: This platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: dancing? - RAG response:  - Agent answerThis platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.\n",
      "result:{'session_id': 1, 'query': 'dancing?', 'retrieved_doc': '', 'generation': 'This platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"What is Phenylephrine used for?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.4932s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  Phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever, and to relieve sinus congestion and pressure.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: What is Phenylephrine used for? - RAG response: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine. phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine. phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine - Agent answer Phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever, and to relieve sinus congestion and pressure.\n",
      "result:{'session_id': 1, 'query': 'What is Phenylephrine used for?', 'retrieved_doc': 'phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine. phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine. phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine', 'generation': ' Phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever, and to relieve sinus congestion and pressure.', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"how can I use it?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: AI:  Phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever, and to relieve sinus congestion and pressure.\n",
      "HUMAN: What is Phenylephrine used for? \n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output:  What are the proper uses of Phenylephrine?\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 7===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.4753s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 8===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.\n",
      "\n",
      "===Step 9===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: What are the proper uses of Phenylephrine? - RAG response: Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.. Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.. Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information. - Agent answer Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.\n",
      "result:{'session_id': 1, 'query': 'What are the proper uses of Phenylephrine?', 'retrieved_doc': 'Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.. Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.. Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.', 'generation': ' Phenylephrine may be prescribed for other uses; ask your doctor or pharmacist for more information.', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 1}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"How can I store it?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Master_Agent: Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: How can I store it? - RAG response:  - Agent answerOur service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.\n",
      "result:{'session_id': 1, 'query': 'How can I store it?', 'retrieved_doc': '', 'generation': 'Our service focuses on medical and health matters, yet your inquiry doesn’t seem medical, so we’re unable to assist with it.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"what should i know about storage and disposal of Phenylephrine?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.5510s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unneeded medications in a way so that pets, children, and other people cannot take them. Do not flush Phenylephrine down the toilet. Use a medicine take-back program. Talk to your pharmacist about take-back programs in your community. Visit the FDA's safe disposal of medicines website for more information.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: what should i know about storage and disposal of Phenylephrine? - RAG response: keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information. - Agent answer Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unneeded medications in a way so that pets, children, and other people cannot take them. Do not flush Phenylephrine down the toilet. Use a medicine take-back program. Talk to your pharmacist about take-back programs in your community. Visit the FDA's safe disposal of medicines website for more information.\n",
      "result:{'session_id': 1, 'query': 'what should i know about storage and disposal of Phenylephrine?', 'retrieved_doc': \"keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â\\x80\\x93 one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â\\x80\\x93 one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â\\x80\\x93 one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.\", 'generation': \" Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unneeded medications in a way so that pets, children, and other people cannot take them. Do not flush Phenylephrine down the toilet. Use a medicine take-back program. Talk to your pharmacist about take-back programs in your community. Visit the FDA's safe disposal of medicines website for more information.\", 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"Are there any dietary instructions while using it?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: AI:  Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unn\n",
      "HUMAN: what should i know about storage and disposal of Phenylephrine? \n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output:  What are the storage and disposal guidelines for Phenylephrine?\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 7===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.5125s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 8===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unneeded medications in a way so that pets, children, and other people cannot take them. Do not flush Phenylephrine down the toilet. Use a medicine take-back program. Talk to your pharmacist about take-back programs in your community. Visit the FDA's safe disposal of medicines website for more information.\n",
      "\n",
      "===Step 9===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: What are the storage and disposal guidelines for Phenylephrine? - RAG response: keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information. - Agent answer Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unneeded medications in a way so that pets, children, and other people cannot take them. Do not flush Phenylephrine down the toilet. Use a medicine take-back program. Talk to your pharmacist about take-back programs in your community. Visit the FDA's safe disposal of medicines website for more information.\n",
      "result:{'session_id': 1, 'query': 'What are the storage and disposal guidelines for Phenylephrine?', 'retrieved_doc': \"keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â\\x80\\x93 one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â\\x80\\x93 one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.. keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. store it at room temperature and away from excess heat and moisture (not in the bathroom).keep all medication out of sight and reach of children as many containers are not child-resistant. always lock safety caps. place the medication in a safe location â\\x80\\x93 one that is up and away and out of their sight and reach.https://www.upandaway.orgdispose of unneeded medications in a way so that pets, children, and other people cannot take them. do not flush Phenylephrine down the toilet. use a medicine take-back program. talk to your pharmacist about take-back programs in your community. visit the fda's safe disposal of medicines websitehttps://goo.gl/c4rm4pfor more information.\", 'generation': \" Keep Phenylephrine in the container it came in, tightly closed, and out of reach of children. Store it at room temperature and away from excess heat and moisture (not in the bathroom). Dispose of unneeded medications in a way so that pets, children, and other people cannot take them. Do not flush Phenylephrine down the toilet. Use a medicine take-back program. Talk to your pharmacist about take-back programs in your community. Visit the FDA's safe disposal of medicines website for more information.\", 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 1}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"how are you?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is just greeting. Greeting back.\n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Real output:  Hi!\n",
      "\n",
      "===Step 0===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: how are you? - RAG response:  - Agent answer Hi!\n",
      "result:{'session_id': 1, 'query': 'how are you?', 'retrieved_doc': '', 'generation': ' Hi!', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"thank you\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not clinical query. I have nothing to do with it. \n",
      "\n",
      "Master_Agent: Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: thank you - RAG response:  - Agent answerBecause we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\n",
      "result:{'session_id': 1, 'query': 'thank you', 'retrieved_doc': '', 'generation': 'Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"why is Antipyrine-Benzocaine Otic prescribed?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: AI: Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\n",
      "HUMAN: thank you \n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "Master_Agent: This platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: why is Antipyrine-Benzocaine Otic prescribed? - RAG response:  - Agent answerThis platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.\n",
      "result:{'session_id': 1, 'query': 'why is Antipyrine-Benzocaine Otic prescribed?', 'retrieved_doc': '', 'generation': 'This platform is designed for medical content, but your question doesn’t fit that scope, so we can’t give relevant information.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"What is Antipyrine-Benzocaine Otic used for?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.4938s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, to help remove a build up of ear wax in the ear, and may be used along with antibiotics to treat an ear infection.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: What is Antipyrine-Benzocaine Otic used for? - RAG response: antipyrine and benzocaine otic is used to relieve ear pain and swelling caused by middle ear infections. it may be used along with antibiotics to treat an ear infection. it is also used to help remove a build up of ear wax in the ear. antipyrine and benzocaine are in a class of medications called analgesics. the combination of antipyrine and benzocaine works by reducing pain and discomfort in the ear.about Antipyrine-Benzocaine Otic. antipyrine and benzocaine otic comes as a solution (liquid) to place into the ear. when antipyrine and benzocaine is used to relieve ear pain, it is usually used every 1 to 2 hours as needed. when antipyrine and benzocaine is used to help in the removal of ear wax, it is usually used 3 times daily for 2-3 days. follow the directions on your prescription label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use antipyrine and benzocaine otic exactly as directed.antipyrine and benzocaine otic is for use only in the ears.to use the eardrops, follow these steps:hold the bottle in your hand for 1 or 2 minutes to warm the solution.place the prescribed number of drops into your ear.be careful not to touch the tip to your ear, fingers, or any other surface.moisten a small piece of cotton with the drops and insert into the outer ear.repeat steps 2-4 for the opposite ear if necessary.about Antipyrine-Benzocaine Otic. Antipyrine-Benzocaine Otic may be prescribed for other uses; ask your doctor or pharmacist for more information. - Agent answer Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, to help remove a build up of ear wax in the ear, and may be used along with antibiotics to treat an ear infection.\n",
      "result:{'session_id': 1, 'query': 'What is Antipyrine-Benzocaine Otic used for?', 'retrieved_doc': 'antipyrine and benzocaine otic is used to relieve ear pain and swelling caused by middle ear infections. it may be used along with antibiotics to treat an ear infection. it is also used to help remove a build up of ear wax in the ear. antipyrine and benzocaine are in a class of medications called analgesics. the combination of antipyrine and benzocaine works by reducing pain and discomfort in the ear.about Antipyrine-Benzocaine Otic. antipyrine and benzocaine otic comes as a solution (liquid) to place into the ear. when antipyrine and benzocaine is used to relieve ear pain, it is usually used every 1 to 2 hours as needed. when antipyrine and benzocaine is used to help in the removal of ear wax, it is usually used 3 times daily for 2-3 days. follow the directions on your prescription label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use antipyrine and benzocaine otic exactly as directed.antipyrine and benzocaine otic is for use only in the ears.to use the eardrops, follow these steps:hold the bottle in your hand for 1 or 2 minutes to warm the solution.place the prescribed number of drops into your ear.be careful not to touch the tip to your ear, fingers, or any other surface.moisten a small piece of cotton with the drops and insert into the outer ear.repeat steps 2-4 for the opposite ear if necessary.about Antipyrine-Benzocaine Otic. Antipyrine-Benzocaine Otic may be prescribed for other uses; ask your doctor or pharmacist for more information.', 'generation': ' Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, to help remove a build up of ear wax in the ear, and may be used along with antibiotics to treat an ear infection.', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"how can I use it?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: AI:  Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, to help remove a build up of ear wax in the ear, and may be used along with antibiotics to treat a\n",
      "HUMAN: What is Antipyrine-Benzocaine Otic used for? \n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "Master_Agent: We mainly handle medical or health-related questions, and since your query isn’t in that area, we don’t have suitable content to share.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: how can I use it? - RAG response:  - Agent answerWe mainly handle medical or health-related questions, and since your query isn’t in that area, we don’t have suitable content to share.\n",
      "result:{'session_id': 1, 'query': 'how can I use it?', 'retrieved_doc': '', 'generation': 'We mainly handle medical or health-related questions, and since your query isn’t in that area, we don’t have suitable content to share.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"I mean Antipyrine-Benzocaine Otic\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.5740s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, may be used along with antibiotics to treat an ear infection, and is also used to help remove a build up of ear wax in the ear. It is a solution that is placed into the ear and should be used exactly as directed.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: I mean Antipyrine-Benzocaine Otic - RAG response: antipyrine and benzocaine otic is used to relieve ear pain and swelling caused by middle ear infections. it may be used along with antibiotics to treat an ear infection. it is also used to help remove a build up of ear wax in the ear. antipyrine and benzocaine are in a class of medications called analgesics. the combination of antipyrine and benzocaine works by reducing pain and discomfort in the ear.about Antipyrine-Benzocaine Otic. antipyrine and benzocaine otic comes as a solution (liquid) to place into the ear. when antipyrine and benzocaine is used to relieve ear pain, it is usually used every 1 to 2 hours as needed. when antipyrine and benzocaine is used to help in the removal of ear wax, it is usually used 3 times daily for 2-3 days. follow the directions on your prescription label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use antipyrine and benzocaine otic exactly as directed.antipyrine and benzocaine otic is for use only in the ears.to use the eardrops, follow these steps:hold the bottle in your hand for 1 or 2 minutes to warm the solution.place the prescribed number of drops into your ear.be careful not to touch the tip to your ear, fingers, or any other surface.moisten a small piece of cotton with the drops and insert into the outer ear.repeat steps 2-4 for the opposite ear if necessary.about Antipyrine-Benzocaine Otic. keep all appointments with your doctor.do not let anyone else take your medication. ask your pharmacist any questions you have about refilling your prescription.keep a written list of all of the prescription and nonprescription (over-the-counter) medicines, vitamins, minerals, and dietary supplements you are taking. bring this list with you each time you visit a doctor or if you are admitted to the hospital. you should carry the list with you in case of emergencies.about Antipyrine-Benzocaine Otic - Agent answer Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, may be used along with antibiotics to treat an ear infection, and is also used to help remove a build up of ear wax in the ear. It is a solution that is placed into the ear and should be used exactly as directed.\n",
      "result:{'session_id': 1, 'query': 'I mean Antipyrine-Benzocaine Otic', 'retrieved_doc': 'antipyrine and benzocaine otic is used to relieve ear pain and swelling caused by middle ear infections. it may be used along with antibiotics to treat an ear infection. it is also used to help remove a build up of ear wax in the ear. antipyrine and benzocaine are in a class of medications called analgesics. the combination of antipyrine and benzocaine works by reducing pain and discomfort in the ear.about Antipyrine-Benzocaine Otic. antipyrine and benzocaine otic comes as a solution (liquid) to place into the ear. when antipyrine and benzocaine is used to relieve ear pain, it is usually used every 1 to 2 hours as needed. when antipyrine and benzocaine is used to help in the removal of ear wax, it is usually used 3 times daily for 2-3 days. follow the directions on your prescription label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use antipyrine and benzocaine otic exactly as directed.antipyrine and benzocaine otic is for use only in the ears.to use the eardrops, follow these steps:hold the bottle in your hand for 1 or 2 minutes to warm the solution.place the prescribed number of drops into your ear.be careful not to touch the tip to your ear, fingers, or any other surface.moisten a small piece of cotton with the drops and insert into the outer ear.repeat steps 2-4 for the opposite ear if necessary.about Antipyrine-Benzocaine Otic. keep all appointments with your doctor.do not let anyone else take your medication. ask your pharmacist any questions you have about refilling your prescription.keep a written list of all of the prescription and nonprescription (over-the-counter) medicines, vitamins, minerals, and dietary supplements you are taking. bring this list with you each time you visit a doctor or if you are admitted to the hospital. you should carry the list with you in case of emergencies.about Antipyrine-Benzocaine Otic', 'generation': ' Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, may be used along with antibiotics to treat an ear infection, and is also used to help remove a build up of ear wax in the ear. It is a solution that is placed into the ear and should be used exactly as directed.', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"how can I eat it?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: AI:  Antipyrine-Benzocaine Otic is used to relieve ear pain and swelling caused by middle ear infections, may be used along with antibiotics to treat an ear infection, and is also used to help remove a bu\n",
      "HUMAN: I mean Antipyrine-Benzocaine Otic \n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not related to the history. So it is a random query. \n",
      "\n",
      "Master_Agent: Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: how can I eat it? - RAG response:  - Agent answerBecause we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.\n",
      "result:{'session_id': 1, 'query': 'how can I eat it?', 'retrieved_doc': '', 'generation': 'Because we specialize in medical information and your question isn’t clearly health-related, we’re unable to provide a response.', 'grade': {'score': 'no'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"how can I take Antipyrine-Benzocaine Otic?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 3===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.4644s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  To use Antipyrine-Benzocaine Otic, tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications. Also, inform your doctor if you have a hole in your ear drum(s) or ear tube(s) and if you are pregnant, plan to become pregnant, or are breast-feeding. Keep all appointments with your doctor and do not let anyone else take your medication. Ask your pharmacist any questions you have about refilling your prescription.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: how can I take Antipyrine-Benzocaine Otic? - RAG response: before using antipyrine and benzocaine otic,tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications.tell your doctor and pharmacist what other prescription and nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take while using antipyrine and benzocaine otic.tell your doctor if you have a hole in your ear drum(s) or ear tube(s). your doctor will probably tell you not to use Antipyrine-Benzocaine Otic.tell your doctor if you are pregnant, plan to become pregnant, or are breast-feeding. if you become pregnant while using antipyrine and benzocaine otic, call your doctor.. keep all appointments with your doctor.do not let anyone else take your medication. ask your pharmacist any questions you have about refilling your prescription.keep a written list of all of the prescription and nonprescription (over-the-counter) medicines, vitamins, minerals, and dietary supplements you are taking. bring this list with you each time you visit a doctor or if you are admitted to the hospital. you should carry the list with you in case of emergencies.about Antipyrine-Benzocaine Otic. antipyrine and benzocaine otic may cause side effects. call your doctor if you have any unusual problems while taking Antipyrine-Benzocaine Otic. - Agent answer To use Antipyrine-Benzocaine Otic, tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications. Also, inform your doctor if you have a hole in your ear drum(s) or ear tube(s) and if you are pregnant, plan to become pregnant, or are breast-feeding. Keep all appointments with your doctor and do not let anyone else take your medication. Ask your pharmacist any questions you have about refilling your prescription.\n",
      "result:{'session_id': 1, 'query': 'how can I take Antipyrine-Benzocaine Otic?', 'retrieved_doc': 'before using antipyrine and benzocaine otic,tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications.tell your doctor and pharmacist what other prescription and nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take while using antipyrine and benzocaine otic.tell your doctor if you have a hole in your ear drum(s) or ear tube(s). your doctor will probably tell you not to use Antipyrine-Benzocaine Otic.tell your doctor if you are pregnant, plan to become pregnant, or are breast-feeding. if you become pregnant while using antipyrine and benzocaine otic, call your doctor.. keep all appointments with your doctor.do not let anyone else take your medication. ask your pharmacist any questions you have about refilling your prescription.keep a written list of all of the prescription and nonprescription (over-the-counter) medicines, vitamins, minerals, and dietary supplements you are taking. bring this list with you each time you visit a doctor or if you are admitted to the hospital. you should carry the list with you in case of emergencies.about Antipyrine-Benzocaine Otic. antipyrine and benzocaine otic may cause side effects. call your doctor if you have any unusual problems while taking Antipyrine-Benzocaine Otic.', 'generation': ' To use Antipyrine-Benzocaine Otic, tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications. Also, inform your doctor if you have a hole in your ear drum(s) or ear tube(s) and if you are pregnant, plan to become pregnant, or are breast-feeding. Keep all appointments with your doctor and do not let anyone else take your medication. Ask your pharmacist any questions you have about refilling your prescription.', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 0}\n",
      "===Step 1===\n",
      "\n",
      "Master_Agent: Got a new query: \"where can I buy it?\"\n",
      "I will check if the query is pure greeting.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not greeting. Let's check if it is self-contained one. \n",
      "\n",
      "===Step 2===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'no'}\n",
      "\n",
      "Master_Agent: The query is not self-contained. Let's check if it is related to history conversation. \n",
      "\n",
      "===Step 3===\n",
      "\n",
      "Master_Agent: I am checking if the query is related to history conversations. \n",
      "\n",
      "history conversations: AI:  To use Antipyrine-Benzocaine Otic, tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications. Also, inform your doctor if you have a hole in your ear dr\n",
      "HUMAN: how can I take Antipyrine-Benzocaine Otic? \n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is related to the history. But it is not self-contained. Let's re-write it.\n",
      "\n",
      "===Step 4===\n",
      "\n",
      "Master_Agent: I am rewriting the query so that I can retrieve relevant documents with a new query. \n",
      "\n",
      "Real output:  How can I take Antipyrine-Benzocaine Otic?\n",
      "\n",
      "===Step 5===\n",
      "\n",
      "Master_Agent: I will check if the query is self-contained.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a self-contained one. We don't need to augment it. Let's check if it is a clinical query.\n",
      "\n",
      "===Step 6===\n",
      "\n",
      "I am checking if the query is about medicine or clinical questions.\n",
      "\n",
      "Real output: {'score': 'yes'}\n",
      "\n",
      "Master_Agent: The query is a clinical one. We can retrive some documents now.\n",
      "\n",
      "===Step 7===\n",
      "\n",
      "Master_Agent: I am seaching documents from RAG.\n",
      "\n",
      "retrieve starts runing!\n",
      "retrieve took 0.5107s\n",
      "Master_Agent: I found some documents you may need.\n",
      "\n",
      "===Step 8===\n",
      "\n",
      "Master_Agent: I am happy to get something you might need!\n",
      "\n",
      "Real output:  To use Antipyrine-Benzocaine Otic, first hold the bottle in your hand for 1 or 2 minutes to warm the solution. Then, place the prescribed number of drops into your ear. Be careful not to touch the tip to your ear, fingers, or any other surface. After that, moisten a small piece of cotton with the drops and insert into the outer ear. If necessary, repeat the process for the opposite ear.\n",
      "\n",
      "===Step 9===\n",
      "\n",
      "Master_Agent: I am saving the user query and RAG response to memory.\n",
      "\n",
      "User query: How can I take Antipyrine-Benzocaine Otic? - RAG response: before using antipyrine and benzocaine otic,tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications.tell your doctor and pharmacist what other prescription and nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take while using antipyrine and benzocaine otic.tell your doctor if you have a hole in your ear drum(s) or ear tube(s). your doctor will probably tell you not to use Antipyrine-Benzocaine Otic.tell your doctor if you are pregnant, plan to become pregnant, or are breast-feeding. if you become pregnant while using antipyrine and benzocaine otic, call your doctor.. antipyrine and benzocaine otic may cause side effects. call your doctor if you have any unusual problems while taking Antipyrine-Benzocaine Otic.. antipyrine and benzocaine otic comes as a solution (liquid) to place into the ear. when antipyrine and benzocaine is used to relieve ear pain, it is usually used every 1 to 2 hours as needed. when antipyrine and benzocaine is used to help in the removal of ear wax, it is usually used 3 times daily for 2-3 days. follow the directions on your prescription label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use antipyrine and benzocaine otic exactly as directed.antipyrine and benzocaine otic is for use only in the ears.to use the eardrops, follow these steps:hold the bottle in your hand for 1 or 2 minutes to warm the solution.place the prescribed number of drops into your ear.be careful not to touch the tip to your ear, fingers, or any other surface.moisten a small piece of cotton with the drops and insert into the outer ear.repeat steps 2-4 for the opposite ear if necessary.about Antipyrine-Benzocaine Otic - Agent answer To use Antipyrine-Benzocaine Otic, first hold the bottle in your hand for 1 or 2 minutes to warm the solution. Then, place the prescribed number of drops into your ear. Be careful not to touch the tip to your ear, fingers, or any other surface. After that, moisten a small piece of cotton with the drops and insert into the outer ear. If necessary, repeat the process for the opposite ear.\n",
      "result:{'session_id': 1, 'query': 'How can I take Antipyrine-Benzocaine Otic?', 'retrieved_doc': 'before using antipyrine and benzocaine otic,tell your doctor and pharmacist if you are allergic to antipyrine or benzocaine or any other medications.tell your doctor and pharmacist what other prescription and nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take while using antipyrine and benzocaine otic.tell your doctor if you have a hole in your ear drum(s) or ear tube(s). your doctor will probably tell you not to use Antipyrine-Benzocaine Otic.tell your doctor if you are pregnant, plan to become pregnant, or are breast-feeding. if you become pregnant while using antipyrine and benzocaine otic, call your doctor.. antipyrine and benzocaine otic may cause side effects. call your doctor if you have any unusual problems while taking Antipyrine-Benzocaine Otic.. antipyrine and benzocaine otic comes as a solution (liquid) to place into the ear. when antipyrine and benzocaine is used to relieve ear pain, it is usually used every 1 to 2 hours as needed. when antipyrine and benzocaine is used to help in the removal of ear wax, it is usually used 3 times daily for 2-3 days. follow the directions on your prescription label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use antipyrine and benzocaine otic exactly as directed.antipyrine and benzocaine otic is for use only in the ears.to use the eardrops, follow these steps:hold the bottle in your hand for 1 or 2 minutes to warm the solution.place the prescribed number of drops into your ear.be careful not to touch the tip to your ear, fingers, or any other surface.moisten a small piece of cotton with the drops and insert into the outer ear.repeat steps 2-4 for the opposite ear if necessary.about Antipyrine-Benzocaine Otic', 'generation': ' To use Antipyrine-Benzocaine Otic, first hold the bottle in your hand for 1 or 2 minutes to warm the solution. Then, place the prescribed number of drops into your ear. Be careful not to touch the tip to your ear, fingers, or any other surface. After that, moisten a small piece of cotton with the drops and insert into the outer ear. If necessary, repeat the process for the opposite ear.', 'grade': {'score': 'yes'}, 'wiki_used': False, 'brave_used': False, 'rewrite_counter': 1}\n"
     ]
    }
   ],
   "source": [
    "questions = [    \n",
    "    \"Is there anything I can assist you with?\",    \n",
    "    \"Can I help you in any way, next?\",\n",
    "    \"Do you have any questions?\",  \n",
    "    \"Are you looking for any particular information?\",\n",
    "    \"I am a Medicine Agentic RAG. I can help you get medical and clinical documents. Just tell me what you need?\"\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(random.choice(questions))\n",
    "    if user_input.strip().lower() in [\"end\", \"exit\"]:\n",
    "        break\n",
    "    query = AgentState(query=user_input, session_id=1,wiki_used=False,brave_used=False,rewrite_counter=0)\n",
    "    result = app.invoke(query)\n",
    "    print(f\"result:{result}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
