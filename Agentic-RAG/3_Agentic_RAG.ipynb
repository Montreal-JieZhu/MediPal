{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882e4567",
   "metadata": {},
   "source": [
    "### In this section, I will build an Agentic RAG\n",
    "\n",
    "Before, I already used a medical-domain LLM to generate hypothentical questions for each chunk. \n",
    "\n",
    "The project's main purpose is medical Q&A.  So I am going to implement Multi-Vector as the foundation of the RAG system.\n",
    "\n",
    "That means I am going to:\n",
    "* Embedding those questions to vectorestore and put chunked documents to docstore.\n",
    "* I will use doc_id which were generated at chunking stage to be a link between vectorstore and docstore.\n",
    "\n",
    "About the Agentic components:\n",
    "* I will involve an agent to do reranking for the retrieved documents so that it can provide the most relevant context. \n",
    "* The agent can remember history conversation so that it can still retrieve the relevant documents in multi-turns conversation.\n",
    "* The agent can genrate similar questions which will be used to retrieve documents.\n",
    "* The agent can do function calling/MCP when there is no relevant document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185c2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Vector implementation\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from huggingface_hub import login\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1ff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will load the json file to json object\n",
    "def load_json_list(path: str):    \n",
    "    with open(path, mode = \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfc87b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/datasets/medicine_data_hypotheticalquestions.json\n"
     ]
    }
   ],
   "source": [
    "workspace_base_path = os.getcwd()\n",
    "dataset_path = os.path.join(workspace_base_path, \"datasets\", \"medicine_data_hypotheticalquestions.json\") \n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39eff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json_list(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d0e581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': '1b8794c4-5946-4a50-bf09-d920746db8cb',\n",
       "  'questions': ['what special precautions should i follow about Chlordiazepoxide',\n",
       "   'What should people who are pregnant or breastfeeding know about Chlordiazepoxide?',\n",
       "   'What does the document say about drive car operate machinery until know how?'],\n",
       "  'original_doc': 'before taking chlordiazepoxide,tell your doctor and pharmacist if you are allergic to chlordiazepoxide, alprazolam (xanax), clonazepam (klonopin), clorazepate (gen-xene, tranxene), diazepam (diastat, valium), estazolam, flurazepam, lorazepam (ativan), oxazepam, temazepam (restoril), triazolam (halcion), any other medications, or any of the ingredients in tablets and capsules. ask your pharmacist for a list of the ingredients.tell your doctor and pharmacist what prescription and nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take while taking chlordiazepoxide. your doctor may need to change the doses of your medications or monitor you carefully for side effects.tell your doctor if you have or have ever had glaucoma; seizures; or lung, heart, or liver disease.tell your doctor if you are pregnant, plan to become pregnant, or are breastfeeding. if you become pregnant while taking chlordiazepoxide, call your doctor immediately.talk to your doctor about the risks and benefits of taking chlordiazepoxide if you are 65 years of age or older. older adults should not usually take chlordiazepoxide because it is not as safe or effective as other medication(s) that can be used to treat the same condition.if you are having surgery, including dental surgery, tell the doctor or dentist that you are taking chlordiazepoxide.you should know that Chlordiazepoxide may make you drowsy. do not drive a car or operate machinery until you know how Chlordiazepoxide affects you.'},\n",
       " {'doc_id': '58dbfea6-83fc-4c75-9481-01b0d22f7232',\n",
       "  'questions': ['what should i do if i forget a dose about Chlordiazepoxide',\n",
       "   'What should you do if you miss a dose of Chlordiazepoxide?'],\n",
       "  'original_doc': 'if you take several doses per day and miss a dose, skip the missed dose and continue your regular dosing schedule. do not take a double dose to make up for a missed one.about Chlordiazepoxide'},\n",
       " {'doc_id': '55470e85-8429-4f01-8d55-b42e879518b6',\n",
       "  'questions': ['what side effects can Chlordiazepoxide cause?',\n",
       "   'What side effects may occur with Chlordiazepoxide?',\n",
       "   'What should you tell your doctor before using Chlordiazepoxide?',\n",
       "   'Are there any dietary instructions while using Chlordiazepoxide?'],\n",
       "  'original_doc': \"chlordiazepoxide may cause side effects. tell your doctor if any of these symptoms are severe or do not go away:drowsinessdizzinesstirednessweaknessdry mouthdiarrheaupset stomachchanges in appetitetell your doctor if any of these symptoms are severe or do not go away:restlessness or excitementconstipationdifficulty urinatingfrequent urinationblurred visionchanges in sex drive or abilitysome side effects can be serious. if you experience any of the following symptoms or those listed in the important warning section, call your doctor immediately or get emergency medical help:shuffling walkpersistent, fine tremor or inability to sit stillfeverdifficulty breathing or swallowingsevere skin rashyellowing of the skin or eyesirregular heartbeatif you experience a serious side effect, you or your doctor may send a report to the food and drug administration's (fda) medwatch adverse event reporting program online (https://www.fda.gov/safety/medwatch) or by phone ([phone]).about Chlordiazepoxide\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[50:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14213b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "login(os.getenv(\"HUGGINGFACE_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dccc9b",
   "metadata": {},
   "source": [
    "##### I choose sentence-transformers/embeddinggemma-300m-medical, as it is a sentence-transformers model finetuned from google/embeddinggemma-300m on the miriad/miriad-4.4M dataset (specifically the first 100.000 question-passage pairs from tomaarsen/miriad-4.4M-split). It maps sentences & documents to a 768-dimensional dense vector space and can be used for medical information retrieval, specifically designed for searching for passages (up to 1k tokens) of scientific medical papers using detailed medical questions.\n",
    "\n",
    "* Reference: https://huggingface.co/sentence-transformers/embeddinggemma-300m-medical\n",
    "\n",
    "@inproceedings{reimers-2019-sentence-bert,\n",
    "    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n",
    "    author = \"Reimers, Nils and Gurevych, Iryna\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = \"11\",\n",
    "    year = \"2019\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://arxiv.org/abs/1908.10084\",\n",
    "}\n",
    "\n",
    "@misc{gao2021scaling,\n",
    "    title={Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup},\n",
    "    author={Luyu Gao and Yunyi Zhang and Jiawei Han and Jamie Callan},\n",
    "    year={2021},\n",
    "    eprint={2101.06983},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.LG}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a50206",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = \"sentence-transformers/embeddinggemma-300m-medical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0d49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 5.2.0.dev0, but you're currently using version 5.1.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    "    model_kwargs = {'device': 'cpu'},\n",
    "    # Normalizing helps cosine similarity behave better across models\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6579d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function will make a multi-vector db and return a retriever\n",
    "\n",
    "def medicine_documents_retriever(vectordb_name: str, data):\n",
    "    # The storage layer for the original documents\n",
    "    docstore = InMemoryStore()\n",
    "    id_key = \"doc_id\"\n",
    "\n",
    "    # The vectorstore to use to index the questions\n",
    "    vectorstore = Chroma(collection_name = vectordb_name, embedding_function = embedding_model)\n",
    "    # The Multi-Vector retriever\n",
    "    retriever = MultiVectorRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        docstore=docstore,\n",
    "        id_key=id_key,\n",
    "    )\n",
    "\n",
    "    doc_ids = list()\n",
    "    questions = list()\n",
    "    docs = list()\n",
    "    for d in data[:20]:\n",
    "        doc_id = d[\"doc_id\"]\n",
    "        doc_ids.append(doc_id)\n",
    "        docs.append(Document(metadata={\"doc_id\": doc_id}, page_content=d[\"original_doc\"]))\n",
    "        for q in d[\"questions\"]:\n",
    "            questions.append(Document(metadata={\"doc_id\": doc_id}, page_content=q))\n",
    "\n",
    "    retriever.vectorstore.add_documents(questions)\n",
    "    retriever.docstore.mset(list(zip(doc_ids,docs)))\n",
    "\n",
    "    return retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6663f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = medicine_documents_retriever(vectordb_name=\"medicinedocs\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "889987fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='94fa51a5-b9b9-452e-abd3-616f59a1d297', metadata={'doc_id': '88423ccc-adf6-4ecb-9d4a-48ead1e5f2b7'}, page_content='what special dietary instructions should i follow about Phenylephrine'),\n",
       " Document(id='bdf54d04-3917-497c-84af-204d4f5bb8b6', metadata={'doc_id': '88423ccc-adf6-4ecb-9d4a-48ead1e5f2b7'}, page_content='Are there any dietary instructions while using Phenylephrine?'),\n",
       " Document(id='9fbf8185-f2e1-4a0e-8f6d-697892a2745f', metadata={'doc_id': '0ff6d87b-c64f-4ac8-853b-d143cb09a386'}, page_content='Are there any dietary instructions while using Phenylephrine?'),\n",
       " Document(id='86730082-4dcf-492c-88fe-267344e5d092', metadata={'doc_id': '22a4ba55-1113-4c1d-9db3-f7eaabb7999a'}, page_content='what special precautions should i follow about Phenylephrine'),\n",
       " Document(id='97731eca-61fa-4ff4-9207-ab27776a0f7a', metadata={'doc_id': '0ff6d87b-c64f-4ac8-853b-d143cb09a386'}, page_content='what other information should i know about Phenylephrine'),\n",
       " Document(id='cd758cc0-c9ba-4e00-b959-956b84aa6ffc', metadata={'doc_id': '22a4ba55-1113-4c1d-9db3-f7eaabb7999a'}, page_content='What should people who are pregnant or breastfeeding know about Phenylephrine?')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.vectorstore.similarity_search(\"what special dietary instructions should i follow about Phenylephrine\",k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c0f7b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '88423ccc-adf6-4ecb-9d4a-48ead1e5f2b7'}, page_content='unless your doctor tells you otherwise, continue your normal diet.about Phenylephrine'),\n",
       " Document(metadata={'doc_id': '0ff6d87b-c64f-4ac8-853b-d143cb09a386'}, page_content='ask your pharmacist any questions you have about phenylephrine.keep a written list of all of the prescription and nonprescription (over-the-counter) medicines, vitamins, minerals, and dietary supplements you are taking. bring this list with you each time you visit a doctor or if you are admitted to the hospital. you should carry the list with you in case of emergencies.about Phenylephrine'),\n",
       " Document(metadata={'doc_id': '22a4ba55-1113-4c1d-9db3-f7eaabb7999a'}, page_content='before taking phenylephrine,tell your doctor and pharmacist if you are allergic to phenylephrine, any other medications, or any of the ingredients in phenylephrine preparations.do not take phenylephrine if you are taking a monoamine oxidase (mao) inhibitor, such as isocarboxazid (marplan), phenelzine (nardil), selegiline (eldepryl, emsam, zelapar), and tranylcypromine (parnate), or if you have stopped taking one of these medications within the past 2 weeks.tell your doctor and pharmacist what other prescription and nonprescription medications, vitamins, nutritional supplements, and herbal products you are taking or plan to take.tell your doctor if you have or have ever had high blood pressure, diabetes, trouble urinating because of an enlarged prostate gland, or thyroid or heart disease.tell your doctor if you are pregnant, plan to become pregnant, or are breast-feeding. if you become pregnant while taking phenylephrine, call your doctor.if you are having surgery, including dental surgery, tell the doctor or dentist that you are taking phenylephrine.if you have phenylketonuria (pku, an inherited condition in which a special diet must be followed to prevent damage to your brain that can cause severe intellectual disability), you should know that some phenylephrine products may be sweetened with aspartame, a source of phenylalanine.about Phenylephrine')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what special dietary instructions should i follow about Phenylephrine\", kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eedb7e",
   "metadata": {},
   "source": [
    "#### It is working as I expected, we can see the the questions' doc_id are matching the documents' doc_id exactly.\n",
    "#### That means when we search by question. It will firstly match the similar questions, then output the documents which are related to those questions.\n",
    "\n",
    "### Next, I will involve a cross-encoder(ncbi/MedCPT-Cross-Encoder) to rerank the retrieved documents and output top_k(3) most relevant ones.\n",
    "\n",
    "##### This corssEncoder(Bert) model was fine-tuned on 30522 medical related tokens\n",
    "##### The clinical knowledge usually can rank relevance more accuracy.\n",
    "\n",
    "Citation:\n",
    "\n",
    "@article{jin2023medcpt,\n",
    "  title={MedCPT: Contrastive Pre-trained Transformers with large-scale PubMed search logs for zero-shot biomedical information retrieval},\n",
    "  author={Jin, Qiao and Kim, Won and Chen, Qingyu and Comeau, Donald C and Yeganova, Lana and Wilbur, W John and Lu, Zhiyong},\n",
    "  journal={Bioinformatics},\n",
    "  volume={39},\n",
    "  number={11},\n",
    "  pages={btad651},\n",
    "  year={2023},\n",
    "  publisher={Oxford University Press}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c96722e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder_model_id = \"ncbi/MedCPT-Cross-Encoder\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e4813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b2a88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder(cross_encoder_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429847cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functiion leverages cross-encoder to evaluate the original query and the retrieved documents.\n",
    "# It gives every (query, document) pair a score, then sort them.\n",
    "def rerank(query: str, retrieved_docs: list[Document]):\n",
    "    pairs = [[query, d.page_content] for d in retrieved_docs]\n",
    "    scores = cross_encoder.predict(pairs, batch_size=32)\n",
    "    for r_d, score in zip(retrieved_docs, scores):\n",
    "        r_d.metadata[\"rerank_score\"] = float(score)\n",
    "\n",
    "    retrieved_docs.sort(key= lambda d: d.metadata[\"rerank_score\"], reverse=True)\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cfd5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just wrap up all the function before.\n",
    "# 1. retrieve documents -> 2. Rerank documents -> 3. Pick top_k\n",
    "def ask(query: str, retriever, top_k):\n",
    "    retrieved_docs = retriever.invoke(query, kwargs={\"k\":10})\n",
    "    retrieved_docs = copy.deepcopy(retrieved_docs) # Avoid rerank changes original documents\n",
    "    reranked_docs = rerank(query,retrieved_docs)\n",
    "    return reranked_docs[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8dd78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '1bf5880b-93ec-4ac9-a0cb-eb35693ccce4', 'rerank_score': 0.9999985694885254}, page_content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine'),\n",
       " Document(metadata={'doc_id': 'e36207d5-1410-47ca-b68a-05ed7bb7921e', 'rerank_score': 6.946862413315102e-05}, page_content=\"phenylephrine may cause side effects. some side effects can be serious. if you experience any of these symptoms, stop using phenylephrine and call your doctor:nervousnessdizzinesssleeplessnessphenylephrine may cause other side effects. call your doctor if you have any unusual problems while taking Phenylephrine.if you experience a serious side effect, you or your doctor may send a report to the food and drug administration's (fda) medwatch adverse event reporting program online (https://www.fda.gov/safety/medwatch) or by phone ([phone]).\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\",retriever,top_k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a3f36",
   "metadata": {},
   "source": [
    "#### The rerank model is just working so good. Keep it and move next.\n",
    "\n",
    "#### Beside rerank, I think query is the most important thing. As it retrieve most related documents of which a LLM makes use to generate most helpful response.\n",
    "#### But in multi-turn conversation, users don't make a query with every previous details.\n",
    "For example, in the third turn the user really want to ask 'How do I take Phenylephrine?'\n",
    "\n",
    "But he types 'How do I take it?'. From the context, 'it' means 'Phenylephrine'.\n",
    "\n",
    "If we retrieve by query  'How do I take it?', we can get unrelevant document.  'How do I take Phenylephrine?' makes more sense.\n",
    "\n",
    "#### This is why I need to put an agent to transfer the query so that it is aligned to the conversation.\n",
    "#### In this case, I choose short-term memory technique to store history conversation which will support the agent to understand the context.\n",
    "#### If we need long-term memory, I need a memory and session management module with redis and vector DB.\n",
    "\n",
    "#### Let's involve the agent firstly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57594f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory # Short-term Memory\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import torch\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f12ecbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0111a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_dtype():\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.is_bf16_supported():\n",
    "            return torch.bfloat16\n",
    "        else:\n",
    "            return torch.float16\n",
    "        \n",
    "    return torch.float32\n",
    "\n",
    "def best_device():\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79a21aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6038fefadee64df7814efe0d8ccbe1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenizer and base model done!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    dtype = best_dtype(),\n",
    "    device_map={\"\":best_device()}, \n",
    "    low_cpu_mem_usage=True     \n",
    ")\n",
    "print(\"Load tokenizer and base model done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d14ff209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n",
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)                    # full architecture tree (long but useful)\n",
    "print(model.config)             # core hyperparameters (dims, layers, heads…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9879013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "original_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206127a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipeline = HuggingFacePipeline(pipeline=original_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afd489b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_agent = ChatHuggingFace(llm=hug_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18f50d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Short_Term_Memory():\n",
    "    def __init__(self) -> None:        \n",
    "        self.session_store: dict[str,BaseChatMessageHistory] = {}\n",
    "        self.current_session_id = \"\"\n",
    "\n",
    "    def get_history(self, session_id: str) -> BaseChatMessageHistory:        \n",
    "        self.current_session_id = session_id\n",
    "        if session_id not in self.session_store:\n",
    "            self.session_store[session_id] = ChatMessageHistory()\n",
    "        return self.session_store[session_id]\n",
    "    \n",
    "    def get_current_history(self) -> BaseChatMessageHistory:\n",
    "        return self.get_history(self.current_session_id)\n",
    "    \n",
    "    def delete_history(self, session_id: str) -> bool:\n",
    "        if session_id in self.session_store:\n",
    "            d = self.session_store.pop(session_id)\n",
    "            if d:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def delete_current_history(self) -> bool:\n",
    "        return self.delete_history(self.current_session_id)\n",
    "    \n",
    "# Convert history message to a string\n",
    "def history_as_text(history: BaseChatMessageHistory) -> str:\n",
    "    return \"\\n\".join([\n",
    "        f\"{m.type.upper()}: {m.content}\"   # e.g. \"HUMAN: …\" or \"AI: …\"\n",
    "        for m in history.messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c78ff675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "#from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        query: question\n",
    "        generation: LLM generation\n",
    "        history: list of history messages\n",
    "    \"\"\"\n",
    "    query: str    \n",
    "    history: BaseChatMessageHistory\n",
    "    generation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33e97fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node: combine_node will check the global session_id and short_term_memory\n",
    "\n",
    "def combine_node(query: str):\n",
    "    if settings.SESSION_ID == \"\":   \n",
    "        settings.SESSION_ID = str(uuid.uuid4())\n",
    "        settings.SHORT_TERM_MEMORY = Short_Term_Memory()\n",
    "    \n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(settings.SESSION_ID)\n",
    "\n",
    "    return {\"query\": query,\"history\": history, \"generation\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6a60ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First turn: ask a question\n",
    "query_1 = \"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e0e34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_return = combine_node(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5a9fbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?',\n",
       " 'history': InMemoryChatMessageHistory(messages=[]),\n",
       " 'generation': ''}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b6042df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'879ea7fc-cb0e-446f-a97e-fd58821fbc4b'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.SESSION_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96fcdba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine_return[\"history\"].messages) # Check how many message it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d560350",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_return[\"history\"].add_user_message(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8622a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = ask(query_1, retriever, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef4aedf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '1bf5880b-93ec-4ac9-a0cb-eb35693ccce4', 'rerank_score': 0.9999985694885254}, page_content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d9968b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first document is what exactly I am expecting\n",
    "# Put is to history store\n",
    "combine_return[\"history\"].add_ai_message(doc_1[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97968082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', additional_kwargs={}, response_metadata={}), AIMessage(content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_return[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32eefaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second turn: ask a question\n",
    "query_2 = \"How can I use it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20cbbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_return_2 = combine_node(\"How can I use it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2436da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How can I use it?',\n",
       " 'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', additional_kwargs={}, response_metadata={}), AIMessage(content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine', additional_kwargs={}, response_metadata={})]),\n",
       " 'generation': ''}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_return_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765156d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether the LLM can determine the query is related to history documents\n",
    "query_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader for a question. \\n \n",
    "    You need to determine if a question is meaningful, if you don't know the conversation context. \\n    \n",
    "    Here is the user's question: {question} \\n   \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the question is meaningful. \\n     \n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\\n\n",
    "    No premable or explanation.\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "query_grader_chain = query_grader_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "231e44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_grader_chain.invoke({\"question\": query_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "38e1f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "920b7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM can rewrite a query depends on history documents\n",
    "rewrite_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Use the history conversation to resolve references. Keep the contextual meaning. \\n\n",
    "     Here is the history conversation: \\n\\n {document} \\n\\n\n",
    "     Here is the initial question: \\n\\n {question}. Improved question with no preamble: \\n \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "query_rewrite_chain = rewrite_prompt | master_agent | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "db2a12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\n"
     ]
    }
   ],
   "source": [
    "doc_txt = history_as_text(combine_return_2[\"history\"])\n",
    "print(doc_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e2352e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_rewrite_chain.invoke({\"question\": query_2, \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "488550b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How can phenylephrine be used to relieve sinus congestion and pressure?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba3e9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM if can judge the retrieval documents are related to the question enough\n",
    "doc_relevance_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n\n",
    "    If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\\n\n",
    "    No premable or explanation.\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader_chain = doc_relevance_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c0bfbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ask(query_2, retriever, top_k = 2)\n",
    "doc_txt = \" \".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a0912796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pyrethrin and piperonyl butoxide comes as a shampoo to apply to the skin and hair. it is usually applied to the skin and hair in two or three treatments. the second treatment must be applied 7-10 days after the first one. sometimes a third treatment may be necessary, as recommended by your doctor. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. use pyrethrin and piperonyl butoxide shampoo exactly as directed. do not use more or less of it or use it more often than directed on the package label or prescribed by your doctor.the package label gives you an estimate of how much shampoo you will need based on your hair length. be sure to use enough shampoo to cover all of your scalp area and hair.pyrethrin and piperonyl butoxide shampoo should only be used on the skin or hair and scalp. avoid getting pyrethrin and piperonyl butoxide shampoo in your eyes, nose, mouth, or vagina. do not use it on your eyebrows or eyelashes.if pyrethrin and piperonyl butoxide shampoo gets in your eyes, flush them with water right away. if your eyes are still irritated after flushing with water, call your doctor or get medical help right away.to use the shampoo, follow these steps:shake the shampoo well right before use to mix the medication evenly.use a towel to cover your face and eyes. be sure to keep your eyes closed during this treatment. you may need to have an adult help you apply the shampoo.apply pyrethrin and piperonyl butoxide shampoo to your dry hair and scalp area or skin. if you have head lice, begin to apply the shampoo behind your ears and at the back of your neck and then cover all of the hair on your head and scalp.keep the shampoo on for 10 minutes, but no longer. you should use a timer or clock to track the time.after 10 minutes, use a small amount of warm water to form a lather and shampoo as usual. rinse your hair and scalp or skin thoroughly with warm water.if you have head lice, dry your hair with a towel and comb out tangles.a lice comb may also be used to remove the dead lice and nits (empty egg shells) after this treatment. you may also need to have an adult help you to do this.you will need to repeat this entire process in 7-10 days to kill the lice that hatch from eggs.after using pyrethrin and piperonyl butoxide shampoo, sanitize all the clothing, underwear, pajamas, hats, sheets, pillowcases, and towels you have used recently. these items should be washed in very hot water or dry-cleaned. you should also wash combs, brushes, hairs clips and other personal care items in hot water.ask your pharmacist or doctor for a copy of the manufacturer's information for the patient.about Pyrethrin and Piperonyl Butoxide Topical Pyrethrin and Piperonyl Butoxide Topical may be prescribed for other uses; ask your doctor or pharmacist for more information.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retrieval_grader_chain.invoke({\"question\": query_1, \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61ca2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd13437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM if can generate an answer\n",
    "\n",
    "# Prompt\n",
    "answer_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Chain\n",
    "answer_chain = answer_prompt | master_agent | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1053394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "answer_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "030a7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can use pyrethrin and piperonyl butoxide shampoo to treat head lice and scabies. It is applied to the hair and scalp, and then washed off after 10 minutes. Two treatments are usually needed, seven to ten days apart, and a third treatment may be necessary if some lice or nits are still present after the second treatment.\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "generation = answer_chain.invoke({\"context\": docs, \"question\": query_2})\n",
    "print(generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dbb0646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hallucination test\n",
    "# Test the LLM if can determine the answer is grounded in the facts. \n",
    "hallucination_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts. \\n \n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation} \\n\n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\\n     \n",
    "    Don't do preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader_chain = hallucination_grader_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2422029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hallucination_grader_chain.invoke({\"documents\": \"You can use pyrethrin and piperonyl butoxide shampoo to treat head lice and scabies. \", \"generation\": \"pseudoephedrine may cause side effects. \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "52e8d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8bb85",
   "metadata": {},
   "source": [
    "#### It is a point where an agent can transfer \"How can I use it?\" to a retrievable query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b656c6",
   "metadata": {},
   "source": [
    "#### The query rewriting part is working well now.\n",
    "#### But sometimes, the user types questions which have multiply meaning. For example: How can I have phenylephrine?\n",
    "* It could mean \"What is the dosage instruction to take phenylephrine?\"\n",
    "* It also could mean \"Where and how can I buy phenylephrine?\" \n",
    "#### This example remind me to involve Query Decomposition technique which will transfer a query to a few querys in different angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the same LLM model to do the job with different prompt\n",
    "\n",
    "# Test the LLM can rewrite a query depends on history documents\n",
    "expand_query_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a medical doctor. You generate exactly one distinct, clinically-relevant question variants from the user's Original question, \\n \n",
    "     covering different angles (e.g., indications/contraindications, dosing vs. administration, \\n\n",
    "     adult vs. pediatric, interactions vs. adverse effects). \\n\n",
    "     Here is the history conversation: \\n\\n {document} \\n\\n\n",
    "     Here is the initial question: \\n\\n {question}. \\n \n",
    "     Return only one question\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "expand_query_chain = expand_query_prompt | master_agent | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0cbe109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = expand_query_chain.invoke({\"question\": \"How can I have Phenylephrine?\", \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3f34afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What are the potential side effects of using Phenylephrine for extended periods?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc91089",
   "metadata": {},
   "source": [
    "### Using LangGraph to coordinate retriever, reranker, query_rewriter and relevant_grader to work together so that produce most relevant answer.\n",
    "##### First of all, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e118c21",
   "metadata": {},
   "source": [
    "Each node will -\n",
    "\n",
    "1/ Either be a function or a runnable.\n",
    "\n",
    "2/ Modify the state.\n",
    "\n",
    "The edges choose which node to call next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_responser = query_rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0459d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatHuggingFace\nllm\n  Field required [type=missing, input_value={'model_id': 'ContactDoct...ask': 'text-generation'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagesState\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response_model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContactDoctor/Bio-Medical-Llama-3-8B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_query_or_respond\u001b[39m(state: MessagesState):\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model to generate a response based on the current state. Given\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Montr\\AI_Projects\\.venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:324\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m     warnings.warn(\n\u001b[32m    317\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    321\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    330\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Montr\\AI_Projects\\.venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:416\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    413\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_huggingface\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatHuggingFace\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatHuggingFace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    418\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_groq\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Montr\\AI_Projects\\.venv\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:505\u001b[39m, in \u001b[36mChatHuggingFace.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m._resolve_model_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Montr\\AI_Projects\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Montr\\AI_Projects\\.venv\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatHuggingFace\nllm\n  Field required [type=missing, input_value={'model_id': 'ContactDoct...ask': 'text-generation'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "response_model = init_chat_model(model=\"ContactDoctor/Bio-Medical-Llama-3-8B\", model_provider=\"huggingface\", temperature=0.2, task=\"text-generation\")\n",
    "\n",
    "\n",
    "def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"Call the model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n",
    "    \"\"\"\n",
    "    response = (\n",
    "        query_responser\n",
    "        # highlight-next-line\n",
    "        .bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
    "    )\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb646d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "GRADE_PROMPT = (\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question. \\n \"\n",
    "    \"Here is the retrieved document: \\n\\n {context} \\n\\n\"\n",
    "    \"Here is the user question: {question} \\n\"\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\"\n",
    "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\n",
    ")\n",
    "\n",
    "\n",
    "# highlight-next-line\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "\n",
    "\n",
    "#grader_model = init_chat_model(\"openai:gpt-4.1\", temperature=0)\n",
    "grader_model = query_rewriter\n",
    "\n",
    "def grade_documents(\n",
    "    state: MessagesState,\n",
    ") -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    \"\"\"Determine whether the retrieved documents are relevant to the question.\"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    response = (\n",
    "        grader_model\n",
    "        # highlight-next-line\n",
    "        .with_structured_output(GradeDocuments).invoke(\n",
    "            [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    )\n",
    "    score = response.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
