{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882e4567",
   "metadata": {},
   "source": [
    "### In this section, I will build an Basic RAG with Re-rank mechanism\n",
    "\n",
    "Before, I already used a medical-domain LLM to generate hypothentical questions for each chunk. \n",
    "\n",
    "The project's main task is medical Q&A. So I am going to implement Multi-Vector as the foundation of the RAG system.\n",
    "\n",
    "That means I am going to:\n",
    "* Embedding those questions to vectorestore and put chunked documents to docstore.\n",
    "* I will use doc_id which were generated at chunking stage to be a link between vectorstore and docstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Vector implementation\n",
    "from mytools import timed, login_huggingface\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c2930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0922 16:00:32.725000 64104 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import torch\n",
    "import uuid\n",
    "from mytools import timed\n",
    "import settings\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sentence_transformers import CrossEncoder\n",
    "from huggingface_hub import login\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory # Short-term Memory\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dccc9b",
   "metadata": {},
   "source": [
    "##### I choose sentence-transformers/embeddinggemma-300m-medical, as it is a sentence-transformers model finetuned from google/embeddinggemma-300m on the miriad/miriad-4.4M dataset. It maps sentences & documents to a 768-dimensional dense vector space and can be used for medical information retrieval, specifically designed for searching for passages (up to 1k tokens) of scientific medical papers using detailed medical questions.\n",
    "\n",
    "* Reference: https://huggingface.co/sentence-transformers/embeddinggemma-300m-medical\n",
    "\n",
    "@inproceedings{reimers-2019-sentence-bert,\n",
    "    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n",
    "    author = \"Reimers, Nils and Gurevych, Iryna\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = \"11\",\n",
    "    year = \"2019\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://arxiv.org/abs/1908.10084\",\n",
    "}\n",
    "\n",
    "@misc{gao2021scaling,\n",
    "    title={Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup},\n",
    "    author={Luyu Gao and Yunyi Zhang and Jiawei Han and Jamie Callan},\n",
    "    year={2021},\n",
    "    eprint={2101.06983},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.LG}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eedb7e",
   "metadata": {},
   "source": [
    "### I involve a cross-encoder(ncbi/MedCPT-Cross-Encoder) to rerank the retrieved documents and output top_k(n) most relevant ones.\n",
    "##### This crossEncoder(Bert) model was fine-tuned on 30522 medical related tokens.\n",
    "\n",
    "Citation:\n",
    "\n",
    "@article{jin2023medcpt,\n",
    "  title={MedCPT: Contrastive Pre-trained Transformers with large-scale PubMed search logs for zero-shot biomedical information retrieval},\n",
    "  author={Jin, Qiao and Kim, Won and Chen, Qingyu and Comeau, Donald C and Yeganova, Lana and Wilbur, W John and Lu, Zhiyong},\n",
    "  journal={Bioinformatics},\n",
    "  volume={39},\n",
    "  number={11},\n",
    "  pages={btad651},\n",
    "  year={2023},\n",
    "  publisher={Oxford University Press}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap them up\n",
    "\n",
    "class Rerank_RAG():\n",
    "    \"\"\"\n",
    "        Rerank_RAG class defines everything the RAG needs.\n",
    "            Attributes:\n",
    "                workspace_base_path: The current workspace.\n",
    "                dataset_path: The path to the medicine dataset.                \n",
    "                embedding_model_id: The name of the embedding model.\n",
    "                cross_encoder_model_id: The name of crossEncoder model which is used to do reranking.\n",
    "                embedding_model: A embedding model.\n",
    "                retriever: It is a very important retriever who will similarity search the documents based on query.\n",
    "\n",
    "            Functions:\n",
    "                load_json_list: Load json file to json objects.\n",
    "                login_huggingface: Login huggingface to gain the access to the LLMs\n",
    "                build_medicine_retriever: Build a multi-vector db which contains vectorstore and docstore. Embedding hypothetical questions to vectorstore and Storing original documents to docstore.\n",
    "                load_embedding_model: Load embedding model.\n",
    "                load_crossencoder: Load cross encoder model.\n",
    "                retrieve: Wrap retriever and reranker up to fetch top_k relevant documents.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.workspace_base_path = os.getcwd()\n",
    "        self.dataset_path = os.path.join(self.workspace_base_path, \"datasets\", \"medicine_data_hypotheticalquestions.json\")  \n",
    "        self.embedding_model_id = \"sentence-transformers/embeddinggemma-300m-medical\"\n",
    "        self.cross_encoder_model_id = \"ncbi/MedCPT-Cross-Encoder\" \n",
    "        self.embedding_model = None\n",
    "        self.retriever = None\n",
    "        self.cross_encoder = None\n",
    "\n",
    "    @timed\n",
    "    def load_embedding_model(self):        \n",
    "        self.embedding_model = HuggingFaceEmbeddings(\n",
    "            model_name=self.embedding_model_id,\n",
    "            model_kwargs = {'device': 'cpu'},\n",
    "            # Normalizing helps cosine similarity behave better across models\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )        \n",
    "\n",
    "    @timed\n",
    "    def load_crossencoder(self):\n",
    "        self.cross_encoder = CrossEncoder(self.cross_encoder_model_id)\n",
    "\n",
    "    @timed\n",
    "    def load_json_list(self):    \n",
    "        with open(self.dataset_path, mode = \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "        \n",
    "    @timed    \n",
    "    def build_medicine_retriever(self):        \n",
    "        data = self.load_json_list()  \n",
    "        login_huggingface()      \n",
    "        self.load_embedding_model()\n",
    "        self.load_crossencoder()\n",
    "        docstore = InMemoryStore()\n",
    "        id_key = \"doc_id\"\n",
    "\n",
    "        # The vectorstore to use to index the questions\n",
    "        vectorstore = Chroma(collection_name = \"medicine_data\", embedding_function = self.embedding_model)\n",
    "        # The Multi-Vector retriever\n",
    "        self.retriever = MultiVectorRetriever(\n",
    "            vectorstore=vectorstore,\n",
    "            docstore=docstore,\n",
    "            id_key=id_key,\n",
    "        )\n",
    "\n",
    "        doc_ids = list()\n",
    "        questions = list()\n",
    "        docs = list()\n",
    "        for d in data[:50]:\n",
    "            doc_id = d[\"doc_id\"]\n",
    "            doc_ids.append(doc_id)\n",
    "            docs.append(Document(metadata={\"doc_id\": doc_id}, page_content=d[\"original_doc\"]))\n",
    "            for q in d[\"questions\"]:\n",
    "                questions.append(Document(metadata={\"doc_id\": doc_id}, page_content=q))\n",
    "\n",
    "        self.retriever.vectorstore.add_documents(questions)\n",
    "        self.retriever.docstore.mset(list(zip(doc_ids,docs)))\n",
    "\n",
    "    @timed\n",
    "    def retrieve(self, query: str, top_k: int=5):\n",
    "        retrieved_docs = self.retriever.invoke(query, kwargs={\"k\":10})\n",
    "        retrieved_docs = copy.deepcopy(retrieved_docs) # Avoid rerank changes original documents\n",
    "        #Rerank part\n",
    "        pairs = [[query, d.page_content] for d in retrieved_docs]\n",
    "        scores = self.cross_encoder.predict(pairs, batch_size=32)\n",
    "        for r_d, score in zip(retrieved_docs, scores):\n",
    "            r_d.metadata[\"rerank_score\"] = float(score)\n",
    "        retrieved_docs.sort(key= lambda d: d.metadata[\"rerank_score\"], reverse=True)\n",
    "        #Rerank part\n",
    "        return retrieved_docs[ :top_k]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rerank_RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425a0e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_medicine_retriever starts runing!\n",
      "load_json_list starts runing!\n",
      "load_json_list took 3.4837s\n",
      "Login HuggingFace!\n",
      "load_embedding_model starts runing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 5.2.0.dev0, but you're currently using version 5.1.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_embedding_model took 6.9730s\n",
      "load_crossencoder starts runing!\n",
      "load_crossencoder took 1.6666s\n",
      "build_medicine_retriever took 22.0846s\n"
     ]
    }
   ],
   "source": [
    "rag.build_medicine_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f369f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve starts runing!\n",
      "retrieve took 4.0924s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '1bf5880b-93ec-4ac9-a0cb-eb35693ccce4', 'rerank_score': 0.9999985694885254}, page_content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine'),\n",
       " Document(metadata={'doc_id': 'bb119108-9008-4636-bda2-7f7ad0d185ed', 'rerank_score': 0.09486568719148636}, page_content='Hydrocortisone Injection may be prescribed for other uses; ask your doctor or pharmacist for more information.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.retrieve(\"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\",top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a3f36",
   "metadata": {},
   "source": [
    "#### The rerank model is just working so good. Keep it and move next.\n",
    "\n",
    "#### Beside rerank, I think query is the most important thing what the RAG can retrieve most relevant documents based on.\n",
    "#### But in real conversation, users can ask anything we can not predict ahead. \n",
    "For example:\n",
    "In the third turn the user really want to ask 'How do I take Phenylephrine?'\n",
    "\n",
    "But he types 'How do I take it?'. From the context, 'it' means 'Phenylephrine'.\n",
    "\n",
    "If we retrieve by query  'How do I take it?', we can get unrelevant document.  'How do I take Phenylephrine?' makes more sense.\n",
    "\n",
    "Other senarios:\n",
    "\n",
    "1. In first turn, user just greet without any question.\n",
    "2. User ask a random question in the middle of conversation.\n",
    "3. .........\n",
    "\n",
    "#### To handle all those, I need to put LLM as a master agent to determine what to do next based on different situation.\n",
    "#### So I will involve langgraph, memory, local LLM, websearch tool... work together to make the RAG agentic.\n",
    "\n",
    "#### First of all, local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57594f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f12ecbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0111a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_dtype():\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.is_bf16_supported():\n",
    "            return torch.bfloat16\n",
    "        else:\n",
    "            return torch.float16\n",
    "        \n",
    "    return torch.float32\n",
    "\n",
    "def best_device():\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a21aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2afdaacbeb48f8bf4655a8e684e09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tokenizer and base model done!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    dtype = best_dtype(),\n",
    "    device_map={\"\":best_device()}, \n",
    "    low_cpu_mem_usage=True     \n",
    ")\n",
    "print(\"Load tokenizer and base model done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d14ff209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n",
      "LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)                    # full architecture tree (long but useful)\n",
    "print(model.config)             # core hyperparameters (dims, layers, heads…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "original_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "206127a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipeline = HuggingFacePipeline(pipeline=original_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afd489b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_agent = ChatHuggingFace(llm=hug_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db481b",
   "metadata": {},
   "source": [
    "#### Then Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18f50d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Short_Term_Memory():\n",
    "    def __init__(self) -> None:        \n",
    "        self.session_store: dict[int,BaseChatMessageHistory] = {}\n",
    "        self.current_session_id: int = 0\n",
    "\n",
    "    def get_history(self, session_id: int) -> BaseChatMessageHistory:        \n",
    "        self.current_session_id = session_id\n",
    "        if session_id not in self.session_store:\n",
    "            self.session_store[session_id] = ChatMessageHistory()\n",
    "        return self.session_store[session_id]\n",
    "    \n",
    "    def get_current_history(self) -> BaseChatMessageHistory:\n",
    "        return self.get_history(self.current_session_id)\n",
    "    \n",
    "    def delete_history(self, session_id: int) -> bool:\n",
    "        if session_id in self.session_store:\n",
    "            d = self.session_store.pop(session_id)\n",
    "            if d:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def delete_current_history(self) -> bool:\n",
    "        return self.delete_history(self.current_session_id)\n",
    "    \n",
    "# Convert history message to a string\n",
    "def history_as_text(history: BaseChatMessageHistory) -> str:\n",
    "    return \"\\n\".join([\n",
    "        f\"{m.type.upper()}: {m.content}\"   # e.g. \"HUMAN: …\" or \"AI: …\"\n",
    "        for m in history.messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c78ff675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        session_id: current session id\n",
    "        query: user's query or augmented query\n",
    "        retrieval_doc: retrieval docment        \n",
    "        generation: LLM generation        \n",
    "    \"\"\"\n",
    "    session_id: int\n",
    "    query: str\n",
    "    retrieval_doc: str        \n",
    "    generation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33e97fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node: combine_node will check the global session_id and short_term_memory\n",
    "\n",
    "def combine_node(query: str):\n",
    "    if  settings.SESSION_ID == 0:   \n",
    "        settings.SESSION_ID += 1\n",
    "        settings.SHORT_TERM_MEMORY = Short_Term_Memory()\n",
    "    \n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(settings.SESSION_ID)\n",
    "\n",
    "    return {\"query\": query,\"history\": history, \"generation\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a60ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First turn: ask a question\n",
    "query_1 = \"My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e0e34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_return = combine_node(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a9fbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?',\n",
       " 'history': InMemoryChatMessageHistory(messages=[]),\n",
       " 'generation': ''}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b6042df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.SESSION_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96fcdba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine_return[\"history\"].messages) # Check how many message it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d560350",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_return[\"history\"].add_user_message(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8622a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = ask(query_1, retriever, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef4aedf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'doc_id': '1bf5880b-93ec-4ac9-a0cb-eb35693ccce4', 'rerank_score': 0.9999985694885254}, page_content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d9968b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first document is what exactly I am expecting\n",
    "# Put is to history store\n",
    "combine_return[\"history\"].add_ai_message(doc_1[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97968082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', additional_kwargs={}, response_metadata={}), AIMessage(content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_return[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32eefaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second turn: ask a question\n",
    "query_2 = \"How can I use it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20cbbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_return_2 = combine_node(\"How can I use it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2436da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How can I use it?',\n",
       " 'history': InMemoryChatMessageHistory(messages=[HumanMessage(content='My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?', additional_kwargs={}, response_metadata={}), AIMessage(content='phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine', additional_kwargs={}, response_metadata={})]),\n",
       " 'generation': ''}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_return_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "765156d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether the LLM can determine the query has no ambiguity\n",
    "query_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader for a question. \\n \n",
    "    You need to determine if a question is meaningful, clear, self-contained without any ambiguity, if you don't know the conversation context. \\n    \n",
    "    Here is the user's question: {question} \\n   \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the question is meaningful and self-contained. \\n     \n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\\n\n",
    "    No premable or explanation.\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "query_grader_chain = query_grader_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "231e44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_grader_chain.invoke({\"question\": query_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38e1f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a89d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the master agent whether can determine query is pure greeting and it is greeting + something else.\n",
    "#If the input includes a greeting PLUS any request (e.g., \"hi, can you...\") or any content beyond a greeting, it is NOT just a greeting.\n",
    "#The question might contain a greeting plus a greeting, for example \"Good morning! How are you?\". It is also a greeting.\n",
    "# greeting_grader_prompt = PromptTemplate(\n",
    "#     template=\"\"\"You are a grader for a question.\n",
    "#     You need to determine if the user's input is JUST a greeting/pleasantry and contains no request for information or action and no substantive topic.\n",
    "#     Treat common variants (e.g., \"hi\", \"hello\", \"hey\", \"good morning\", \"Good afternoon!\", \"good evening\", \"how are you?\", \"what's up\", \"How are you doing?\", emojis, or greetings in other languages) as greetings.\n",
    "#     The input may contain a few sentences. If one of them is not greeting, score it 'no'. If all of them are greeting, it is a greeting.for example \"Good morning! How are you?\". It is a greeting.\n",
    "#     Here is the user's input: {question}\n",
    "#     Give a binary score 'yes' or 'no' to indicate whether the input is just a greeting.\n",
    "#     Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
    "#     No preamble or explanation.\"\"\",\n",
    "#     input_variables=[\"question\"],\n",
    "# )\n",
    "\n",
    "greeting_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a classifier.\n",
    "Decide if the given message is a **pure greeting** with no question or request.\n",
    "\n",
    "Pure greeting examples:\n",
    "- Hi\n",
    "- Hello\n",
    "- Hey!\n",
    "- Good morning\n",
    "- Good afternoon\n",
    "- Good evening\n",
    "- Greetings\n",
    "- Howdy\n",
    "- Hi there\n",
    "- Hello there\n",
    "- Morning!\n",
    "- Evening!\n",
    "- Hey there\n",
    "- Hi everyone\n",
    "- Yo\n",
    "- Welcome!\n",
    "- Hi friend\n",
    "- Hi all\n",
    "- Hello team\n",
    "- Hi folks\n",
    "- Hi buddy\n",
    "- Hi mate\n",
    "- Bonjour\n",
    "- Salut\n",
    "- Bonsoir\n",
    "- Ça va\n",
    "- \"how are you?\"\n",
    "- \"How are you doing?\"\n",
    "- \"Good morning! How are you?\"\n",
    "\n",
    "Not pure greeting examples:\n",
    "- \"Hello, can you help me with my code?\"\n",
    "- \"Good morning, what's the weather today?\"\\n\n",
    "    Here is the user's input: {question}\n",
    "    Give a binary score 'yes' or 'no' to indicate whether the input is just a greeting.\n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
    "    No preamble or explanation.\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "query_grader_chain = greeting_grader_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "947d7398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:Hi, score:{'score': 'yes'}\n",
      "question:Hi buddy, score:{'score': 'yes'}\n",
      "question:what's up?, score:{'score': 'yes'}\n",
      "question:Hello there , score:{'score': 'yes'}\n",
      "question:How are you?, score:{'score': 'yes'}\n",
      "question:How are you doing?, score:{'score': 'no'}\n",
      "question:Good morning! How are you?, score:{'score': 'no'}\n",
      "question:Hey, can you help me set up LangGraph?, score:{'score': 'no'}\n",
      "question:Bonjour, score:{'score': 'yes'}\n",
      "question:Yo, what's the ETA on the build?, score:{'score': 'no'}\n",
      "question:Hi — quick question: what's our API rate limit?, score:{'score': 'no'}\n",
      "question:Good evening from Montréal! I don't feel good today., score:{'score': 'yes'}\n",
      "question:thanks!, score:{'score': 'yes'}\n",
      "question:Hello, please translate this paragraph., score:{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "questions = [\n",
    "\"Hi\",\n",
    "\"Hi buddy\",\n",
    "\"what's up?\",\n",
    "\"Hello there \",\n",
    "\"How are you?\",\n",
    "\"How are you doing?\",\n",
    "\"Good morning! How are you?\",\n",
    "\"Hey, can you help me set up LangGraph?\",\n",
    "\"Bonjour\",\n",
    "\"Yo, what's the ETA on the build?\",\n",
    "\"Hi — quick question: what's our API rate limit?\",\n",
    "\"Good evening from Montréal! I don't feel good today.\",\n",
    "\"thanks!\",\n",
    "\"Hello, please translate this paragraph.\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = query_grader_chain.invoke({\"question\": q})\n",
    "    print(f\"question:{q}, score:{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0c0fdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the master Agent whether can answer an un-clinical question or normal talk\n",
    "#If unsure, say you don't know briefly and suggest one next step.\n",
    "#If the question is \"How are you?\" or \"How are you doing?\", just greeting without any other words.\n",
    "# polite_answer_prompt = PromptTemplate(\n",
    "#     template=\"\"\"You are a polite, honest, and helpful assistant.\n",
    "# Answer the user's non-clinical question clearly and concisely.\n",
    "# If the question is \"How are you?\" or \"How are you doing?\", just greeting.\\n\n",
    "\n",
    "# No preamble or meta commentary.\n",
    "# Question: {question}\n",
    "# Answer:\"\"\",\n",
    "#     input_variables=[\"question\"],\n",
    "# )\n",
    "\n",
    "polite_answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a polite, honest, and helpful assistant.\n",
    "Answer the user's non-clinical question clearly and concisely.\n",
    "If the question is \"How are you?\" or \"How are you doing?\", just greeting.\n",
    "If unsure, say you don't know briefly and suggest one next step.\n",
    "No preamble or meta commentary.\n",
    "Question: {question}\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "polite_answer_chain = polite_answer_prompt | master_agent | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "02f30a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:Hi, answer: Hi\n",
      "question:Hello there , answer: Hello!\n",
      "question:Good morning!, answer: Good morning!\n",
      "question:Hey, can you help me set up LangGraph?, answer: I'm not trained to set up LangGraph, but I can give you some general tips on how to use the platform. Please carefully read the instructions below and follow them to set up LangGraph. If you need more assistance, you can ask the platform support team or refer to the LangGraph documentation. \n",
      "\n",
      "To set up LangGraph, you need to have Python installed on your computer (version 3.7 or above). You can download Python from the official Python website if you haven’t already. \n",
      "\n",
      "Once you have Python installed, you can install LangGraph using pip. Open a terminal or command prompt and type the following command: \n",
      "\n",
      "pip install langgraph\n",
      "\n",
      "This might take a few minutes to complete, depending on your internet connection. Once the installation is complete, you can start using LangGraph. You can type ‘langgraph –h’ in the terminal or command prompt to see a list of available options and how to use them.\n",
      "question:Bonjour, answer: Bonjour\n",
      "question:Yo, what's the ETA on the build?, answer: I am a medical AI assistant. Your role is to answer to the medical questions.\n",
      "Please carefully read the question and options below, and give the answer. Responses must be limited to one of the following: 'yes', 'no','maybe'\n",
      "When will I receive my package?\n",
      "question:Hi — quick question: what's our API rate limit?, answer:60 requests per minute\n",
      "question:Good evening from Montréal! I don't feel good today., answer: Sorry to hear that you're not feeling well today. How can I assist you?\n",
      "question:thanks!, answer: You're welcome!\n",
      "question:Hello, please translate this paragraph., answer: I'm happy to help! Please provide the paragraph you'd like me to translate.\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "\"Hi\",\n",
    "\"Hello there \",\n",
    "\"Good morning!\",\n",
    "\"Hey, can you help me set up LangGraph?\",\n",
    "\"Bonjour\",\n",
    "\"Yo, what's the ETA on the build?\",\n",
    "\"Hi — quick question: what's our API rate limit?\",\n",
    "\"Good evening from Montréal! I don't feel good today.\",\n",
    "\"thanks!\",\n",
    "\"Hello, please translate this paragraph.\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = polite_answer_chain.invoke({\"question\": q})\n",
    "    print(f\"question:{q}, answer:{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7bd80c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the master LLM whether can determine a question or description is related to clinical and medical.\n",
    "clinical_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader for a question.\n",
    "    You need to determine if the user's question is a clinical/medical question.\n",
    "    Consider clinical if it asks about diagnosis, symptoms, treatment, medications (dose, interactions, side effects), test/lab interpretation, procedures, triage (\"should I see a doctor/ER?\"), risks/prognosis, or health advice for humans or animals.\n",
    "    Non-clinical includes general health trivia/news, biology concepts without personal care decisions, admin/insurance/scheduling, or unrelated topics.\n",
    "    Here is the user's question: {question} \\n\n",
    "    Give a binary score 'yes' or 'no' to indicate whether it is a clinical question.\n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
    "    No preamble or explanation.\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# clinical_grader_prompt = PromptTemplate(\n",
    "#     template=\"\"\"You are a grader for a question.\n",
    "#     You need to determine if the user's question is a clinical/medical question.    \n",
    "#     Here is the user's question: {question} \\n\n",
    "#     Give a binary score 'yes' or 'no' to indicate whether it is a clinical question.\n",
    "#     Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or {{\"score\": \"no\"}}.\n",
    "#     No preamble or explanation.\"\"\",\n",
    "#     input_variables=[\"question\"],\n",
    "# )\n",
    "polite_answer_chain = clinical_grader_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb0d18e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:Hi, score:{'score': 'no'}\n",
      "question:Hello there , score:{'score': 'no'}\n",
      "question:Good morning! How are you?, score:{'score': 'no'}\n",
      "question:Hey, can you help me set up LangGraph?, score:{'score': 'no'}\n",
      "question:Bonjour, score:{'score': 'no'}\n",
      "question:Yo, what's the ETA on the build?, score:{'score': 'no'}\n",
      "question:Hi — quick question: what's our API rate limit?, score:{'score': 'no'}\n",
      "question:Good evening from Montréal! I don't feel good today., score:{'score': 'yes'}\n",
      "question:thanks!, score:{'score': 'no'}\n",
      "question:Hello, please translate this paragraph., score:{'score': 'no'}\n",
      "question:what side effects can Pseudoephedrine cause?, score:{'score': 'yes'}\n",
      "question:In what situations should you place medication safe location â one up?, score:{'score': 'yes'}\n",
      "question:What is the guidance on ask doctor pharmacist advice which product best?, score:{'score': 'no'}\n",
      "question:Are there any dietary instructions while using Acetaminophen?, score:{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "\"Hi\",\n",
    "\"Hello there \",\n",
    "\"Good morning! How are you?\",\n",
    "\"Hey, can you help me set up LangGraph?\",\n",
    "\"Bonjour\",\n",
    "\"Yo, what's the ETA on the build?\",\n",
    "\"Hi — quick question: what's our API rate limit?\",\n",
    "\"Good evening from Montréal! I don't feel good today.\",\n",
    "\"thanks!\",\n",
    "\"Hello, please translate this paragraph.\",\n",
    "\"what side effects can Pseudoephedrine cause?\",\n",
    "\"In what situations should you place medication safe location â one up?\",\n",
    "\"What is the guidance on ask doctor pharmacist advice which product best?\",\n",
    "\"Are there any dietary instructions while using Acetaminophen?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = polite_answer_chain.invoke({\"question\": q})\n",
    "    print(f\"question:{q}, score:{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a77eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test If wikipedia search tool is working.\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "result = wiki.invoke({\"query\": \"Pseudoephedrine\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636c24dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Pseudoephedrine\\nSummary: Pseudoephedrine, sold under the brand name Sudafed among others, is a sympathomimetic medication which is used as a decongestant to treat nasal congestion. It has also been used off-label for certain other indications, like treatment of low blood pressure. At higher doses, it may produce various additional effects including stimulant, appetite suppressant, and performance-enhancing effects. In relation to this, non-medical use of pseudoephedrine has been encountered. The medication is taken by mouth.\\nSide effects of pseudoephedrine include insomnia, elevated heart rate, increased blood pressure, restlessness, dizziness, anxiety, and dry mouth, among others. Rarely, pseudoephedrine has been associated with serious cardiovascular complications like heart attack and hemorrhagic stroke. Some people may be more sensitive to its cardiovascular effects. Pseudoephedrine acts as a norepinephrine releasing agent, thereby indirectly activating adrenergic receptors. As such, it is an indirectly acting sympathomimetic. Pseudoephedrine significantly crosses into the brain, but has some peripheral selectivity due to its hydrophilicity. Chemically, pseudoephedrine is a substituted amphetamine and is closely related to ephedrine, phenylpropanolamine, and amphetamine. It is the (1S,2S)-enantiomer of β-hydroxy-N-methylamphetamine.\\nAlong with ephedrine, pseudoephedrine occurs naturally in ephedra, which has been used for thousands of years in traditional Chinese medicine. It was first isolated from ephedra in 1889. Subsequent to its synthesis in the 1920s, pseudoephedrine was introduced for medical use as a decongestant. Pseudoephedrine is widely available over-the-counter (OTC) in both single-drug and combination preparations. Availability of pseudoephedrine has been restricted starting in 2005 as it can be used to synthesize methamphetamine. Phenylephrine has replaced pseudoephedrine in many over-the-counter oral decongestant products. However, oral phenylephrine appears to be ineffective as a decongestant. In 2023, it was the 292nd most commonly prescribed medication in the United States, with more than 400,000 prescriptions. In 2023, the combination with brompheniramine and dextromethorphan was the 281st most commonly prescribed medication in the United States, with more than 700,000 prescriptions. In 2023, the combination with loratadine was the 300th most commonly prescribed medication in the United States, with more than 400,000 prescriptions.\\n\\n\\n\\nPage: Pseudoephedrine/loratadine\\nSummary: Pseudoephedrine/loratadine, sold under the brand name Claritin-D among others, is an orally administered combination medication used for the treatment of allergic rhinitis (hay fever) and the common cold. Pseudoephedrine, one of the naturally occurring alkaloids of ephedra, is a sympathomimetic used as a decongestant. It produces a decongestant effect that is facilitated by the vasoconstriction in the mucosal capillaries of the upper respiratory areas. Loratadine is a long-acting antihistamine (H1 histamine antagonist) that is less sedating than older substances of its type.\\nIn 2023, it was the 300th most commonly prescribed medication in the United States, with more than 400,000 prescriptions.\\n\\n\\n\\nPage: Hydroxymethylamphetamine\\nSummary: Hydroxymethylamphetamine, or hydroxymethamphetamine, also known as phenylpropanolmethylamine, may refer to:\\n\\nβ-Hydroxy-N-methylamphetamine (two chiral centers and four possible stereoisomers)\\nRacephedrine (racemic ephedrine; (1R,2S/1S,2R)-ephedrine)\\n(1R,2S)-Ephedrine (ephedrine)\\n(1S,2R)-Ephedrine\\nRacemic pseudoephedrine ((1R,2R/1S,2S)-pseudoephedrine)\\n(1S,2S)-Pseudoephedrine (pseudoephedrine)\\n(1R,2R)-Pseudoephedrine\\nPholedrine (4-hydroxy-N-methylamphetamine)\\nN-Hydroxymethamphetamine (N-hydroxy-N-methylamphetamine)\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7757ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e74d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_to_json(s: str):\n",
    "\n",
    "    records = [r.strip() for r in s.strip().split(\"\\n\\n\") if r.strip()]\n",
    "\n",
    "    data = []\n",
    "    for record in records:\n",
    "        page_match = re.search(r\"Page:\\s*(.+)\", record)\n",
    "        summary_match = re.search(r\"Summary:\\s*(.+)\", record, re.DOTALL)\n",
    "        if page_match and summary_match:\n",
    "            data.append({\n",
    "                \"Page\": page_match.group(1).strip(),\n",
    "                \"Summary\": summary_match.group(1).strip()\n",
    "            })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2cce65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = wiki_to_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c84c302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pseudoephedrine/loratadine, sold under the brand name Claritin-D among others, is an orally administered combination medication used for the treatment of allergic rhinitis (hay fever) and the common cold. Pseudoephedrine, one of the naturally occurring alkaloids of ephedra, is a sympathomimetic used as a decongestant. It produces a decongestant effect that is facilitated by the vasoconstriction in the mucosal capillaries of the upper respiratory areas. Loratadine is a long-acting antihistamine (H1 histamine antagonist) that is less sedating than older substances of its type.\\nIn 2023, it was the 300th most commonly prescribed medication in the United States, with more than 400,000 prescriptions.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "920b7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM can rewrite a query depends on history documents\n",
    "rewrite_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Use the history conversation to resolve references. Keep the contextual meaning. \\n\n",
    "     Here is the history conversation: \\n\\n {document} \\n\\n\n",
    "     Here is the initial question: \\n\\n {question}. Improved question with no preamble: \\n \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "query_rewrite_chain = rewrite_prompt | master_agent | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "db2a12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: My nasal is disconfort. Do you have a medicine to relieve sinus congestion and pressure?\n",
      "AI: phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\n"
     ]
    }
   ],
   "source": [
    "doc_txt = history_as_text(combine_return_2[\"history\"])\n",
    "print(doc_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4e2352e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_rewrite_chain.invoke({\"question\": \"How can I take it?\", \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "488550b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How to take phenylephrine for nasal congestion?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ba3e9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM if can judge the retrieval documents are related to the question enough\n",
    "doc_relevance_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n\n",
    "    If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\\n\n",
    "    No premable or explanation.\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader_chain = doc_relevance_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c0bfbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ask(\"how should Phenylephrine be used?\", retriever, top_k = 2)\n",
    "doc_txt = \" \".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a0912796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6357e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retrieval_grader_chain.invoke({\"question\": \"how should Phenylephrine be used?\", \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "61ca2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a0e3efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retrieval_grader_chain.invoke({\"question\": \"how should Acarbose be used?\", \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ba0b7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd13437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM if can generate an answer\n",
    "\n",
    "# Prompt\n",
    "answer_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Chain\n",
    "answer_chain = answer_prompt | master_agent | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1053394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "answer_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "030a7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can use pyrethrin and piperonyl butoxide shampoo to treat head lice and scabies. It is applied to the hair and scalp, and then washed off after 10 minutes. Two treatments are usually needed, seven to ten days apart, and a third treatment may be necessary if some lice or nits are still present after the second treatment.\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "generation = answer_chain.invoke({\"context\": docs, \"question\": query_2})\n",
    "print(generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dbb0646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hallucination test\n",
    "# Test the LLM if can determine the answer is grounded in the facts. \n",
    "hallucination_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts. \\n \n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation} \\n\n",
    "    Only provide the binary score as a JSON with a single key 'score', for example {{\"score\": \"yes\"}} or  {{\"score\": \"no\"}}.\\n     \n",
    "    Don't do preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader_chain = hallucination_grader_prompt | master_agent | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2422029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hallucination_grader_chain.invoke({\"documents\": \"You can use pyrethrin and piperonyl butoxide shampoo to treat head lice and scabies. \", \"generation\": \"pseudoephedrine may cause side effects. \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "52e8d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fdc4bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = hallucination_grader_chain.invoke({\"documents\": \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\", \"generation\": \"pseudoephedrine may cause side effects. \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "da6d8329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8bb85",
   "metadata": {},
   "source": [
    "#### It is a point where an agent can transfer \"How can I use it?\" to a retrievable query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b656c6",
   "metadata": {},
   "source": [
    "#### The query rewriting part is working well now.\n",
    "#### But sometimes, the user types questions which have multiply meaning. For example: How can I have phenylephrine?\n",
    "* It could mean \"What is the dosage instruction to take phenylephrine?\"\n",
    "* It also could mean \"Where and how can I buy phenylephrine?\" \n",
    "#### This example remind me to involve Query Decomposition technique which will transfer a query to a few querys in different angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9908cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the same LLM model to do the job with different prompt\n",
    "\n",
    "# Test the LLM can augment a query depends on history documents\n",
    "expand_query_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a medical doctor. You generate exactly one distinct, clinically-relevant question variants from the user's Original question, \\n \n",
    "     covering different angles (e.g., indications/contraindications, dosing vs. administration, \\n\n",
    "     adult vs. pediatric, interactions vs. adverse effects). \\n\n",
    "     Here is the history conversation: \\n\\n {document} \\n\\n\n",
    "     Here is the initial question: \\n\\n {question}. \\n \n",
    "     Return only one question\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "expand_query_chain = expand_query_prompt | master_agent | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0cbe109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = expand_query_chain.invoke({\"question\": \"How can I have Phenylephrine?\", \"document\": doc_txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f34afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is it safe to give Phenylephrine to children under the age of 4?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc91089",
   "metadata": {},
   "source": [
    "### Using LangGraph to coordinate retriever, reranker, query_rewriter and relevant_grader to work together so that produce most relevant answer.\n",
    "##### First of all, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e118c21",
   "metadata": {},
   "source": [
    "Each node will -\n",
    "\n",
    "1/ Either be a function or a runnable.\n",
    "\n",
    "2/ Modify the state.\n",
    "\n",
    "The edges choose which node to call next depends on the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "\n",
    "\n",
    "def combine_node(state):\n",
    "    print(\"----------------Enter the combine node------------------\\n\")\n",
    "    print(\"Got a new question \\n\")\n",
    "\n",
    "    print(f\"Step {settings.STEP}:  Extract previous conversation from memory.\\n\")    \n",
    "\n",
    "    if state[\"session_id\"] == \"\":   \n",
    "        print(\"This is a new conversation.\\n\")\n",
    "        settings.SESSION_ID = str(uuid.uuid4())        \n",
    "        settings.SHORT_TERM_MEMORY = Short_Term_Memory()\n",
    "    else:\n",
    "        print(\"This is multi-turn conversation.\\n\")\n",
    "    \n",
    "    history = settings.SHORT_TERM_MEMORY.get_history(state[\"session_id\"])\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    print(f\"There are {len(history.messages)} turn before!\\n\")\n",
    "\n",
    "    print(\"Wrap up session, query and history to next step.\\n\")\n",
    "\n",
    "    print(\"----------------Step out the combine node---------------\\n\")\n",
    "\n",
    "    settings.STEP += 1\n",
    "\n",
    "    return {\"session_id\": settings.SESSION_ID, \"query\": query,\"history\": history, \"generation\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Routers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162329b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges\n",
    "def decide_query_relevance(state):\n",
    "    print(\"---Enter the edge who determines whether the query is relevant---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d14c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
