{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb877d9c",
   "metadata": {},
   "source": [
    "## MediPal -- LLM test and select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7cfa1",
   "metadata": {},
   "source": [
    "### In this section, I set three tasks to test three small LLMs' performance, so that I can understand them and design the application properly.\n",
    "##### Tasks:\n",
    "1. Reasoning\n",
    "2. Generate questions based on content\n",
    "3. Solve Yes or No question\n",
    "4. Structured ouput\n",
    "\n",
    "##### Target LLMs:\n",
    "1. meta-llama/Llama-3.2-1B-Instruct \n",
    "2. meta-llama/Meta-Llama-3-8B-Instruct\n",
    "3. ContactDoctor/Bio-Medical-Llama-3-8B\n",
    "\n",
    "##### Why test Bio-Medical-Llama-3-8B？\n",
    "\n",
    "Bio-Medical-Llama-3-8B model is a specialized large language model designed for biomedical applications. It is finetuned from the meta-llama/Meta-Llama-3-8B-Instruct model using a custom dataset containing over 500,000 diverse entries. These entries include a mix of synthetic and manually curated data, ensuring high quality and broad coverage of biomedical topics.\n",
    "\n",
    "The model is trained to understand and generate text related to various biomedical fields, making it a valuable tool for researchers, clinicians, and other professionals in the biomedical domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e0a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_dtype():\n",
    "    \"\"\"Return the best dtype for the device\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.is_bf16_supported():\n",
    "            return torch.bfloat16\n",
    "        else:\n",
    "            return torch.float16\n",
    "        \n",
    "    return torch.float32\n",
    "\n",
    "def best_device():\n",
    "    \"\"\"Return the device type\"\"\"\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def login_huggingface():\n",
    "    \"\"\"Login HaggingFace\"\"\"\n",
    "    load_dotenv()\n",
    "    login(os.getenv(\"HUGGINGFACE_KEY\"))\n",
    "    print(\"Login HuggingFace!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a849037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login HuggingFace!\n"
     ]
    }
   ],
   "source": [
    "login_huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974779f",
   "metadata": {},
   "source": [
    "##### Task1: Reasoning\n",
    "##### Prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e2aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_last_letters_basic = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a precise but brief problem-solver. \"\n",
    "     \"Explain your reasoning in a few short steps labeled 'Step 1:', 'Step 2:', 'Step 3:' etc., \"\n",
    "     \"then end with a single line 'Result: <value>'. Avoid long explanations.\"),\n",
    "    (\"human\",\n",
    "     \"Given three English words: {w1}, {w2}, {w3}.\\n\"\n",
    "     \"Task:\\n\"\n",
    "     \"- For each word, ignore trailing spaces/punctuation and find the last alphabetic letter (A–Z/a–z).\\n\"\n",
    "     \"- Concatenate these three letters in the SAME order (word1 → word2 → word3).\\n\"\n",
    "     \"- For example, you got 'how', 'are', 'you', each word's last letter are 'w', 'e', 'u'. Output: 'weu'  .\\n\"\n",
    "     \"Output:\\n\"\n",
    "     \"- Write step-by-step text (Step 1/2/3...).\\n\"\n",
    "     \"- End with one final line: Result: <concatenated_string>.\")\n",
    "])\n",
    "\n",
    "prompt_simple_math = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a precise but brief math tutor. \"\n",
    "     \"Explain in short steps labeled 'Step 1:', 'Step 2:', ... \"\n",
    "     \"then finish with a single line 'Result: <number>'.\"),\n",
    "    (\"human\",\n",
    "     \"John has 5 apples. His father has 8 apples. He gives 2 apples to his father. \"\n",
    "     \"How many apples does his father have?\\n\"\n",
    "     \"Solve step by step and end with: Result: <number>.\")\n",
    "])\n",
    "\n",
    "prompt_moderate_math = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a precise but brief math tutor. \"\n",
    "     \"Explain in short steps labeled 'Step 1:', 'Step 2:', ... \"\n",
    "     \"then finish with a single line 'Result: <number>'.\"),\n",
    "    (\"human\",\n",
    "     \"John has 12 apples. His father has 9 apples. John gives 3 apples to his father. \"\n",
    "     \"Then John's father gives one-third (1/3) of his apples to John's sister. \"\n",
    "     \"John's sister eats 2 apples and returns the rest to John. \"\n",
    "     \"How many apples does John have at the end?\\n\"\n",
    "     \"Solve step by step and end with: Result: <number>.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb4252",
   "metadata": {},
   "source": [
    "##### Task2: Generate questions based on content\n",
    "##### Prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae6746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_generate_questions = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a cautious medical student who generates clinically relevant, self-contained questions. \"\n",
    "     \"Ground every question strictly in the provided document; do not invent details or rely on outside knowledge.\"),\n",
    "    (\"user\",\n",
    "     \"Instructions:\\n\"\n",
    "     \"1) From the document below, write exactly 3 unique QUESTIONS in English only.\\n\"\n",
    "     \"2) Cover different medical perspectives (aim for breadth), such as: symptoms/signs; diagnosis/differential; \"\n",
    "     \"investigations/labs/imaging; treatment/procedures; medications (dose, interactions, adverse effects); \"\n",
    "     \"contraindications/precautions; risk factors/prognosis; prevention/patient counseling; special populations \"\n",
    "     \"(e.g., pregnancy, breastfeeding, pediatrics, geriatrics).\\n\"\n",
    "     \"3) Each question must be concise (≤ 25 words), self-contained (avoid pronouns like 'it/this/that'), and \"\n",
    "     \"directly supported by the document.\\n\"\n",
    "     \"4) Do NOT provide any answers or explanations.\\n\"\n",
    "     \"5) Return ONLY a JSON list that matches exactly this schema: [\\\"question1\\\", \\\"question2\\\", ..., \\\"question3\\\"]\\n\"\n",
    "     \"6) Enclose the JSON list between <json> and </json> tags.\\n\"\n",
    "     \"7) If the document does not support 3 distinct perspectives, still produce 3 questions but avoid near-duplicates; \"\n",
    "     \"prefer covering as many perspectives as possible.\"),\n",
    "    (\"user\", \"Document:\\n{doc}\\n\")\n",
    "])\n",
    "\n",
    "contents = [\n",
    "    \"phenylephrine is used to relieve nasal discomfort caused by colds, allergies, and hay fever. it is also used to relieve sinus congestion and pressure. phenylephrine will relieve symptoms but will not treat the cause of the symptoms or speed recovery. phenylephrine is in a class of medications called nasal decongestants. it works by reducing swelling of the blood vessels in the nasal passages.about Phenylephrine\",\n",
    "    \"Sinner's physical struggles appeared to begin late in the second set, and he rushed to place ice towels around his neck at the changeover before the start of the third. In the decider, the Italian was limping between points and frequently massaged his right thigh. At the 2-1 changeover, he didn't sit and instead put his legs up on his bench to try and ward off cramp.\",\n",
    "    \"Artificial intelligence (AI) investing is still the dominant theme in the stock market. This checks out, as it's where a massive amount of capital is getting invested to build out computing infrastructure and train models. Although it seems like AI has been the prevailing market theme for some time, there are multiple indications that this will persist for several more years, making AI a great place to invest today.\",\n",
    "    \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\",\n",
    "    \"if you are taking scheduled doses of aluminum hydroxide, magnesium hydroxide, take the missed dose as soon as you remember it. however, if it is almost time for the next dose, skip the missed dose and continue your regular dosing schedule. do not take a double dose to make up for a missed one.about Aluminum Hydroxide and Magnesium Hydroxide\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9301b",
   "metadata": {},
   "source": [
    "##### Task 3 and 4: Solve Yes or No question\n",
    "##### Prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2a029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_self_contained = PromptTemplate(\n",
    "        template=\"\"\"You are a grader for a question.\n",
    "    You must decide whether the question is self-contained—meaning that it is clear, meaningful, and understandable on its own, without any conversation history or external context.\n",
    "    Here is the user's question: {question} \\n\n",
    "    Return a binary judgment as a JSON object with a single key \"score\".\n",
    "    Respond only with {{\"score\": \"yes\"}} if the question is self-contained,\n",
    "    or {{\"score\": \"no\"}} if it is not. Do not include any explanation or extra text.\"\"\",\n",
    "        input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "self_contained_questions = [\n",
    "    {\"question\":\"What is the tallest mountain in South America?\", \"expect\":\"\"\"{\"score\": \"yes\"}\"\"\"},   \n",
    "    {\"question\":\"Can you think about it?\", \"expect\":\"\"\"{\"score\": \"no\"}\"\"\"},   \n",
    "    {\"question\":\"Can you explain how blockchain technology works?\", \"expect\":\"\"\"{\"score\": \"yes\"}\"\"\"},  \n",
    "    {\"question\":\"Do you have a medicine to relieve sinus congestion and pressure?\", \"expect\":\"\"\"{\"score\": \"yes\"}\"\"\"},        \n",
    "    {\"question\":\"How can I take it?\", \"expect\":\"\"\"{\"score\": \"no\"}\"\"\"},          \n",
    "    {\"question\": \"Who discovered penicillin?\", \"expect\": \"\"\"{\"score\": \"yes\"}\"\"\"},  \n",
    "    {\"question\": \"Can you tell me more about it?\", \"expect\": \"\"\"{\"score\": \"no\"}\"\"\"},  \n",
    "    {\"question\": \"What are the side effects of ibuprofen?\", \"expect\": \"\"\"{\"score\": \"yes\"}\"\"\"},  \n",
    "    {\"question\": \"Why do you think so?\", \"expect\": \"\"\"{\"score\": \"no\"}\"\"\"},  \n",
    "    {\"question\": \"What is the capital city of Japan?\", \"expect\": \"\"\"{\"score\": \"yes\"}\"\"\"},  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e017ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_related_question = PromptTemplate(\n",
    "        template=\"\"\"You are a conversation coherence grader.\n",
    "        Your task is to decide whether the user's latest message is logically and topically connected to the previous conversation.\n",
    "\n",
    "        Conversation history:\n",
    "        {document}\n",
    "\n",
    "        User's latest message:\n",
    "        {question}\n",
    "\n",
    "        Return only a JSON object with a single key \"score\":\n",
    "        - {{\"score\": \"yes\"}} if the latest message is coherent and contextually related to the conversation history.\n",
    "        - {{\"score\": \"no\"}} if it is not related or breaks the context.\n",
    "\n",
    "        No explanation or extra text.\"\"\",\n",
    "        input_variables=[\"document\", \"question\"],\n",
    "    )  \n",
    "\n",
    "documents = [\n",
    "    \"\"\"AI: phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed.\\n \n",
    "             HUMAN: What form does Phenylephrine come? \"\"\",\n",
    "\n",
    "    \"\"\"Sinner's physical struggles appeared to begin late in the second set, and he rushed to place ice towels around his neck at the changeover\"\"\",\n",
    "             \n",
    "    \"\"\"AI: amoxicillin is available as a capsule, tablet, chewable tablet, and liquid suspension to take by mouth.\\n \n",
    "       HUMAN: What forms does amoxicillin come in?\"\"\",\n",
    "\n",
    "    \"\"\"AI: metformin is usually taken once or twice daily with meals to reduce stomach upset.\\n \n",
    "       HUMAN: When should I take metformin?\"\"\",\n",
    "\n",
    "    \"\"\"AI: ibuprofen works by reducing hormones that cause inflammation and pain in the body.\\n \n",
    "       HUMAN: How does ibuprofen work?\"\"\",\n",
    "\n",
    "    \"\"\"AI: loratadine may cause headache, dry mouth, or drowsiness in some people.\\n \n",
    "       HUMAN: What are common side effects of loratadine?\"\"\",\n",
    "\n",
    "    \"\"\"AI: acetaminophen is generally used to relieve mild to moderate pain and reduce fever.\\n \n",
    "       HUMAN: What is acetaminophen used for?\"\"\",\n",
    "\n",
    "    \"\"\"AI: azithromycin is typically taken once daily for 3 to 5 days, depending on the infection type.\\n \n",
    "       HUMAN: How long do I need to take azithromycin?\"\"\",\n",
    "\n",
    "    \"\"\"AI: omeprazole should be taken before meals, usually in the morning, to reduce stomach acid production.\\n \n",
    "       HUMAN: When is the best time to take omeprazole?\"\"\",\n",
    "\n",
    "    \"\"\"AI: insulin helps lower blood sugar by allowing glucose to enter cells and be used for energy.\\n \n",
    "       HUMAN: What does insulin do in the body?\"\"\"\n",
    "\n",
    "]  \n",
    "\n",
    "related_questions = [\n",
    "    \"how can I take it?\",\n",
    "    \"what did happen to John?\",\n",
    "    \"how can I take it?\",\n",
    "    \"how can I take azithromycin?\",\n",
    "    \"how can I take it?\",\n",
    "    \"how can I take it?\",\n",
    "    \"how can I take azithromycin?\",\n",
    "    \"how can I take it?\",\n",
    "    \"how can I take it?\",\n",
    "    \"how can I take it?\",\n",
    "    ]\n",
    "\n",
    "expecting = [\n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"no\"}\"\"\",\n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"no\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"no\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    \"\"\"{\"score\": \"yes\"}\"\"\", \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c521222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure structure output\n",
    "prompt_structured_output = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a precise assistant. \"\n",
    "     \"Read the user's request and produce your answer as structured JSON. \"\n",
    "     \"Do not include extra explanations or text outside the JSON.\"),\n",
    "    (\"human\",\n",
    "     \"Extract the following information from this sentence:\\n\"\n",
    "     \"'Alice bought 3 apples for $5 on Monday.'\\n\\n\"\n",
    "     \"Return the result in this JSON format:\\n\"\n",
    "     \"{{\\n\"\n",
    "     '  \"person\": \"\",\\n'\n",
    "     '  \"item\": \"\",\\n'\n",
    "     '  \"quantity\": ,\\n'\n",
    "     '  \"price\": \"\",\\n'\n",
    "     '  \"day\": \"\"\\n'\n",
    "     \"}}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64956071",
   "metadata": {},
   "source": [
    "##### First of all, Testing meta-llama/Llama-3.2-1B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b91a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd542a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load meta-llama/Llama-3.2-1B-Instruct done!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            dtype = best_dtype(),\n",
    "            device_map={\"\":best_device()}, \n",
    "            low_cpu_mem_usage=True           \n",
    "        )\n",
    "\n",
    "print(f\"Load {model_id} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13058dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,   \n",
    "    )\n",
    "\n",
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipe = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Transfer the pipeline to Chat mode.\n",
    "# Because this is a way we can use ChatPromptTemplate to make better prompt.\n",
    "Llama_1b = ChatHuggingFace(llm=hug_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d67af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting: dgl\n",
      "\n",
      "content=\"Step 1: \\nRemove trailing spaces from 'good' to get 'good'.\\nStep 2: \\nFind last alphabetic letter in 'good' which is 'D'.\\nStep 3: \\nFind last alphabetic letter in'morning' which is 'G'.\\nStep 4: \\nFind last alphabetic letter in 'Medipal' which is 'L'.\\nStep 5: \\nConcatenate these three letters in the same order to get 'DGGL'.\" additional_kwargs={} response_metadata={} id='run--c224fad4-a593-4f4a-8632-e769d2fa7a7b-0'\n"
     ]
    }
   ],
   "source": [
    "# Reasoning test\n",
    "reason_letters_chain = prompt_last_letters_basic | Llama_1b\n",
    "result = reason_letters_chain.invoke({\"w1\":\"good\", \"w2\":\"morning\", \"w3\": \"Medipal\"})\n",
    "print(\"Expecting: dgl\\n\")\n",
    "print(result)\n",
    "# Expecting: 'dgl'\n",
    "# Result is 'DGGL'\n",
    "# It is ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacee4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Step 1: Start with the initial number of apples John has.\\nJohn has 5 apples.\\n\\nStep 2: Calculate the number of apples John gives to his father.\\nJohn gives 2 apples to his father.\\n\\nStep 3: Subtract the number of apples John gave to his father from the initial number of apples John has.\\n5 - 2 = 3\\n\\nResult: 3' additional_kwargs={} response_metadata={} id='run--f64dffbd-9538-4ed5-b943-2a46489568cb-0'\n"
     ]
    }
   ],
   "source": [
    "# simple math\n",
    "reason_math_chain = prompt_simple_math | Llama_1b\n",
    "result = reason_math_chain.invoke({})\n",
    "print(result)\n",
    "\n",
    "# Expecting: 10\n",
    "# Result is 3\n",
    "# It is bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e7a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Step 1: Find the initial number of apples John has. \\nJohn has 5 apples.\\n\\nStep 2: Find the number of apples John gave to his father. \\nJohn gave 2 apples to his father.\\n\\nStep 3: Subtract the number of apples given from the initial number of apples to find the number of apples his father has.\\n5 - 2 = 3\\n\\nResult: 3' additional_kwargs={} response_metadata={} id='run--0bf10b0a-741b-4a43-8652-12fc9f09179b-0'\n"
     ]
    }
   ],
   "source": [
    "# a little harder math\n",
    "reason_math_moderate_chain = prompt_moderate_math | Llama_1b\n",
    "result = reason_math_chain.invoke({})\n",
    "print(result)\n",
    "# Expecting: 11\n",
    "# Result is 3\n",
    "# It is bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here are three questions based on the provided information:\\n\\n<json>\\n\"question1\", \"question2\", \"question3\"\\n\"Is phenylephrine used to treat colds, allergies, and hay fever?\", \"Does phenylephrine relieve sinus congestion and pressure?\", \"Is phenylephrine a class of medications called nasal decongestants?\"\\n</json>\\n\\n\"question4\", \"question5\", \"question6\"\\n\"Does phenylephrine relieve nasal discomfort caused by colds, allergies, and hay fever?\", \"Does phenylephrine reduce swelling of the blood vessels in the nasal passages?\", \"Is phenylephrine used to relieve sinus pressure?\"\\n</json>\\n\\n\"question7\", \"question8\", \"question9\"\\n\"Is phenylephrine used to relieve nasal discomfort caused by colds, allergies, and hay fever?\", \"Is phenylephrine used to relieve sinus congestion?\", \"Is phenylephrine used to relieve nasal pressure?\"\\n</json>' additional_kwargs={} response_metadata={} id='run--7c33200c-72df-45cd-b410-e4cc40cbaf49-0'\n",
      "content='<json>\\n    \"question1\": \"What is the likely diagnosis for Sinner\\'s physical struggles?\",\\n    \"question2\": \"What is the most likely cause of Sinner\\'s cramps?\",\\n    \"question3\": \"What should be done to alleviate Sinner\\'s discomfort?\"\\n</json>' additional_kwargs={} response_metadata={} id='run--56bdbdab-4b1c-4f12-a704-33d3bcd8e2c8-0'\n",
      "content='Here are three questions covering different medical perspectives:\\n\\n<json>\\n    \"question1\",\\n    \"question2\",\\n    \"question3\"\\n</json>' additional_kwargs={} response_metadata={} id='run--11ae2652-3aba-437e-9775-16f352da2169-0'\n",
      "content='<json>\\n\"question1\", \"question2\", \"question3\"\\n\"Phenylephrine should not be taken in combination with other medications without consulting a doctor or pharmacist.\", \\n\"Phenylephrine can cause serious side effects or death in young children.\", \"Phenylephrine should not be given to children under 4 years of age.\", \\n\"Phenylephrine should be used carefully in children 4 to 11 years of age with caution.\", \"Phenylephrine can cause overdose in children if given to one.\", \"Phenylephrine should not be used in combination with other cough and cold products.\", \\n\"Phenylephrine should be measured carefully in children to avoid overdose.\", \"Phenylephrine is not suitable for children under 4 years of age.\", \\n\"Phenylephrine should not be given to children who have had an allergic reaction to it before.\", \"Phenylephrine is not recommended for use in children with certain medical conditions.\", \"Phenylephrine should be used with caution in children with a fever.\", \\n\"Phenylephrine is not suitable for children who are taking certain medications.\", \"Phenylephrine should be used with caution in' additional_kwargs={} response_metadata={} id='run--0b176325-79fb-4f58-95fe-680902e2ba1c-0'\n",
      "content='<json>\\n\"question1\": \"What is the purpose of taking the missed dose of Aluminum Hydroxide and Magnesium Hydroxide when you remember it?\",\\n\"question2\": \"What should happen if you miss a dose of Aluminum Hydroxide and Magnesium Hydroxide?\",\\n\"question3\": \"What should you do if you are taking Aluminum Hydroxide and Magnesium Hydroxide and it is almost time for your next dose?\",\\n</json>' additional_kwargs={} response_metadata={} id='run--ee673a12-cab8-4e0a-88be-7a310eae6af6-0'\n"
     ]
    }
   ],
   "source": [
    "# Generate questions based on content\n",
    "generate_question_chain = prompt_generate_questions | Llama_1b\n",
    "\n",
    "for c in contents:\n",
    "    result = generate_question_chain.invoke({\"doc\": c})\n",
    "    print(result)\n",
    "\n",
    "# The generated questions are no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b996f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--13fd686f-7e9c-4a88-8603-d662d8ab2ca5-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--a4b889f1-632d-46ae-9b8f-db85d9291776-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--f8bce220-7728-494e-ae32-292f8a859450-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--713c188b-5aa0-4426-b72f-e99432a34ce4-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--0538ac44-d930-45d8-b155-fe15c8cfe4f3-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--7fcddd22-a9dd-46be-bd2d-ca27d2d25ac5-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--b4577ad3-bd73-47ae-8440-3dd777a94fdc-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--b30eca00-36e5-421d-a918-8a1d43e09f52-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--deeb0807-ca64-445e-aa37-b9600fe3566f-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--8b8fe225-9368-47c1-bb81-1168c8c9f846-0'\n"
     ]
    }
   ],
   "source": [
    "# Solve Yes or No question， structured_output\n",
    "self_contained_chain = prompt_self_contained | Llama_1b\n",
    "for q in self_contained_questions:\n",
    "    result = self_contained_chain.invoke({\"question\": q[\"question\"]})\n",
    "    print(f\"\"\"Expecting:{q[\"expect\"]}, actual result:{result}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7efc8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--f82fe778-b8f1-41c8-823c-307e729dfdb1-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--b1094875-b0f9-4041-8ed1-ea9fdd5e1d58-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--57d554ae-899c-4eef-8dd9-22ea6087360b-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--2e51e744-63d2-4166-9d1a-729867c4689a-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--a183cefd-6b6a-4314-8268-7f906d8c2ba8-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--63be0bf9-031d-4dc4-8110-dfb454270036-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--7bd56778-df1d-4246-afec-b7aae3516752-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--2baa7896-9b7f-44b8-bf43-da1d2cdf0ca1-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--c0b69579-e7f9-4bae-afb9-987bef8f9457-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--2570a9c0-ba2f-4fe9-ab0d-88589eae0c05-0' \n"
     ]
    }
   ],
   "source": [
    "related_chain = prompt_related_question | Llama_1b\n",
    "for q, d, e in zip(related_questions, documents, expecting):\n",
    "    result  = related_chain.invoke({\"question\": q, \"document\": d})\n",
    "    print(f\"\"\"Expecting:{e}, actual result: {result} \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ac718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: content='{\\n  \"person\": \"\",\\n  \"item\": \"apples\",\\n  \"quantity\": 3,\\n  \"price\": \"$5\",\\n  \"day\": \"Monday\"\\n}' additional_kwargs={} response_metadata={} id='run--45caa7c9-4848-4bfd-814e-a133f5360225-0' \n"
     ]
    }
   ],
   "source": [
    "structured_output_chain = prompt_structured_output | Llama_1b\n",
    "result  = structured_output_chain.invoke({})\n",
    "print(f\"\"\"Result: {result} \"\"\")\n",
    "\n",
    "# Expecting {\\n  \"person\": \"Alice \",\\n  \"item\": \"apples\",\\n  \"quantity\": 3,\\n  \"price\": \"5\",\\n  \"day\": \"Monday\"\\n}\n",
    "# It is OK, but not accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e215e1",
   "metadata": {},
   "source": [
    "##### Testing meta-llama/Meta-Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2043988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61cf7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48a32aa40314f5e95f6bfde59a2368d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load meta-llama/Meta-Llama-3-8B-Instruct done!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            dtype = best_dtype(),\n",
    "            device_map={\"\":best_device()}, \n",
    "            low_cpu_mem_usage=True           \n",
    "        )\n",
    "\n",
    "print(f\"Load {model_id} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca10ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,   \n",
    "    )\n",
    "\n",
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipe = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Transfer the pipeline to Chat mode.\n",
    "# Because this is a way we can use ChatPromptTemplate to make better prompt.\n",
    "Llama_8b = ChatHuggingFace(llm=hug_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d19e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here are the steps to solve the problem:\\n\\nStep 1: Remove trailing spaces and punctuation from each word.\\ngood -> good, morning -> morning, Medipal -> Medipal\\n\\nStep 2: Find the last alphabetic letter (A-Z/a-z) of each word.\\ngood -> d, morning -> g, Medipal -> L\\n\\nStep 3: Concatenate these letters in the same order (word1 → word2 → word3).\\nd-g-L\\n\\nResult: dgl' additional_kwargs={} response_metadata={} id='run--e1852036-12c9-4dda-9575-6da38c4f4b10-0'\n"
     ]
    }
   ],
   "source": [
    "# Reasoning test\n",
    "reason_letters_chain = prompt_last_letters_basic | Llama_8b\n",
    "result = reason_letters_chain.invoke({\"w1\":\"good\", \"w2\":\"morning\", \"w3\": \"Medipal\"})\n",
    "print(result)\n",
    "# Expecting: 'dgl'\n",
    "# Result is 'dgl'\n",
    "# It is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2d5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Step 1: John's father initially has 8 apples.\\nStep 2: John gives 2 apples to his father, so the father receives 2 more apples.\\nStep 3: To find the total number of apples his father has now, add the initial 8 apples to the 2 apples received: 8 + 2 = 10\\nResult: 10\" additional_kwargs={} response_metadata={} id='run--cfa477ae-9516-4d08-823f-21b69ead357d-0'\n"
     ]
    }
   ],
   "source": [
    "reason_math_chain = prompt_simple_math | Llama_8b\n",
    "result = reason_math_chain.invoke({})\n",
    "print(result)\n",
    "# Expecting: 10\n",
    "# Result is 10\n",
    "# It is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Step 1: Calculate the total number of apples John has initially.\\nJohn has 5 apples.\\n\\nStep 2: Calculate the number of apples John's father has after receiving 2 apples from John.\\nJohn's father has 8 apples initially. \\nAfter receiving 2 apples from John, his father has 8 + 2 = 10 apples.\\n\\nResult: 10\" additional_kwargs={} response_metadata={} id='run--07c4e435-a6c5-4839-bd58-24b2242423fc-0'\n"
     ]
    }
   ],
   "source": [
    "# a little harder math\n",
    "reason_math_moderate_chain = prompt_moderate_math | Llama_8b\n",
    "result = reason_math_chain.invoke({})\n",
    "print(result)\n",
    "# Expecting: 11\n",
    "# Result is 10\n",
    "# The step is wrong, so result is wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75927e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<json>\\n[\"What are the common uses of phenylephrine?\", \"Can phenylephrine treat the underlying cause of nasal discomfort?\", \"What is the mechanism of action of phenylephrine as a nasal decongestant?\"]\\n</json>' additional_kwargs={} response_metadata={} id='run--ef813a3f-c710-4f41-b9b3-7a6998f2a8aa-0'\n",
      "content='<json>\\n[\"What are the initial symptoms exhibited by Sinner during the second set?\", \"What is the potential cause of Sinner\\'s limping and thigh massaging in the decider?\", \"What is Sinner\\'s attempt to alleviate his cramp symptoms at the 2-1 changeover?\"]\\n</json>' additional_kwargs={} response_metadata={} id='run--ac0d01d6-b3ba-4bb3-bcf8-19071b901edd-0'\n",
      "content='<json>\\n[\"What are the key areas of computing infrastructure being built to support AI investing?\", \"What are the indications that AI will remain a prevailing market theme for several more years?\", \"What is the expected impact of AI investing on the stock market in the near future?\"]\\n</json>' additional_kwargs={} response_metadata={} id='run--64e7aaa7-5f0c-4155-adc3-2773b1b5747b-0'\n",
      "content='<json>\\n[\"What is the recommended frequency of taking phenylephrine?\", \"Can phenylephrine products be given to children under 4 years of age?\", \"How should the liquid form of phenylephrine be measured for proper dosage?\"]\\n</json>' additional_kwargs={} response_metadata={} id='run--bd7ef9f5-f704-4c04-b180-f43f4972deca-0'\n",
      "content='<json>\\n[\"What is the recommended action if a scheduled dose of aluminum hydroxide and magnesium hydroxide is missed?\", \\n\"What is the recommended action if the missed dose is almost time for the next scheduled dose?\", \\n\"What is the recommended action to avoid when taking a missed dose of aluminum hydroxide and magnesium hydroxide?\"]\\n</json>' additional_kwargs={} response_metadata={} id='run--28c1b638-9592-4af4-9e08-006ffed63d28-0'\n"
     ]
    }
   ],
   "source": [
    "# Generate questions based on content\n",
    "generate_question_chain = prompt_generate_questions | Llama_8b\n",
    "\n",
    "for c in contents:\n",
    "    result = generate_question_chain.invoke({\"doc\": c})\n",
    "    print(result)\n",
    "\n",
    "# Pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b934fef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--7a7660c2-e76b-4dad-96ba-1d710374f8bb-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--e9816c7c-1ce0-4b22-b2f8-e9c6524cab80-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--7754d14f-57f2-473b-abf3-823c69640242-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--8a07e2aa-9402-4df4-81a9-b2bb131524d2-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--82701dd2-6e18-46b9-a7e5-b10e0fca5370-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--f0c498ef-7abc-42c3-86e3-6ce908791831-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--889a2234-1430-4cde-b6b1-56214d667f6e-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--d061103b-5872-43d1-9df5-cd388953a25d-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--0594a29f-d591-4f81-8e60-47ee980416a2-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--13c2b667-abc2-4161-bd7f-1ecf80442c28-0'\n"
     ]
    }
   ],
   "source": [
    "# Solve Yes or No question， structured_output\n",
    "self_contained_chain = prompt_self_contained | Llama_8b\n",
    "for q in self_contained_questions:\n",
    "    result = self_contained_chain.invoke({\"question\": q[\"question\"]})\n",
    "    print(f\"\"\"Expecting:{q[\"expect\"]}, actual result:{result}\"\"\")\n",
    "\n",
    "# 10 out of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2eaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--0a6f9a37-b2ca-4804-b967-040f5a5cd4e0-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--354220e5-078e-44b3-a89d-2283b627ceef-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--cba23984-4bdc-4b44-848f-a0c77a94ef3f-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--e8c968f2-6aed-466f-aca0-a61ca31ff99f-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--23d103f8-b169-4053-8fc2-3856b2fab385-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--fd8f7d73-9123-41e9-9199-3e684d34d983-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--65e9feaa-d9d3-49ba-a8e5-827bdf23aad6-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--5f04858f-6262-4e88-9291-f7212da83c35-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--e66170fc-74e1-4d63-8ed3-00edb7eb56c9-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content='{\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--3e3cefec-5263-46dd-9b84-9080382bb18b-0' \n"
     ]
    }
   ],
   "source": [
    "related_chain = prompt_related_question | Llama_8b\n",
    "for q, d, e in zip(related_questions, documents, expecting):\n",
    "    result  = related_chain.invoke({\"question\": q, \"document\": d})\n",
    "    print(f\"\"\"Expecting:{e}, actual result: {result} \"\"\")\n",
    "\n",
    "# 9 out of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6dd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: content='{\\n  \"person\": \"Alice\",\\n  \"item\": \"apples\",\\n  \"quantity\": 3,\\n  \"price\": 5,\\n  \"day\": \"Monday\"\\n}' additional_kwargs={} response_metadata={} id='run--5283cdc7-1d15-44d8-8a45-a94768beefa4-0' \n"
     ]
    }
   ],
   "source": [
    "structured_output_chain = prompt_structured_output | Llama_8b\n",
    "result  = structured_output_chain.invoke({})\n",
    "print(f\"\"\"Result: {result} \"\"\")\n",
    "\n",
    "# Expecting {\\n  \"person\": \"Alice \",\\n  \"item\": \"apples\",\\n  \"quantity\": 3,\\n  \"price\": \"5\",\\n  \"day\": \"Monday\"\\n}\n",
    "# It is pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3e647",
   "metadata": {},
   "source": [
    "##### Testing ContactDoctor/Bio-Medical-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a13873",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c7c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac621fbc84d429fa7b6f1b511210878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ContactDoctor/Bio-Medical-Llama-3-8B done!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            dtype = best_dtype(),\n",
    "            device_map={\"\":best_device()}, \n",
    "            low_cpu_mem_usage=True           \n",
    "        )\n",
    "\n",
    "print(f\"Load {model_id} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d58f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,   \n",
    "    )\n",
    "\n",
    "# Wrapper normal piple with huggingfacepipeline\n",
    "hug_pipe = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Transfer the pipeline to Chat mode.\n",
    "# Because this is a way we can use ChatPromptTemplate to make better prompt.\n",
    "Medical_Llama_8b = ChatHuggingFace(llm=hug_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d39f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' Step 1: Remove trailing spaces from the input words.\\nStep 2: Remove punctuation from the input words.\\nStep 3: Find the last alphabetic letter of each word.\\nStep 4: Concatenate the last letters of the words.\\nResult: mg' additional_kwargs={} response_metadata={} id='run--b7d2e97b-fd76-459e-afb8-2e05057f4892-0'\n"
     ]
    }
   ],
   "source": [
    "# Reasoning test\n",
    "reason_letters_chain = prompt_last_letters_basic | Medical_Llama_8b\n",
    "result = reason_letters_chain.invoke({\"w1\":\"good\", \"w2\":\"morning\", \"w3\": \"Medipal\"})\n",
    "print(result)\n",
    "\n",
    "# Expecting: 'dgl'\n",
    "# Result is 'mg'\n",
    "# It is bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ca7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" Step 1: Initial number of apples father has: 8\\nStep 2: Apples John gives to father: 2\\nStep 3: Subtract apples given from father's initial apples: 8 - 2 = 6\\nResult: 6\" additional_kwargs={} response_metadata={} id='run--53f40231-ee84-4a4e-b7a3-19884634620a-0'\n"
     ]
    }
   ],
   "source": [
    "reason_math_chain = prompt_simple_math | Medical_Llama_8b\n",
    "result = reason_math_chain.invoke({})\n",
    "print(result)\n",
    "# Expecting: 10\n",
    "# Result is 10\n",
    "# It is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca97ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' Step 1: John has 5 apples and gives 2 apples to his father, so John has 5 - 2 = 3 apples left.\\nStep 2: His father had 8 apples and received 2 apples from John, so his father now has 8 + 2 = 10 apples.\\nResult: 10' additional_kwargs={} response_metadata={} id='run--23b5571c-9927-4655-a6a5-754168a5aa5f-0'\n"
     ]
    }
   ],
   "source": [
    "# a little harder math\n",
    "reason_math_moderate_chain = prompt_moderate_math | Medical_Llama_8b\n",
    "result = reason_math_chain.invoke({})\n",
    "print(result)\n",
    "# Expecting: 11\n",
    "# Result is 10\n",
    "# The step is wrong, so result is wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b081bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' <json>\\n[\"Is phenylephrine effective in relieving nasal discomfort caused by allergic rhinitis?\", \"Can phenylephrine be used to treat sinus congestion and pressure?\", \"Does phenylephrine belong to the class of medications known as nasal decongestants?\"\\n</json>' additional_kwargs={} response_metadata={} id='run--d172c326-5995-4153-b08e-937131a17ef4-0'\n",
      "content=' <json>\\n[\"Why would a player use ice towels during a set break?\", \"What might cause a player to limp between points?\", \"Why might a player try to prevent cramping during a match?\"\\n</json>' additional_kwargs={} response_metadata={} id='run--db5681a9-30c5-476e-8064-67208208748c-0'\n",
      "content=' <json>\\n[\"What are the key drivers of the dominance of artificial intelligence investing in the stock market?\", \"How will the trend of AI investing in the stock market persist in the coming years?\", \"What are the implications of AI investing being the dominant theme in the stock market?\"\\n</json>' additional_kwargs={} response_metadata={} id='run--0453f6cc-7e49-43ab-8d62-da55afb50eb7-0'\n",
      "content=' <json>[\"Can phenylephrine be given to children younger than 4 years of age?\", \"How often should phenylephrine be taken?\", \"How should phenylephrine liquid be measured?\"</json>' additional_kwargs={} response_metadata={} id='run--0bec8480-a441-4bc6-b035-0a5e6c40cc0c-0'\n",
      "content=' [  \"What is the appropriate action if a dose of aluminum hydroxide and magnesium hydroxide is missed?\", \"When should one take a missed dose of aluminum hydroxide and magnesium hydroxide, if not forgotten until just before the next scheduled dose?\", \"Are there any drug interactions or contraindications associated with taking aluminum hydroxide and magnesium hydroxide?\" ]' additional_kwargs={} response_metadata={} id='run--1e6312b2-624a-409a-a359-2e3c63e00325-0'\n"
     ]
    }
   ],
   "source": [
    "# Generate questions based on content\n",
    "generate_question_chain = prompt_generate_questions | Medical_Llama_8b\n",
    "\n",
    "for c in contents:\n",
    "    result = generate_question_chain.invoke({\"doc\": c})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f05ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"yes\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--e54e8da6-4919-4135-8010-56fbfef7343a-0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"no\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--b9fb0ca1-39eb-4506-b9c3-ff344f83205a-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--9d16c68e-1462-4cbf-acf4-236ee2a0500f-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--96cbffff-ffc4-46b8-9c5b-754241ad009c-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content=' {\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--57e89f08-cf5a-49a6-8849-4d5f7a60732e-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--71ecbcbb-70e3-4864-9ca1-2c22f44fdc01-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content=' {\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--eb32dc49-9576-493a-815d-84ed7c21cd80-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--8eb4360f-2876-4835-a3ab-376ec32aad31-0'\n",
      "Expecting:{\"score\": \"no\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--84ebbe57-8741-42a6-ac74-8b670a3dbc04-0'\n",
      "Expecting:{\"score\": \"yes\"}, actual result:content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--c342ec67-512c-4ac3-b93b-2d25bdaef3f4-0'\n"
     ]
    }
   ],
   "source": [
    "# Solve Yes or No question， structured_output\n",
    "self_contained_chain = prompt_self_contained | Medical_Llama_8b\n",
    "for q in self_contained_questions:\n",
    "    result = self_contained_chain.invoke({\"question\": q[\"question\"]})\n",
    "    print(f\"\"\"Expecting:{q[\"expect\"]}, actual result:{result}\"\"\")\n",
    "\n",
    "# 8 out of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--9ae7e78c-73df-4f9e-9392-915ecd34b520-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content=' {\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--f2b2d779-e781-4619-9461-9e47bede35ae-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--2c2c6068-7ec9-413b-8885-e65f0c753d08-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content=' {\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--2e38731a-f0fd-4bbd-be1c-036b2d95cf51-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--8f9898e8-8283-471a-9ac8-88dfecad9ee2-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--8225a82d-b702-4892-9e08-75cc479b79fe-0' \n",
      "Expecting:{\"score\": \"no\"}, actual result: content=' {\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--d45b7967-4000-4842-9522-95898bb3864c-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--2f5995aa-a521-413f-8bad-d0efc98c9a92-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"yes\"}' additional_kwargs={} response_metadata={} id='run--0b6711b9-8451-486b-a545-d99e4438c5ce-0' \n",
      "Expecting:{\"score\": \"yes\"}, actual result: content=' {\"score\": \"no\"}' additional_kwargs={} response_metadata={} id='run--187441c0-9625-4fc9-a914-98ae204a7a03-0' \n"
     ]
    }
   ],
   "source": [
    "related_chain = prompt_related_question | Medical_Llama_8b\n",
    "for q, d, e in zip(related_questions, documents, expecting):\n",
    "    result  = related_chain.invoke({\"question\": q, \"document\": d})\n",
    "    print(f\"\"\"Expecting:{e}, actual result: {result} \"\"\")\n",
    "\n",
    "# 9 out of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1199726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: content=' {\\n  \"person\": \"Alice\",\\n  \"item\": \"apples\",\\n  \"quantity\": 3,\\n  \"price\": 5,\\n  \"day\": \"Monday\"\\n}' additional_kwargs={} response_metadata={} id='run--e228831b-023b-4f5f-a97a-401b93cde14a-0' \n"
     ]
    }
   ],
   "source": [
    "structured_output_chain = prompt_structured_output | Medical_Llama_8b\n",
    "result  = structured_output_chain.invoke({})\n",
    "print(f\"\"\"Result: {result} \"\"\")\n",
    "\n",
    "# Expecting {\\n  \"person\": \"Alice \",\\n  \"item\": \"apples\",\\n  \"quantity\": 3,\\n  \"price\": \"5\",\\n  \"day\": \"Monday\"\\n}\n",
    "# It is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef327bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
