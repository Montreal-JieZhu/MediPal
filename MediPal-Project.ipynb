{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89800077",
   "metadata": {},
   "source": [
    "![](assets/screenshots/logo_small.PNG \"\")\n",
    "\n",
    "**MediPal** is your AI friend for medical and clinical Q&A.\n",
    "* It is an open-source medical assistant that provides comprehensive mediciation information and symptom-based recommendations using natural-language understanding which supports voice and message conversation.\n",
    "\n",
    "* Powered by local Huggingface LLMs, embedding model, cross-encoder(BERT) and whisper with AI Agent development frameworks like langchain, langgraph and many tools.\n",
    "\n",
    "<!-- <div style=\"display: flex; align-items: flex-start;\">\n",
    "  <div style=\"flex: 0 0 150px;\">\n",
    "    <img src=\"./screenshots/medipal_logo.PNG\" alt=\"Logo\" width=\"140\" height=\"140\" style=\"margin-right:15px;\" />\n",
    "  </div>\n",
    "  <div style=\"flex: 1; padding-left: 15px;\">\n",
    "    <p>\n",
    "      <b>MediPal</b> is your AI friend for medical and clinical Q&A. \n",
    "      <ul>\n",
    "         <li>It is an open-source medical assistant that provides comprehensive mediciation information and symptom-based recommendations using natural-language understanding which supports voice and message conversation.</li>\n",
    "         <li>Powered by local Huggingface LLMs, embedding model, cross-encoder(BERT) and whisper with AI Agent development frameworks like langchain, langgraph and many tools. </li>\n",
    "      </ul>\n",
    "    </p>\n",
    "  </div>\n",
    "</div> -->\n",
    "\n",
    "---\n",
    "\n",
    "## Motivation\n",
    "1. **Easy examples with big LLM**\n",
    "\n",
    "Recently, I tried to make a medical Q&A agent, I saw that many code examples use big models like gpt-4o. With a few lines of code, I can get pretty good result.\n",
    "\n",
    "2. **Not good for deeper learning**\n",
    "\n",
    "This is good to learn how to use AI frameworks/tools, but it does not help me understand why and how gpt can do this. For example: How could it reason? How could it use tools? How could its talks are always linked to previous conversations?\n",
    "\n",
    "3. **Real project limits**\n",
    "\n",
    "In real projects, we often has limited resource, as we need to manage cost and keep data security. Sometimes we must use small local models to build AI application. Those models usually doesn't have the same capability as gpt-4o has.\n",
    "\n",
    "#### So this project is not to build a very fancy and powerful AI application, instead **My main motivation is** to build a Q&A agent using small local models. But it can do similar things just like a big model do. \n",
    "\n",
    "---\n",
    "\n",
    "## Main Components\n",
    "\n",
    "MediPal is designed to have:\n",
    "\n",
    "1. **Comprehensive Medicine Knowledge Base**\n",
    "\n",
    "   * I built an **Agentic RAG** to provide relevant and accurate information for responses.\n",
    "\n",
    "2. **Evaluation and Decision Patterns**\n",
    "\n",
    "   * Instead of solving a problem at once, it is better to break the problem into small yes-or-no questions. \n",
    "   * The model can evaluate and decide what to do next. By repeating this process, until solve a problem correctly.\n",
    "\n",
    "3. **Conversation Memory**\n",
    "\n",
    "   * Remembers previous conversations, so that its talks can always stay connected with the context.\n",
    "\n",
    "4. **External tools**\n",
    "\n",
    "   * Calls wikipedia or brave search tools when needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Development Process\n",
    "\n",
    "![](assets/screenshots/development_process.PNG \"\")\n",
    "\n",
    "---\n",
    "\n",
    "## Project Structure\n",
    "The project is organized into six stages:\n",
    "\n",
    "1. **LLMs selections**\n",
    "\n",
    "   * Test and compares three small LLMs.\n",
    "   * Analyze their strenghts and weaknesses so that I can use the right one for the project.\n",
    "\n",
    "2. **Data ETL Pipeline**\n",
    "\n",
    "   * Scrape data from medicine websites.\n",
    "   * Preprocess the data and analysis.\n",
    "   * Implement properly chunking strategy.\n",
    "   * Generate extra questions using local LLM.\n",
    "\n",
    "3. **Agentic RAG**\n",
    "\n",
    "   * Combined multi-vector retriever and re-ranking techniques to enhance retrieval efficiency and accuracy.\n",
    "   * Add agentic elements and decomposes retrieval task into a series of yes/no questions so that the process go to the right direction.\n",
    "   * Call external tools when no relevant documents are found in the local vector database.\n",
    "\n",
    "4. **MediPal - Medical Q&A Agent**\n",
    "\n",
    "   * Generate answers based on the retrieval documents with halluciation checking.\n",
    "   * Interact with users on other topics, but emphasizes its primary role is to provide medical information.\n",
    "   * leverage external tools or MCP services to support users in the medical domain. For example, it can analysize and summarize conversations, then save them to Notion, or even help schedule an appointment with a doctor (Future stage!).\n",
    "\n",
    "5. **FrontEnd**\n",
    "\n",
    "   * Place Medipal under a API endpoint, so that we only needs to launch it once. Other apps just need to interact with the api.\n",
    "   * Provide a chat interface that supports both text and voice conversations.\n",
    "\n",
    "6. **Evaluation**\n",
    "\n",
    "   * I set exact the same evaluation dataset, matrics, temperature=0.1 and environment, comparing three models.\n",
    "\n",
    "| Medicial Expert      |  Normal Guy                     |  Big  Model                      |\n",
    "| ----------------- | ---------------------------------- |---------------------------------- |\n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B | meta-llama/Meta-Llama-3-8B-Instruct | meta-llama/Meta-Llama-3-70B-Instruct |\n",
    "  \n",
    "```text\n",
    "MediPal/\n",
    "‚îú‚îÄ 1_LLM_Selection/                # Key Techniques/Tools: Langchain, Prompt Engineering, HuggingFace(transformers)\n",
    "‚îÇ  ‚îú‚îÄ README.md\n",
    "‚îÇ  ‚îú‚îÄ Test_and_Select_LLM.ipynb\n",
    "‚îÇ  ‚îî‚îÄ .env\n",
    "‚îÇ\n",
    "‚îú‚îÄ 2_DataPipeline/                 # Key Techniques/Tools: bs4.BeautifulSoup, Regex, matplotlib, Langchain, transformers\n",
    "‚îÇ  ‚îú‚îÄ README.md\n",
    "‚îÇ  ‚îú‚îÄ 1_Medicine_data_collection.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 2_Medicine_data_preprocessing_analysis.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 3_Medicine_data_chunking.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 4_Medicine_data_generate_questions.ipynb\n",
    "‚îÇ  ‚îú‚îÄ utils/\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ mytools.py \n",
    "‚îÇ  ‚îú‚îÄ datasets/*.json              # Scraped, cleaned, chunked and augmented dataset\n",
    "‚îÇ  ‚îî‚îÄ .env\n",
    "‚îÇ\n",
    "‚îú‚îÄ 3_AgenticRAG/                   # Key Techniques/Tools: Muilti-Vector, Chroma, CrossEncoder(BERT), Embedding Model, LLM, Memory, langgraph, Langchain, \n",
    "‚îÇ  ‚îú‚îÄ README.md                    # transformers, torch, wikipadia, brave search, logging, whisper, gtts, fastapi, gradio, unicorn, RAGAS  \n",
    "‚îÇ  ‚îú‚îÄ 1_Rerank_Retriever.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 2_Agentic_RAG.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 3_MediPal.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 4_API_Chatbox.ipynb\n",
    "‚îÇ  ‚îú‚îÄ 5_Evaluation.ipynb\n",
    "‚îÇ  ‚îú‚îÄ src/\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ rerank_retriever.py\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ agentic_rag.py\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ medipal.py\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ settings.py\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ mytools.py\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ datasets/*.json\n",
    "‚îÇ  ‚îî‚îÄ .env\n",
    "‚îÇ\n",
    "‚îú‚îÄ src/                            # Moved and restructed all the codes from jupyter notebooks to src files\n",
    "‚îÇ  ‚îú‚îÄ retriever/\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ rerank_retriever.py\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ datasets/*.json\n",
    "‚îÇ  ‚îú‚îÄ agenticrag/\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ agentic_rag.py\n",
    "‚îÇ  ‚îú‚îÄ medipal/\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ medipal.py\n",
    "‚îÇ  ‚îú‚îÄ config/\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ settings.py\n",
    "‚îÇ  ‚îú‚îÄ utils/\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ mytools.py \n",
    "‚îÇ  ‚îî‚îÄ __init__.py  \n",
    "‚îÇ\n",
    "‚îú‚îÄ assets/ \n",
    "‚îÇ  ‚îú‚îÄ screenshots/                   # Pictures\n",
    "‚îÇ  ‚îî‚îÄ *.PNG\n",
    "‚îÇ\n",
    "‚îú‚îÄ medipal_api.py\n",
    "‚îÇ\n",
    "‚îú‚îÄ medipal_chatbox.py\n",
    "‚îÇ\n",
    "‚îú‚îÄ .env\n",
    "‚îÇ\n",
    "‚îú‚îÄ Requirements.txt\n",
    "‚îÇ\n",
    "‚îú‚îÄ LICENSE\n",
    "‚îÇ\n",
    "‚îî‚îÄ README.md                       # Main project overview\n",
    "\n",
    "````\n",
    "\n",
    "## Dataset \n",
    "\n",
    "Only three sample medicine entries (manually processed) are included in this repo to show the data structure and help run the code.\n",
    "For full data scraping with 1_Medicine_data_collection.ipynb, please read the disclaimer first.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Getting Started\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "List all software or tools required.\n",
    "\n",
    "```bash\n",
    "# Example\n",
    "python >= 3.11\n",
    "```\n",
    "\n",
    "### Installation\n",
    "\n",
    "Step-by-step guide:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/yourname/yourproject.git\n",
    "cd yourproject\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üñ• Usage\n",
    "\n",
    "Provide clear examples:\n",
    "\n",
    "```bash\n",
    "python src/main.py --config config.yaml\n",
    "```\n",
    "\n",
    "You can also show **inline code** like `python main.py` within a sentence.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    ".env files\n",
    "\n",
    "| Variable      | Description              | Default |\n",
    "| ------------- | ------------------------ | ------- |\n",
    "| `HUGGINGFACE_KEY`| Your own huggingface key like \"hf_xxxxxxxxxxxxxxxx\" | None    |\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Links\n",
    "\n",
    "* **Documentation:** [Project Docs](https://example.com/docs)\n",
    "* **Demo:** [Live Demo](https://example.com/demo)\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Examples\n",
    "\n",
    "Embed different code languages:\n",
    "\n",
    "<details>\n",
    "<summary>Python</summary>\n",
    "\n",
    "```python\n",
    "from yourmodule import run\n",
    "run()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>JavaScript</summary>\n",
    "\n",
    "```javascript\n",
    "import { run } from 'yourmodule';\n",
    "run();\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Tests\n",
    "\n",
    "```bash\n",
    "pytest tests/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üõ£ Roadmap\n",
    "\n",
    "* [ ] Add authentication\n",
    "* [ ] Implement CI/CD\n",
    "* [ ] Multi-language support\n",
    "\n",
    "See the [open issues](https://github.com/yourname/yourproject/issues) for full list.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Contributing\n",
    "\n",
    "1. Fork the Project\n",
    "2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n",
    "3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n",
    "4. Push to the Branch (`git push origin feature/AmazingFeature`)\n",
    "5. Open a Pull Request\n",
    "\n",
    "---\n",
    "\n",
    "## üìú License\n",
    "\n",
    "Distributed under the MIT License. See `LICENSE` for more information.\n",
    "\n",
    "---\n",
    "\n",
    "## üôè Acknowledgements\n",
    "\n",
    "* [Awesome Library](https://github.com/some/library)\n",
    "* [Inspiration Blog Post](https://example.com)\n",
    "\n",
    "---\n",
    "\n",
    "### Markdown Tips & Samples\n",
    "\n",
    "| Element           | Syntax Example                     |\n",
    "| ----------------- | ---------------------------------- |\n",
    "| **Bold**          | `**text**`                         |\n",
    "| *Italic*          | `*text*`                           |\n",
    "| ~~Strikethrough~~ | `~~text~~`                         |\n",
    "| Blockquote        | `> quoted text`                    |\n",
    "| Checklist         | `- [ ] item` or `- [x] done`       |\n",
    "| Link              | `[title](URL)`                     |\n",
    "| Image             | `![alt](path_or_URL)`              |\n",
    "| Footnote[^1]      | `Here is a footnote reference[^1]` |\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "- [Motivation](#motivation)\n",
    "- [Features](#features)\n",
    "- [Project Structure](#project-structure)\n",
    "- [Getting Started](#getting-started)\n",
    "  - [Prerequisites](#prerequisites)\n",
    "  - [Installation](#installation)\n",
    "- [Usage](#usage)\n",
    "- [Configuration](#configuration)\n",
    "- [Examples](#examples)\n",
    "- [Tests](#tests)\n",
    "- [Roadmap](#roadmap)\n",
    "- [Contributing](#contributing)\n",
    "- [License](#license)\n",
    "- [Acknowledgements](#acknowledgements)\n",
    "\n",
    "---\n",
    "\n",
    "## Citation:\n",
    "\n",
    "**Data Source:** Content obtained from MedlinePlus(https://medlineplus.gov/), a service of the U.S. National Library of Medicine (NLM), National Institutes of Health (NIH). Courtesy of the National Library of Medicine.\n",
    "\n",
    "@misc{ContactDoctor_Bio-Medical-Llama-3-8B, author = ContactDoctor, title = {ContactDoctor-Bio-Medical: A High-Performance Biomedical Language Model}, year = {2024}, howpublished = {https://huggingface.co/ContactDoctor/Bio-Medical-Llama-3-8B}, }\n",
    "\n",
    "@inproceedings{reimers-2019-sentence-bert,\n",
    "    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n",
    "    author = \"Reimers, Nils and Gurevych, Iryna\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = \"11\",\n",
    "    year = \"2019\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://arxiv.org/abs/1908.10084\",\n",
    "}\n",
    "\n",
    "@misc{gao2021scaling,\n",
    "    title={Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup},\n",
    "    author={Luyu Gao and Yunyi Zhang and Jiawei Han and Jamie Callan},\n",
    "    year={2021},\n",
    "    eprint={2101.06983},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.LG}\n",
    "}\n",
    "\n",
    "@article{jin2023medcpt,\n",
    "  title={MedCPT: Contrastive Pre-trained Transformers with large-scale PubMed search logs for zero-shot biomedical information retrieval},\n",
    "  author={Jin, Qiao and Kim, Won and Chen, Qingyu and Comeau, Donald C and Yeganova, Lana and Wilbur, W John and Lu, Zhiyong},\n",
    "  journal={Bioinformatics},\n",
    "  volume={39},\n",
    "  number={11},\n",
    "  pages={btad651},\n",
    "  year={2023},\n",
    "  publisher={Oxford University Press}\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "## Disclaimer: \n",
    "This project provides code for scraping content from MedlinePlus, a service of the U.S. National Library of Medicine (NLM), National Institutes of Health (NIH).\n",
    "\n",
    "Some MedlinePlus materials are in the public domain and may be reused freely with proper attribution. However, other materials (such as certain drug monographs, encyclopedia articles, and images) are copyrighted or licensed for use only on MedlinePlus.\n",
    "\n",
    "This code only involves content in the public domain. If you use or modify this code to access any materials, please ensure that your use of MedlinePlus content complies with NLM policies and applicable copyright laws.\n",
    "\n",
    "Source attribution: ‚ÄúCourtesy of MedlinePlus from the National Library of Medicine (NLM), National Institutes of Health (NIH).‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd64628",
   "metadata": {},
   "source": [
    "### Results:\n",
    "\n",
    "#### Task 1: Reasoning\n",
    "\n",
    "| LLM                                   | LetterTest | Simple math  | Harder math   |\n",
    "|---------------------------------------|------------------|--------------------|--------------|\n",
    "| meta-llama/Llama-3.2-1B-Instruct      | Resoiningüëç, Resultüëé | Resoiningüëé, Resultüëé | Resoiningüëé, Resultüëé |\n",
    "| meta-llama/Meta-Llama-3-8B-Instruct   | Resoiningüëç, Resultüëç | Resoiningüëç, Resultüëç | Resoiningüëç, Resultüëç |\n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B  | Resoiningüëé, Resultüëé | Resoiningüëç, Resultüëç | Resoiningüëå, Resultüëé |\n",
    "\n",
    "\n",
    "#### Task 2: Generate questions based on given content\n",
    "| LLM                                   | Question Quality | Structured_output  | \n",
    "|---------------------------------------|------------------|--------------------|\n",
    "| meta-llama/Llama-3.2-1B-Instruct      | Badüëé            | Badüëé              | \n",
    "| meta-llama/Meta-Llama-3-8B-Instruct   | Goodüëå           | Amazingüëç          | \n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B  | Amazingüëç        | Goodüëå              | \n",
    "\n",
    "\n",
    "#### Task 3: Answer question based on given content\n",
    "| LLM                                   | Answer Quality | Structured_output  | \n",
    "|---------------------------------------|------------------|--------------------|\n",
    "| meta-llama/Llama-3.2-1B-Instruct      | Goodüëå            | Goodüëå             | \n",
    "| meta-llama/Meta-Llama-3-8B-Instruct   | Amazingüëç        | Goodüëå             | \n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B  | Goodüëå            | Goodüëå             | \n",
    "\n",
    "#### Task 4: Solve Yes or No question\n",
    "| LLM                                   | Result | Structured_output  | \n",
    "|---------------------------------------|------------------|--------------------|\n",
    "| meta-llama/Llama-3.2-1B-Instruct      | Pretty Badüëé     | Goodüëå             | \n",
    "| meta-llama/Meta-Llama-3-8B-Instruct   | Amazingüëç        | Goodüëå             | \n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B  | Goodüëå           | Goodüëå             | \n",
    "\n",
    "\n",
    "#### Task 5: Structured ouput\n",
    "| LLM                                   | Result | Structured_output  | \n",
    "|---------------------------------------|------------------|--------------------|\n",
    "| meta-llama/Llama-3.2-1B-Instruct      | Badüëé            | Badüëé             | \n",
    "| meta-llama/Meta-Llama-3-8B-Instruct   | Amazingüëç        | Amazingüëç         | \n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B  | Amazingüëç        | Amazingüëç         | \n",
    "\n",
    "### Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48700a4f",
   "metadata": {},
   "source": [
    "### Results:\n",
    "\n",
    "#### Task 1: Reasoning\n",
    "\n",
    "| LLM                                   | faithfulness | answer_relevancy  | context_precision  | context_recall  |\n",
    "|---------------------------------------|--------------|-------------------|--------------------|-----------------|\n",
    "| ContactDoctor/Bio-Medical-Llama-3-8B  |  0.5636 | 0.9085 | 0.7586 | 0.7069 |\n",
    "| meta-llama/Meta-Llama-3-8B-Instruct   |  0.8645 | 0.8018 | 0.7586 | 0.7069 |\n",
    "| meta-llama/Meta-Llama-3-70B-Instruct   |  xx | xx | xx | xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a01d00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
