{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39f698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from huggingface_hub import login\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57566704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Huggingface so that we can access the model\n"
     ]
    }
   ],
   "source": [
    "with open(\"keys.txt\") as f:\n",
    "    os.environ[\"HF_TOKEN\"] = f.read().strip()\n",
    "\n",
    "# login using env var\n",
    "login(os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "print(f\"Login Huggingface so that we can access the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"   # or a biomedical instruct variant\n",
    "\n",
    "# model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65cf2ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document and generate 5 clinically relevant questions.\\n \"    \n",
    "    \"Requirements:\\n\"   \n",
    "    \"1) Don't need answer. \\n\"\n",
    "    \"2) Output JSON string like this: {\\\"questions:\\\": ['question1','question2',...,'question5']}.\\n\\n\"\n",
    "    \"3) Only put 5 questions.\\n\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return only JSON array.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e48cf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf02e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is the document:\n",
      "```\n",
      "{\n",
      "  \"questions\": [\n",
      "    \"What is phenylephrine?\",\n",
      "    \"How is phenylephrine taken?\",\n",
      "    \"What are the side effects of phenylephrine?\",\n",
      "    \"How long does it take for phenylephrine to work?\",\n",
      "    \"What are the contraindications of phenylephrine?\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db95148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "gen = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tok,\n",
    "    return_full_text=False,\n",
    "    #max_new_tokens=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26913e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a medical student.\"},\n",
    "  {\"role\": \"user\", \"content\": (\n",
    "    \"Read the document and generate 5 clinically relevant questions.\\n\"    \n",
    "    \"Requirements:\\n\"    \n",
    "    \"1) Don't need answer. \\n\"\n",
    "    \"2) Output complete JSON string: {'questions:': ['question1','question2',...,'question5']}.\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return only JSON.\"\n",
    "  )}\n",
    "]\n",
    "prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "resp = gen(prompt, max_new_tokens=500, temperature=0.4,\n",
    "           eos_token_id=tok.eos_token_id)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e49529db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"questions\": [\n",
      "    \"What is the recommended dosage of phenylephrine for adults?\",\n",
      "    \"How often should phenylephrine be taken by mouth?\",\n",
      "    \"What are the potential side effects of taking phenylephrine with other medications?\",\n",
      "    \"When should phenylephrine not be given to children?\",\n",
      "    \"How do I measure my dose of phenylephrine?\"\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abfa0b",
   "metadata": {},
   "source": [
    "### Now Try stanford-crfm/BioMedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ddf7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"stanford-crfm/BioMedLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b264de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document and generate 5 clinically relevant questions.\\n\"    \n",
    "    \"Requirements:\\n\"   \n",
    "    \"1) Don't need answer. \\n\"\n",
    "    \"2) Output JSON string like this: {\\\"questions:\\\": ['question1','question2',...,'question5']}.\\n\\n\"\n",
    "    \"3) Only put 5 questions.\\n\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return only JSON array.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1b47ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [224,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [225,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [226,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [227,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [228,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [229,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [230,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [231,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [232,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [233,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [234,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [235,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [236,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [237,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [238,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [239,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [240,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [241,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [242,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [243,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [244,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [245,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [246,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [247,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [248,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [249,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [250,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [251,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [252,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [253,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [254,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [255,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [224,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [225,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [226,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [227,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [228,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [229,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [230,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [231,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [232,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [233,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [234,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [235,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [236,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [237,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [238,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [239,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [240,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [241,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [242,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [243,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [244,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [245,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [246,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [247,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [248,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [249,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [250,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [251,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [252,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [253,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [254,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,2,0], thread: [255,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [192,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [193,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [194,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [195,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [196,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [197,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [198,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [199,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [200,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [201,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [202,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [203,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [204,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [205,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [206,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [207,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [208,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [209,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [210,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [211,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [212,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [213,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [214,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [215,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [216,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [217,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [218,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [219,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [220,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [221,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [222,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [223,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [160,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [161,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [162,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [163,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [164,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [165,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [166,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [167,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [168,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [169,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [170,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [171,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [172,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [173,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [174,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [175,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [176,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [177,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [178,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [179,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [180,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [181,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [182,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [183,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [184,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [185,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [186,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [187,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [188,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [189,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [190,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [191,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [128,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [129,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [130,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [131,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [132,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [133,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [134,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [135,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [136,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [137,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [138,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [139,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [140,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [141,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [142,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [143,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [144,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [145,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [146,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [147,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [148,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [149,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [150,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [151,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [152,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [153,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [154,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [155,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [156,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [157,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [158,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,0,0], thread: [159,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [0,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [1,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [2,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [3,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [4,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [5,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [6,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [7,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [8,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [9,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [10,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [11,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [12,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [13,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [14,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [15,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [16,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [17,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [18,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [19,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [20,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [21,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [22,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [23,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [24,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [25,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [26,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [27,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [28,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [29,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [30,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1024,1,0], thread: [31,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m out = \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:332\u001b[39m, in \u001b[36mTextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, text_inputs, **kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/pipelines/base.py:1467\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1460\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1461\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1464\u001b[39m         )\n\u001b[32m   1465\u001b[39m     )\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/pipelines/base.py:1474\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1473\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1475\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/pipelines/base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:432\u001b[39m, in \u001b[36mTextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    430\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[32m    435\u001b[39m     generated_sequence = output.sequences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/generation/utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/generation/utils.py:2870\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2868\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2872\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2873\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2874\u001b[39m     outputs,\n\u001b[32m   2875\u001b[39m     model_kwargs,\n\u001b[32m   2876\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2877\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1070\u001b[39m, in \u001b[36mGPT2LMHeadModel.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[33;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[33;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1066\u001b[39m \u001b[33;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[32m   1067\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1068\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m transformer_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1086\u001b[39m hidden_states = transformer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:875\u001b[39m, in \u001b[36mGPT2Model.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask.ndim < \u001b[32m4\u001b[39m:\n\u001b[32m    873\u001b[39m     attention_mask = attention_mask.view(batch_size, -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m causal_mask = \u001b[43mcreate_causal_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[38;5;66;03m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[32m    886\u001b[39m _use_sdpa = \u001b[38;5;28mself\u001b[39m._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m output_attentions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/masking_utils.py:822\u001b[39m, in \u001b[36mcreate_causal_mask\u001b[39m\u001b[34m(config, input_embeds, attention_mask, cache_position, past_key_values, position_ids, or_mask_function, and_mask_function)\u001b[39m\n\u001b[32m    819\u001b[39m     allow_is_causal_skip = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[38;5;66;03m# We now create the mask\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m causal_mask = \u001b[43mmask_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_factory_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_is_causal_skip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_is_causal_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# additional kwarg for sdpa\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Additional kwarg for eager\u001b[39;49;00m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the config as well, in case someone wants to easily have their own mask_interface\u001b[39;49;00m\n\u001b[32m    832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m causal_mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/masking_utils.py:374\u001b[39m, in \u001b[36msdpa_mask_recent_torch\u001b[39m\u001b[34m(batch_size, cache_position, kv_length, kv_offset, mask_function, attention_mask, local_size, allow_is_causal_skip, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m padding_mask = prepare_padding_mask(attention_mask, kv_length, kv_offset, _slice=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Under specific conditions, we can avoid materializing the mask, instead relying on the `is_causal` argument\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_is_causal_skip \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_ignore_causal_mask_sdpa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# Similar to `kv_arange = torch.arange(start=kv_offset, end=kv_offset + kv_length, device=cache_position.device)`\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[38;5;66;03m# but without data-dependent slicing (i.e. torch.compile friendly)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai311/lib/python3.11/site-packages/transformers/masking_utils.py:255\u001b[39m, in \u001b[36m_ignore_causal_mask_sdpa\u001b[39m\u001b[34m(padding_mask, query_length, kv_length, kv_offset, local_attention_size)\u001b[39m\n\u001b[32m    238\u001b[39m     padding_mask = padding_mask[:, mask_indices]\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# When using `torch.export` or `torch.onnx.dynamo_export`, we must pass an example input, and `is_causal` behavior is\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m# hard-coded to the forward. If a user exports a model with query_length > 1, the exported model will hard-code `is_causal=True`\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# which is in general wrong (see https://github.com/pytorch/pytorch/issues/108108). Thus, we only set\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# `ignore_causal_mask = True` if we are not tracing\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m is_tracing\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# only cases when lower and upper diags are the same, see https://github.com/pytorch/pytorch/issues/108108\u001b[39;00m\n\u001b[32m    247\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (query_length == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (kv_length == query_length \u001b[38;5;129;01mor\u001b[39;00m _is_torch_xpu_available))\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# in this case we need to add special patterns to the mask so cannot be skipped otherwise\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (local_attention_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m kv_length < local_attention_size)\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# In this case, we need to add padding to the mask, so cannot be skipped otherwise\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    252\u001b[39m         padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    253\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    254\u001b[39m             padding_mask.all()\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_torch_xpu_available \u001b[38;5;129;01mor\u001b[39;00m query_length == \u001b[32m1\u001b[39m\n\u001b[32m    256\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m padding_mask[:, :query_length].all()\n\u001b[32m    257\u001b[39m         )\n\u001b[32m    258\u001b[39m     )\n\u001b[32m    259\u001b[39m ):\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ca7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86766f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946f2b7c1018437299fed469d1923ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d123c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document and generate 5 clinically relevant questions.\\n\"    \n",
    "    \"Requirements:\\n\"   \n",
    "    #\"1) Don't need answer. \\n\"\n",
    "    \"2) Output JSON string like this: {\\\"questions:\\\": ['','',...,'']}.\\n\\n\"\n",
    "    #\"3) Only put 5 questions.\\n\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return only JSON string without any words around the json string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655298c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d91d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"questions\": [\"What is the typical dosing frequency of phenylephrine?\", \"Is it safe to take phenylephrine with other cough and cold medications?\", \"Can phenylephrine be given to children younger than 4 years of age?\", \"How do I determine the appropriate dose of phenylephrine for a child?\", \"What should I do if I experience no relief from phenylephrine after 7 days?\"]}\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31214e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"questions\": [\"What is the typical dosing frequency of phenylephrine?\", \"Is it safe to take phenylephrine with other cough and cold medications?\", \"Can phenylephrine be given to children younger than 4 years of age?\", \"How do I determine the appropriate dose of phenylephrine for a child?\", \"What should I do if I experience no relief from phenylephrine after 7 days?\"]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bef5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/ai311/lib/python3.11/site-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66e7a9fe1b6488c92e1814d3597a021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "gen = pipeline(\"text-generation\", model=model, tokenizer=tok,return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee87c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a medical student.\"},\n",
    "  {\"role\": \"user\", \"content\": (\n",
    "    \"Read the document and generate 5 clinically relevant questions.\\n\"    \n",
    "    \"Requirements:\\n\"    \n",
    "    #\"1) Don't need answer. \\n\"\n",
    "    \"2) Output complete JSON string: {'questions:': ['question1','question2',...,'question5']}.\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return only JSON.\"\n",
    "  )}\n",
    "]\n",
    "prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "resp = gen(prompt, max_new_tokens=500, temperature=0.4,\n",
    "           eos_token_id=tok.eos_token_id)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f64a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6478148b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70e8d8986074cf4a5f1e17760f4eac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6534449d3583411a8e0313bc1f8c68f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e765658546c4c6ea885325e6b2a3b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b421ae63da640bba10163713c547de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18170ae0e4804eaca265f0c5d1e33f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431c4d170dcf4a34aef82db56241c0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dc85b1610f4805aaa3ddc251c49a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661408683cff4d7abed7f62313125c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b8b15f626f4acc92447e824cd3f528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a875cf7cc3c4a61a8a47205c44eea1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1322491dd0e4208bfb757e505b977a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415dd99900f34f7c91a7f8f2f4483639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b5b2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document Below and generate 5 clinically relevant questions. \\n\"    \n",
    "    \"Requirements:\\n\"   \n",
    "    \"1) Don't need python code at all. \\n\"\n",
    "    \"2) Output JSON string: {\\\"questions:\\\": ['','',...,'']}.\\n\\n\"\n",
    "    \"3) Output only JSON string. \\n\"\n",
    "    \"4) Don't generate any other text besides the JSON string. \\n\"\n",
    "    \"5) Don't put Note after the JSON string. \\n\"\n",
    "    #\"3) Only put 5 questions.\\n\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return only JSON without any words around the json object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b848436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb34ce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "{\"questions\": [\"What is the recommended frequency of taking phenylephrine?\", \"What should you do if you are taking phenylephrine and your symptoms do not get better within 7 days?\", \"What is the recommended age range for giving phenylephrine to children?\", \"What should you do if you are giving phenylephrine to a child and you are unsure about the dose?\", \"What is the recommended way to measure the dose of phenylephrine liquid?\"]} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "{\"questions\": [\"What is the recommended frequency of taking phenylephrine?\", \"What should you do if you are taking phenylephrine and your symptoms do not get better within 7 days?\", \"What is the recommended age range for giving phenylephrine to children?\", \"What should you do if you are giving phenylephrine to a child and you are unsure about the dose?\", \"What is the recommended way to measure the dose of phenylephrine liquid?\"]}\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "{\"questions\": [\"What is the recommended frequency of taking phenylephrine?\", \"What should you do if you are taking phenylephrine and your symptoms do not get better within 7 days?\", \"What is the recommended age range for giving phenylephrine to children?\", \"What should you do if you are giving phenylephrine to a child and you are unsure about the dose?\", \"What is the recommended way to measure the dose of phenylephrine liquid?\"]}\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "{\"questions\": [\"What is the recommended frequency of taking phenylephrine?\", \"What should you do if you are taking phenylephrine and your symptoms do not get better within 7 days?\", \"What is the recommended age range for giving phenylephrine to children?\", \"What should you do if you are giving phenylephrine to a child and you are unsure about the dose?\", \"What is the recommended way to measure the dose of phenylephrine liquid?\"]}\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "{\"questions\": [\"What is the recommended frequency of taking phenylephrine?\", \"What should you do if you are taking phenylephrine and your symptoms do not get better within 7 days?\", \"What is the recommended age range for giving phenylephrine to children?\", \"What should you do if you are giving phenylephrine to a child and you are unsure about the dose?\", \"What is the recommended way to measure the dose of phenylephrine\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b1fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4badbc8c",
   "metadata": {},
   "source": [
    "### test do summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee05f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8ae658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d611a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document and do a summarization.\\n \"    \n",
    "    \"Requirements:\\n\"   \n",
    "    \"1) Only give me a summarization under 300 words. \\n\"\n",
    "    \"2) The summarization only have one paragraph\\n\"    \n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return summarization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555e71d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d554ec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Phenylephrine is a medication that comes in various forms, including tablets, liquids, and dissolving strips. It is usually taken every 4 hours as needed, and the exact dosage depends on the specific product and the individual's needs. Taking phenylephrine exactly as directed is crucial to avoid side effects and ensure effective treatment. It is essential to check the product label carefully before using multiple products at the same time and to consult with a doctor or pharmacist if you have any questions or concerns. Phenylephrine is available in combination with other medications, and it is recommended to use caution when giving it to children, especially those under 4 years old. It is also important to follow the package directions carefully and to consult with a doctor if you are unsure about the correct dosage or the product's suitability for your child. In addition, phenylephrine can cause serious side effects or death in young children, so it is essential to use it only under adult supervision.\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47629f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c101fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c30af0d9834fdf93d2239d5fc217e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08461154",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document and do a summarization.\\n \"    \n",
    "    \"Requirements:\\n\"   \n",
    "    \"1) Only give me a summarization under 300 words. \\n\"\n",
    "    \"2) The summarization only have one paragraph\\n\"    \n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return summarization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93089c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f5c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Phenylephrine is a medication used to treat nasal congestion and eye redness. It comes in various forms such as tablets, liquids, and dissolving strips, and should be taken exactly as directed by a doctor or the label. It is important to carefully read the label and follow the instructions, especially when giving it to children. The medication should not be given to children under the age of four, and proper dosage should be followed for children between the ages of four and eleven. Additionally, phenylephrine should not be used with other cough and cold medications without consulting a doctor, as this can lead to an overdose. If symptoms persist or worsen, one should stop taking the medication and consult a doctor.\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e6f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49449b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a175f84bb30a45e79bde713645d24a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97d1e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Read the document and do a summarization.\\n \"    \n",
    "    \"Requirements:\\n\"   \n",
    "    \"1) Only give me a summarization under 300 words. \\n\"\n",
    "    \"2) The summarization only have one paragraph\\n\"    \n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    \"Return summarization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17eddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f621a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ec7407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053d57d8bd4848e89b5cd8623ebf079c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aca299a299d4b058190415e190b6232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596d9521b72942d09397cf5cc95c8adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae58bb3ae8c4adb9867c5e54a27f977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdfd2f084254595ab103e285cf3a697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d3776754504deaa858481a39a22375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771482a79d22430b8af7c4ef72de966a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeabb9ae5884ed58db2ded62e55a2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b06d3353c134686b5f0bf593f402a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57eac51aab748c2832a52ce51422a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model_id ,return_full_text=False, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2c5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"phenylephrine comes as a tablet, a liquid, or a dissolving strip to take by mouth. it is usually taken every 4 hours as needed. follow the directions on your prescription label or the package label carefully, and ask your doctor or pharmacist to explain any part you do not understand. take phenylephrine exactly as directed. do not take more or less of it or take it more often than prescribed by your doctor or directed on the label.phenylephrine comes alone and in combination with other medications. ask your doctor or pharmacist for advice on which product is best for your symptoms. check nonprescription cough and cold product labels carefully before using two or more products at the same time. these products may contain the same active ingredient(s) and taking them together could cause you to receive an overdose. this is especially important if you will be giving cough and cold medications to a child.nonprescription cough and cold combination products, including products that contain phenylephrine, can cause serious side effects or death in young children. do not give these products to children younger than 4 years of age. if you give these products to children 4 to 11 years of age, use caution and follow the package directions carefully.if you are giving phenylephrine or a combination product that contains phenylephrine to a child, read the package label carefully to be sure that it is the right product for a child of that age. do not give phenylephrine products that are made for adults to children.before you give a phenylephrine product to a child, check the package label to find out how much medication the child should receive. give the dose that matches the child's age on the chart. ask the child's doctor if you don't know how much medication to give the child.if you are taking the liquid, do not use a household spoon to measure your dose. use the measuring spoon or cup that came with the medication or use a spoon made especially for measuring medication.if your symptoms do not get better within 7 days or if you have a fever, stop taking phenylephrine and call your doctor.if you are taking the dissolving strips, place one strip on your tongue and allow it to dissolve.about Phenylephrine\"\n",
    "\n",
    "prompt = (\"Please give me a summarization of the document below.\\n \"   \n",
    "    \"The summarization only contains under 300 words.\\n\"\n",
    "    \"The summarization only has one paragraph.\\n\"\n",
    "    f\"Document:\\n{document}\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf8ea6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = pipe(prompt, max_new_tokens=512, temperature=0.4)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92cd2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenylephrine is used to treat stuffy nose, sinus congestion, and runny nose caused by the common cold, flu, or other breathing illnesses (e.g., hay fever). Phenylephrine is also used to treat nasal congestion caused by a cold, flu, hay fever, or other breathing illnesses. It is also used to treat nasal congestion caused by an enlarged prostate (benign prostatic hyperplasia). Phenylephrine is a decongestant that works by narrowing the blood vessels in the nasal passages. This helps to decrease congestion and stuffiness in the nose. Phenylephrine is also used to treat low blood pressure (hypotension) after surgery or to prevent low blood pressure caused by certain medications (e.g., antihistamines, tranquilizers). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e.g., spinal tap, regional anesthesia). Phenylephrine is also used to treat low blood pressure (hypotension) that occurs during or after surgery or other procedures (e\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cd261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFT_QLoRA_Llama3_1B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
